{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import scipy.stat as sps\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pandas import ExcelWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 9.97 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = pd.read_excel('card transactions.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\beizh\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th># NaN</th>\n",
       "      <th>% populated</th>\n",
       "      <th># unique</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Recnum</td>\n",
       "      <td>0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>96753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cardnum</td>\n",
       "      <td>0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>1645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Date</td>\n",
       "      <td>0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Merchnum</td>\n",
       "      <td>3375</td>\n",
       "      <td>96.511736</td>\n",
       "      <td>13091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Merch description</td>\n",
       "      <td>0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>13126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Merch state</td>\n",
       "      <td>1195</td>\n",
       "      <td>98.764896</td>\n",
       "      <td>227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Merch zip</td>\n",
       "      <td>4656</td>\n",
       "      <td>95.187746</td>\n",
       "      <td>4567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Transtype</td>\n",
       "      <td>0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Amount</td>\n",
       "      <td>0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>34909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Fraud</td>\n",
       "      <td>0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            variable  # NaN  % populated # unique\n",
       "0             Recnum      0   100.000000    96753\n",
       "1            Cardnum      0   100.000000     1645\n",
       "2               Date      0   100.000000      365\n",
       "3           Merchnum   3375    96.511736    13091\n",
       "4  Merch description      0   100.000000    13126\n",
       "5        Merch state   1195    98.764896      227\n",
       "6          Merch zip   4656    95.187746     4567\n",
       "7          Transtype      0   100.000000        4\n",
       "8             Amount      0   100.000000    34909\n",
       "9              Fraud      0   100.000000        2"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# summary\n",
    "numrecords = len(df)\n",
    "stat_df = pd.DataFrame(df.isnull().sum(axis = 0))\n",
    "stat_df = stat_df.reset_index().rename(columns = {'index':'variable', 0 :\"# NaN\"})\n",
    "stat_df[\"% populated\"] = (1 - stat_df[\"# NaN\"]/numrecords)*100\n",
    "stat_df[\"# unique\"] = ''\n",
    "\n",
    "for i in range(len(list(df))):\n",
    "    stat_df[\"# unique\"][i] = df[list(df)[i]].nunique()\n",
    "    \n",
    "stat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96397"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Identify any exclusions, bad records\n",
    "\n",
    "# Remove single large transaction outlier in Amount\n",
    "df = df[df['Amount']<3000000]\n",
    "\n",
    "# Remove all but P transaction type\n",
    "df = df[df['Transtype'] == 'P']\n",
    "\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1414"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --------------- Fill in NAs ----------\n",
    "\n",
    "### Merchnum \n",
    "# Transform 0 values into NA\n",
    "df.loc[df['Merchnum'] == '0', 'Merchnum'] = np.NaN\n",
    "\n",
    "# fill most frequenct merchnum using merch description\n",
    "dict1 = df.set_index('Merch description')['Merchnum'].to_dict()\n",
    "df['Merchnum'].fillna(df['Merch description'].map(dict1), inplace = True)\n",
    "\n",
    "# fill most frequenct merchnum in this zip\n",
    "dict1 = dict(zip(df['Merch zip'].dropna(), df['Merchnum']))\n",
    "df['Merchnum'].fillna(df['Merch zip'].map(dict1), inplace = True)\n",
    "\n",
    "pd.isnull(df['Merchnum']).sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3810"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Merch state and zip\n",
    "numrecords - (df['Merch state'].isna() == df['Merch zip'].isna()).sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "543"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Merch zip\n",
    "# df.groupby(['Merch description','Merch zip']).size()\n",
    "\n",
    "# fill NA in Merch zip using Merch description\n",
    "dict1 = df.set_index('Merch description')['Merch zip'].to_dict()\n",
    "df['Merch zip'].fillna(df['Merch description'].map(dict1), inplace = True)\n",
    "\n",
    "# fill NA in Merch zip using Merchnum\n",
    "dict1 = df.set_index('Merchnum')['Merch zip'].to_dict()\n",
    "df['Merch zip'].fillna(df['Merchnum'].map(dict1), inplace = True)\n",
    "\n",
    "# fill NA in Merch zip using Cardnum\n",
    "dict1 = df.set_index('Cardnum')['Merch zip'].to_dict()\n",
    "df['Merch zip'].fillna(df['Cardnum'].map(dict1), inplace = True)\n",
    "# It will automatically choose zip with highest frequency\n",
    "\n",
    "pd.isnull(df['Merch zip']).sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60108.0"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic = dict(zip(df['Cardnum'], df['Merch zip']))\n",
    "dic[5142310525]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "122"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Merch state\n",
    "# df.groupby(['Merch description','Merch state']).size()\n",
    "# Each Merch description has one matched state\n",
    "\n",
    "# fill NA in Merch state using Merch description\n",
    "dict1 = df.set_index('Merch description')['Merch state'].to_dict()\n",
    "df['Merch state'].fillna(df['Merch description'].map(dict1), inplace = True)\n",
    "\n",
    "# fill NA in Merch state using Merchnum\n",
    "dict1 = df.set_index('Merchnum')['Merch state'].to_dict()\n",
    "df['Merch state'].fillna(df['Merchnum'].map(dict1), inplace = True)\n",
    "\n",
    "# fill NA in Merch state using Merch zip\n",
    "\n",
    "dict1 = dict(zip(df['Merch zip'].dropna(), df['Merch state']))\n",
    "df['Merch state'].fillna(df['Merch zip'].map(dict1), inplace = True)\n",
    "\n",
    "# fill NA in Merch state using Cardnum\n",
    "dict1 = df.set_index('Cardnum')['Merch state'].to_dict()\n",
    "df['Merch state'].fillna(df['Cardnum'].map(dict1), inplace = True)\n",
    "\n",
    "pd.isnull(df['Merch state']).sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94631"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop remained NA in three variables\n",
    "df = df.dropna()\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cardnum     Date        Amount \n",
       "5142110081  2010-11-26  636.20     1\n",
       "            2010-12-27  495.90     1\n",
       "5142110402  2010-01-19  506.50     1\n",
       "            2010-01-31  20.81      1\n",
       "            2010-02-03  30.26      1\n",
       "            2010-02-04  54.00      1\n",
       "                        437.76     1\n",
       "5142110434  2010-10-06  1551.64    1\n",
       "5142110749  2010-04-19  62.94      1\n",
       "            2010-06-13  794.85     1\n",
       "5142110909  2010-01-17  351.24     1\n",
       "            2010-01-20  64.40      1\n",
       "            2010-02-09  301.79     1\n",
       "            2010-03-21  128.00     1\n",
       "            2010-03-22  90.99      1\n",
       "                        766.88     1\n",
       "            2010-04-05  435.47     1\n",
       "            2010-04-12  30.40      1\n",
       "                        161.25     1\n",
       "            2010-04-13  809.45     1\n",
       "            2010-05-18  79.80      2\n",
       "            2010-06-12  288.00     1\n",
       "            2010-07-07  1535.40    1\n",
       "            2010-07-12  51.75      1\n",
       "            2010-12-20  107.76     1\n",
       "            2010-12-27  305.25     1\n",
       "                        387.00     1\n",
       "            2010-12-30  354.94     1\n",
       "5142111097  2010-02-02  56.98      1\n",
       "            2010-03-02  83.80      1\n",
       "                                  ..\n",
       "5142847398  2010-01-29  168.63     1\n",
       "            2010-01-31  101.02     1\n",
       "            2010-02-03  803.21     1\n",
       "            2010-02-04  126.48     1\n",
       "            2010-02-06  761.66     1\n",
       "            2010-02-09  53.64      1\n",
       "            2010-02-10  652.97     1\n",
       "            2010-02-11  668.75     1\n",
       "            2010-02-14  144.01     1\n",
       "            2010-02-17  905.78     1\n",
       "            2010-02-18  0.22       1\n",
       "            2010-02-21  365.38     1\n",
       "            2010-02-22  589.20     1\n",
       "            2010-02-25  607.18     1\n",
       "            2010-02-26  758.01     1\n",
       "            2010-02-27  875.74     1\n",
       "            2010-03-02  314.50     1\n",
       "            2010-03-03  261.20     1\n",
       "            2010-03-07  347.94     1\n",
       "            2010-03-08  855.61     1\n",
       "            2010-03-11  465.50     1\n",
       "            2010-03-12  825.09     1\n",
       "            2010-03-14  595.59     1\n",
       "            2010-03-17  46.27      1\n",
       "            2010-03-18  75.53      1\n",
       "            2010-03-21  199.14     1\n",
       "            2010-03-22  78.23      1\n",
       "            2010-03-24  440.06     1\n",
       "            2010-03-28  288.82     1\n",
       "            2010-03-29  736.55     1\n",
       "Name: Amount, Length: 87585, dtype: int64"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df.groupby(['Cardnum','Date'])['Amount'].value_counts()\n",
    "# df[df['Cardnum'] == 5142190439]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# --------------- Create variables ----------\n",
    "### Amount expert variables\n",
    "\n",
    "# Cardnum\n",
    "# sum the amount at the same day first and then rolling\n",
    "df2 = df.groupby(['Cardnum','Date'])['Amount'].sum().to_frame().reset_index().set_index('Date')\n",
    "new_df = df.join(df.groupby(['Cardnum','Date'])['Amount'].sum(),on = ['Cardnum','Date'], rsuffix = '_cn_actual')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (closed = 'left') in rolling function means when calculating past n days we exlude today's transactions\n",
    "\n",
    "def amount_mean_func(column, window, rsuffix):\n",
    "    dataframe = pd.DataFrame()\n",
    "    dataframe = new_df.join(df2.groupby([column])['Amount'].rolling(window = window, closed = 'left').mean(), on = [column,'Date'], rsuffix = rsuffix)\n",
    "    return dataframe\n",
    "\n",
    "# def amount_max_func(column, window, rsuffix):\n",
    "#     dataframe = pd.DataFrame()\n",
    "#     dataframe = new_df.join(df2.groupby([column])['Amount'].rolling(window = window).max(), on = [column,'Date'], rsuffix = rsuffix)\n",
    "#     return dataframe\n",
    "\n",
    "# def amount_median_func(column, window, rsuffix):\n",
    "#     dataframe = pd.DataFrame()\n",
    "#     dataframe = new_df.join(df2.groupby([column])['Amount'].rolling(window = window).median(), on = [column,'Date'], rsuffix = rsuffix)\n",
    "#     return dataframe\n",
    "\n",
    "def amount_sum_func(column, window, rsuffix):\n",
    "    dataframe = pd.DataFrame()\n",
    "    dataframe = new_df.join(df2.groupby([column])['Amount'].rolling(window = window, closed = 'left').sum(), on = [column,'Date'], rsuffix = rsuffix)\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.groupby(['Cardnum','Date'])['Amount'].sum().to_frame().reset_index().set_index('Date')\n",
    "new_df = df.join(df.groupby(['Cardnum','Date'])['Amount'].sum(),on = ['Cardnum','Date'], rsuffix = '_cn_actual')\n",
    "\n",
    "new_df = amount_mean_func(column = 'Cardnum',window = '1D',rsuffix = '_cn_1d_avg')\n",
    "# new_df = amount_max_func(column = 'Cardnum',window = '1D',rsuffix = '_cn_1d_max')\n",
    "# new_df = amount_median_func(column = 'Cardnum',window = '1D',rsuffix = '_cn_1d_median')\n",
    "new_df = amount_sum_func(column = 'Cardnum',window = '1D',rsuffix = '_cn_1d_sum')\n",
    "new_df['Amount_cn_1d_act-avg'] = new_df['Amount_cn_actual'] - new_df['Amount_cn_1d_avg']\n",
    "# new_df['Amount_cn_1d_act-median'] = new_df['Amount_cn_actual'] - new_df['Amount_cn_1d_median']\n",
    "new_df['Amount_cn_1d_act/avg'] = new_df['Amount_cn_actual']/new_df['Amount_cn_1d_avg']\n",
    "# new_df['Amount_cn_1d_act/max'] = new_df['Amount_cn_actual']/new_df['Amount_cn_1d_max']\n",
    "new_df['Amount_cn_1d_act/sum'] = new_df['Amount_cn_actual']/new_df['Amount_cn_1d_sum']\n",
    "# new_df['Amount_cn_1d_act/median'] = new_df['Amount_cn_actual']/new_df['Amount_cn_1d_median']\n",
    "\n",
    "new_df = amount_mean_func(column = 'Cardnum',window = '4D',rsuffix = '_cn_4d_avg')\n",
    "new_df = amount_sum_func(column = 'Cardnum',window = '4D',rsuffix = '_cn_4d_sum')\n",
    "new_df['Amount_cn_4d_act-avg'] = new_df['Amount_cn_actual'] - new_df['Amount_cn_4d_avg']\n",
    "new_df['Amount_cn_4d_act/avg'] = new_df['Amount_cn_actual']/new_df['Amount_cn_4d_avg']\n",
    "new_df['Amount_cn_4d_act/sum'] = new_df['Amount_cn_actual']/new_df['Amount_cn_4d_sum']\n",
    "\n",
    "new_df = amount_mean_func(column = 'Cardnum',window = '7D',rsuffix = '_cn_7d_avg')\n",
    "new_df = amount_sum_func(column = 'Cardnum',window = '7D',rsuffix = '_cn_7d_sum')\n",
    "new_df['Amount_cn_7d_act-avg'] = new_df['Amount_cn_actual'] - new_df['Amount_cn_7d_avg']\n",
    "new_df['Amount_cn_7d_act/avg'] = new_df['Amount_cn_actual']/new_df['Amount_cn_7d_avg']\n",
    "new_df['Amount_cn_7d_act/sum'] = new_df['Amount_cn_actual']/new_df['Amount_cn_7d_sum']\n",
    "\n",
    "new_df = amount_mean_func(column = 'Cardnum',window = '14D',rsuffix = '_cn_14d_avg')\n",
    "new_df = amount_sum_func(column = 'Cardnum',window = '14D',rsuffix = '_cn_14d_sum')\n",
    "new_df['Amount_cn_14d_act-avg'] = new_df['Amount_cn_actual'] - new_df['Amount_cn_14d_avg']\n",
    "new_df['Amount_cn_14d_act/avg'] = new_df['Amount_cn_actual']/new_df['Amount_cn_14d_avg']\n",
    "new_df['Amount_cn_14d_act/sum'] = new_df['Amount_cn_actual']/new_df['Amount_cn_14d_sum']\n",
    "\n",
    "new_df = amount_mean_func(column = 'Cardnum',window = '30D',rsuffix = '_cn_30d_avg')\n",
    "new_df = amount_sum_func(column = 'Cardnum',window = '30D',rsuffix = '_cn_30d_sum')\n",
    "new_df['Amount_cn_30d_act-avg'] = new_df['Amount_cn_actual'] - new_df['Amount_cn_30d_avg']\n",
    "new_df['Amount_cn_30d_act/avg'] = new_df['Amount_cn_actual']/new_df['Amount_cn_30d_avg']\n",
    "new_df['Amount_cn_30d_act/sum'] = new_df['Amount_cn_actual']/new_df['Amount_cn_30d_sum']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.groupby(['Merchnum','Date'])['Amount'].sum().to_frame().reset_index().set_index('Date')\n",
    "new_df = new_df.join(df.groupby(['Merchnum','Date'])['Amount'].sum(),on = ['Merchnum','Date'], rsuffix = '_mn_actual')\n",
    "\n",
    "new_df = amount_mean_func(column = 'Merchnum',window = '1D',rsuffix = '_mn_1d_avg')\n",
    "new_df = amount_sum_func(column = 'Merchnum',window = '1D',rsuffix = '_mn_1d_sum')\n",
    "new_df['Amount_mn_1d_act-avg'] = new_df['Amount_mn_actual'] - new_df['Amount_mn_1d_avg']\n",
    "new_df['Amount_mn_1d_act/avg'] = new_df['Amount_mn_actual']/new_df['Amount_mn_1d_avg']\n",
    "new_df['Amount_mn_1d_act/sum'] = new_df['Amount_mn_actual']/new_df['Amount_mn_1d_sum']\n",
    "\n",
    "new_df = amount_mean_func(column = 'Merchnum',window = '4D',rsuffix = '_mn_4d_avg')\n",
    "new_df = amount_sum_func(column = 'Merchnum',window = '4D',rsuffix = '_mn_4d_sum')\n",
    "new_df['Amount_mn_4d_act-avg'] = new_df['Amount_mn_actual'] - new_df['Amount_mn_4d_avg']\n",
    "new_df['Amount_mn_4d_act/avg'] = new_df['Amount_mn_actual']/new_df['Amount_mn_4d_avg']\n",
    "new_df['Amount_mn_4d_act/sum'] = new_df['Amount_mn_actual']/new_df['Amount_mn_4d_sum']\n",
    "\n",
    "new_df = amount_mean_func(column = 'Merchnum',window = '7D',rsuffix = '_mn_7d_avg')\n",
    "new_df = amount_sum_func(column = 'Merchnum',window = '7D',rsuffix = '_mn_7d_sum')\n",
    "new_df['Amount_mn_7d_act-avg'] = new_df['Amount_mn_actual'] - new_df['Amount_mn_7d_avg']\n",
    "new_df['Amount_mn_7d_act/avg'] = new_df['Amount_mn_actual']/new_df['Amount_mn_7d_avg']\n",
    "new_df['Amount_mn_7d_act/sum'] = new_df['Amount_mn_actual']/new_df['Amount_mn_7d_sum']\n",
    "\n",
    "new_df = amount_mean_func(column = 'Merchnum',window = '14D',rsuffix = '_mn_14d_avg')\n",
    "new_df = amount_sum_func(column = 'Merchnum',window = '14D',rsuffix = '_mn_14d_sum')\n",
    "new_df['Amount_mn_14d_act-avg'] = new_df['Amount_mn_actual'] - new_df['Amount_mn_14d_avg']\n",
    "new_df['Amount_mn_14d_act/avg'] = new_df['Amount_mn_actual']/new_df['Amount_mn_14d_avg']\n",
    "new_df['Amount_mn_14d_act/sum'] = new_df['Amount_mn_actual']/new_df['Amount_mn_14d_sum']\n",
    "\n",
    "new_df = amount_mean_func(column = 'Merchnum',window = '30D',rsuffix = '_mn_30d_avg')\n",
    "new_df = amount_sum_func(column = 'Merchnum',window = '30D',rsuffix = '_mn_30d_sum')\n",
    "new_df['Amount_mn_30d_act-avg'] = new_df['Amount_mn_actual'] - new_df['Amount_mn_30d_avg']\n",
    "new_df['Amount_mn_30d_act/avg'] = new_df['Amount_mn_actual']/new_df['Amount_mn_30d_avg']\n",
    "new_df['Amount_mn_30d_act/sum'] = new_df['Amount_mn_actual']/new_df['Amount_mn_30d_sum']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.groupby(['Cardnum','Merchnum','Date'])['Amount'].sum().to_frame().reset_index().set_index('Date')\n",
    "new_df = new_df.join(df.groupby(['Cardnum','Merchnum','Date'])['Amount'].sum(),on = ['Cardnum','Merchnum','Date'], rsuffix = '_cn_mn_actual')\n",
    "\n",
    "new_df = new_df.join(df2.groupby(['Cardnum','Merchnum'])['Amount'].rolling(window = '1D', closed = 'left').mean(), on = ['Cardnum','Merchnum','Date'], rsuffix = '_cn_mn_1d_avg')\n",
    "new_df = new_df.join(df2.groupby(['Cardnum','Merchnum'])['Amount'].rolling(window = '1D', closed = 'left').sum(), on = ['Cardnum','Merchnum','Date'], rsuffix = '_cn_mn_1d_sum')\n",
    "new_df['Amount_cn_mn_1d_act-avg'] = new_df['Amount_cn_mn_actual'] - new_df['Amount_cn_mn_1d_avg']\n",
    "new_df['Amount_cn_mn_1d_act/avg'] = new_df['Amount_cn_mn_actual']/new_df['Amount_cn_mn_1d_avg']\n",
    "new_df['Amount_cn_mn_1d_act/sum'] = new_df['Amount_cn_mn_actual']/new_df['Amount_cn_mn_1d_sum']\n",
    "\n",
    "new_df = new_df.join(df2.groupby(['Cardnum','Merchnum'])['Amount'].rolling(window = '4D', closed = 'left').mean(), on = ['Cardnum','Merchnum','Date'], rsuffix = '_cn_mn_4d_avg')\n",
    "new_df = new_df.join(df2.groupby(['Cardnum','Merchnum'])['Amount'].rolling(window = '4D', closed = 'left').sum(), on = ['Cardnum','Merchnum','Date'], rsuffix = '_cn_mn_4d_sum')\n",
    "new_df['Amount_cn_mn_4d_act-avg'] = new_df['Amount_cn_mn_actual'] - new_df['Amount_cn_mn_4d_avg']\n",
    "new_df['Amount_cn_mn_4d_act/avg'] = new_df['Amount_cn_mn_actual']/new_df['Amount_cn_mn_4d_avg']\n",
    "new_df['Amount_cn_mn_4d_act/sum'] = new_df['Amount_cn_mn_actual']/new_df['Amount_cn_mn_4d_sum']\n",
    "\n",
    "new_df = new_df.join(df2.groupby(['Cardnum','Merchnum'])['Amount'].rolling(window = '7D', closed = 'left').mean(), on = ['Cardnum','Merchnum','Date'], rsuffix = '_cn_mn_7d_avg')\n",
    "new_df = new_df.join(df2.groupby(['Cardnum','Merchnum'])['Amount'].rolling(window = '7D', closed = 'left').sum(), on = ['Cardnum','Merchnum','Date'], rsuffix = '_cn_mn_7d_sum')\n",
    "new_df['Amount_cn_mn_7d_act-avg'] = new_df['Amount_cn_mn_actual'] - new_df['Amount_cn_mn_7d_avg']\n",
    "new_df['Amount_cn_mn_7d_act/avg'] = new_df['Amount_cn_mn_actual']/new_df['Amount_cn_mn_7d_avg']\n",
    "new_df['Amount_cn_mn_7d_act/sum'] = new_df['Amount_cn_mn_actual']/new_df['Amount_cn_mn_7d_sum']\n",
    "\n",
    "new_df = new_df.join(df2.groupby(['Cardnum','Merchnum'])['Amount'].rolling(window = '14D', closed = 'left').mean(), on = ['Cardnum','Merchnum','Date'], rsuffix = '_cn_mn_14d_avg')\n",
    "new_df = new_df.join(df2.groupby(['Cardnum','Merchnum'])['Amount'].rolling(window = '14D', closed = 'left').sum(), on = ['Cardnum','Merchnum','Date'], rsuffix = '_cn_mn_14d_sum')\n",
    "new_df['Amount_cn_mn_14d_act-avg'] = new_df['Amount_cn_mn_actual'] - new_df['Amount_cn_mn_14d_avg']\n",
    "new_df['Amount_cn_mn_14d_act/avg'] = new_df['Amount_cn_mn_actual']/new_df['Amount_cn_mn_14d_avg']\n",
    "new_df['Amount_cn_mn_14d_act/sum'] = new_df['Amount_cn_mn_actual']/new_df['Amount_cn_mn_14d_sum']\n",
    "\n",
    "new_df = new_df.join(df2.groupby(['Cardnum','Merchnum'])['Amount'].rolling(window = '30D', closed = 'left').mean(), on = ['Cardnum','Merchnum','Date'], rsuffix = '_cn_mn_30d_avg')\n",
    "new_df = new_df.join(df2.groupby(['Cardnum','Merchnum'])['Amount'].rolling(window = '30D', closed = 'left').sum(), on = ['Cardnum','Merchnum','Date'], rsuffix = '_cn_mn_30d_sum')\n",
    "new_df['Amount_cn_mn_30d_act-avg'] = new_df['Amount_cn_mn_actual'] - new_df['Amount_cn_mn_30d_avg']\n",
    "new_df['Amount_cn_mn_30d_act/avg'] = new_df['Amount_cn_mn_actual']/new_df['Amount_cn_mn_30d_avg']\n",
    "new_df['Amount_cn_mn_30d_act/sum'] = new_df['Amount_cn_mn_actual']/new_df['Amount_cn_mn_30d_sum']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.groupby(['Cardnum','Merch zip','Date'])['Amount'].sum().to_frame().reset_index().set_index('Date')\n",
    "new_df = new_df.join(df.groupby(['Cardnum','Merch zip','Date'])['Amount'].sum(),on = ['Cardnum','Merch zip','Date'], rsuffix = '_cn_zip_actual')\n",
    "\n",
    "new_df = new_df.join(df2.groupby(['Cardnum','Merch zip'])['Amount'].rolling(window = '1D', closed = 'left').mean(), on = ['Cardnum','Merch zip','Date'], rsuffix = '_cn_zip_1d_avg')\n",
    "new_df = new_df.join(df2.groupby(['Cardnum','Merch zip'])['Amount'].rolling(window = '1D', closed = 'left').sum(), on = ['Cardnum','Merch zip','Date'], rsuffix = '_cn_zip_1d_sum')\n",
    "new_df['Amount_cn_zip_1d_act-avg'] = new_df['Amount_cn_zip_actual'] - new_df['Amount_cn_zip_1d_avg']\n",
    "new_df['Amount_cn_zip_1d_act/avg'] = new_df['Amount_cn_zip_actual']/new_df['Amount_cn_zip_1d_avg']\n",
    "new_df['Amount_cn_zip_1d_act/sum'] = new_df['Amount_cn_zip_actual']/new_df['Amount_cn_zip_1d_sum']\n",
    "\n",
    "new_df = new_df.join(df2.groupby(['Cardnum','Merch zip'])['Amount'].rolling(window = '4D', closed = 'left').mean(), on = ['Cardnum','Merch zip','Date'], rsuffix = '_cn_zip_4d_avg')\n",
    "new_df = new_df.join(df2.groupby(['Cardnum','Merch zip'])['Amount'].rolling(window = '4D', closed = 'left').sum(), on = ['Cardnum','Merch zip','Date'], rsuffix = '_cn_zip_4d_sum')\n",
    "new_df['Amount_cn_zip_4d_act-avg'] = new_df['Amount_cn_zip_actual'] - new_df['Amount_cn_zip_4d_avg']\n",
    "new_df['Amount_cn_zip_4d_act/avg'] = new_df['Amount_cn_zip_actual']/new_df['Amount_cn_zip_4d_avg']\n",
    "new_df['Amount_cn_zip_4d_act/sum'] = new_df['Amount_cn_zip_actual']/new_df['Amount_cn_zip_4d_sum']\n",
    "\n",
    "new_df = new_df.join(df2.groupby(['Cardnum','Merch zip'])['Amount'].rolling(window = '7D', closed = 'left').mean(), on = ['Cardnum','Merch zip','Date'], rsuffix = '_cn_zip_7d_avg')\n",
    "new_df = new_df.join(df2.groupby(['Cardnum','Merch zip'])['Amount'].rolling(window = '7D', closed = 'left').sum(), on = ['Cardnum','Merch zip','Date'], rsuffix = '_cn_zip_7d_sum')\n",
    "new_df['Amount_cn_zip_7d_act-avg'] = new_df['Amount_cn_zip_actual'] - new_df['Amount_cn_zip_7d_avg']\n",
    "new_df['Amount_cn_zip_7d_act/avg'] = new_df['Amount_cn_zip_actual']/new_df['Amount_cn_zip_7d_avg']\n",
    "new_df['Amount_cn_zip_7d_act/sum'] = new_df['Amount_cn_zip_actual']/new_df['Amount_cn_zip_7d_sum']\n",
    "\n",
    "new_df = new_df.join(df2.groupby(['Cardnum','Merch zip'])['Amount'].rolling(window = '14D', closed = 'left').mean(), on = ['Cardnum','Merch zip','Date'], rsuffix = '_cn_zip_14d_avg')\n",
    "new_df = new_df.join(df2.groupby(['Cardnum','Merch zip'])['Amount'].rolling(window = '14D', closed = 'left').sum(), on = ['Cardnum','Merch zip','Date'], rsuffix = '_cn_zip_14d_sum')\n",
    "new_df['Amount_cn_zip_14d_act-avg'] = new_df['Amount_cn_zip_actual'] - new_df['Amount_cn_zip_14d_avg']\n",
    "new_df['Amount_cn_zip_14d_act/avg'] = new_df['Amount_cn_zip_actual']/new_df['Amount_cn_zip_14d_avg']\n",
    "new_df['Amount_cn_zip_14d_act/sum'] = new_df['Amount_cn_zip_actual']/new_df['Amount_cn_zip_14d_sum']\n",
    "\n",
    "new_df = new_df.join(df2.groupby(['Cardnum','Merch zip'])['Amount'].rolling(window = '30D', closed = 'left').mean(), on = ['Cardnum','Merch zip','Date'], rsuffix = '_cn_zip_30d_avg')\n",
    "new_df = new_df.join(df2.groupby(['Cardnum','Merch zip'])['Amount'].rolling(window = '30D', closed = 'left').sum(), on = ['Cardnum','Merch zip','Date'], rsuffix = '_cn_zip_30d_sum')\n",
    "new_df['Amount_cn_zip_30d_act-avg'] = new_df['Amount_cn_zip_actual'] - new_df['Amount_cn_zip_30d_avg']\n",
    "new_df['Amount_cn_zip_30d_act/avg'] = new_df['Amount_cn_zip_actual']/new_df['Amount_cn_zip_30d_avg']\n",
    "new_df['Amount_cn_zip_30d_act/sum'] = new_df['Amount_cn_zip_actual']/new_df['Amount_cn_zip_30d_sum']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.groupby(['Cardnum','Merch state','Date'])['Amount'].sum().to_frame().reset_index().set_index('Date')\n",
    "new_df = new_df.join(df.groupby(['Cardnum','Merch state','Date'])['Amount'].sum(),on = ['Cardnum','Merch state','Date'], rsuffix = '_cn_st_actual')\n",
    "\n",
    "new_df = new_df.join(df2.groupby(['Cardnum','Merch state'])['Amount'].rolling(window = '1D', closed = 'left').mean(), on = ['Cardnum','Merch state','Date'], rsuffix = '_cn_st_1d_avg')\n",
    "new_df = new_df.join(df2.groupby(['Cardnum','Merch state'])['Amount'].rolling(window = '1D', closed = 'left').sum(), on = ['Cardnum','Merch state','Date'], rsuffix = '_cn_st_1d_sum')\n",
    "new_df['Amount_cn_st_1d_act-avg'] = new_df['Amount_cn_st_actual'] - new_df['Amount_cn_st_1d_avg']\n",
    "new_df['Amount_cn_st_1d_act/avg'] = new_df['Amount_cn_st_actual']/new_df['Amount_cn_st_1d_avg']\n",
    "new_df['Amount_cn_st_1d_act/sum'] = new_df['Amount_cn_st_actual']/new_df['Amount_cn_st_1d_sum']\n",
    "\n",
    "new_df = new_df.join(df2.groupby(['Cardnum','Merch state'])['Amount'].rolling(window = '4D', closed = 'left').mean(), on = ['Cardnum','Merch state','Date'], rsuffix = '_cn_st_4d_avg')\n",
    "new_df = new_df.join(df2.groupby(['Cardnum','Merch state'])['Amount'].rolling(window = '4D', closed = 'left').sum(), on = ['Cardnum','Merch state','Date'], rsuffix = '_cn_st_4d_sum')\n",
    "new_df['Amount_cn_st_4d_act-avg'] = new_df['Amount_cn_st_actual'] - new_df['Amount_cn_st_4d_avg']\n",
    "new_df['Amount_cn_st_4d_act/avg'] = new_df['Amount_cn_st_actual']/new_df['Amount_cn_st_4d_avg']\n",
    "new_df['Amount_cn_st_4d_act/sum'] = new_df['Amount_cn_st_actual']/new_df['Amount_cn_st_4d_sum']\n",
    "\n",
    "new_df = new_df.join(df2.groupby(['Cardnum','Merch state'])['Amount'].rolling(window = '7D', closed = 'left').mean(), on = ['Cardnum','Merch state','Date'], rsuffix = '_cn_st_7d_avg')\n",
    "new_df = new_df.join(df2.groupby(['Cardnum','Merch state'])['Amount'].rolling(window = '7D', closed = 'left').sum(), on = ['Cardnum','Merch state','Date'], rsuffix = '_cn_st_7d_sum')\n",
    "new_df['Amount_cn_st_7d_act-avg'] = new_df['Amount_cn_st_actual'] - new_df['Amount_cn_st_7d_avg']\n",
    "new_df['Amount_cn_st_7d_act/avg'] = new_df['Amount_cn_st_actual']/new_df['Amount_cn_st_7d_avg']\n",
    "new_df['Amount_cn_st_7d_act/sum'] = new_df['Amount_cn_st_actual']/new_df['Amount_cn_st_7d_sum']\n",
    "\n",
    "new_df = new_df.join(df2.groupby(['Cardnum','Merch state'])['Amount'].rolling(window = '14D', closed = 'left').mean(), on = ['Cardnum','Merch state','Date'], rsuffix = '_cn_st_14d_avg')\n",
    "new_df = new_df.join(df2.groupby(['Cardnum','Merch state'])['Amount'].rolling(window = '14D', closed = 'left').sum(), on = ['Cardnum','Merch state','Date'], rsuffix = '_cn_st_14d_sum')\n",
    "new_df['Amount_cn_st_14d_act-avg'] = new_df['Amount_cn_st_actual'] - new_df['Amount_cn_st_14d_avg']\n",
    "new_df['Amount_cn_st_14d_act/avg'] = new_df['Amount_cn_st_actual']/new_df['Amount_cn_st_14d_avg']\n",
    "new_df['Amount_cn_st_14d_act/sum'] = new_df['Amount_cn_st_actual']/new_df['Amount_cn_st_14d_sum']\n",
    "\n",
    "new_df = new_df.join(df2.groupby(['Cardnum','Merch state'])['Amount'].rolling(window = '30D', closed = 'left').mean(), on = ['Cardnum','Merch state','Date'], rsuffix = '_cn_st_30d_avg')\n",
    "new_df = new_df.join(df2.groupby(['Cardnum','Merch state'])['Amount'].rolling(window = '30D', closed = 'left').sum(), on = ['Cardnum','Merch state','Date'], rsuffix = '_cn_st_30d_sum')\n",
    "new_df['Amount_cn_st_30d_act-avg'] = new_df['Amount_cn_st_actual'] - new_df['Amount_cn_st_30d_avg']\n",
    "new_df['Amount_cn_st_30d_act/avg'] = new_df['Amount_cn_st_actual']/new_df['Amount_cn_st_30d_avg']\n",
    "new_df['Amount_cn_st_30d_act/sum'] = new_df['Amount_cn_st_actual']/new_df['Amount_cn_st_30d_sum']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "### frequency variables\n",
    "new_df['Date'] = new_df['Date'].astype('datetime64[ns]')\n",
    "\n",
    "# Cardnum\n",
    "df3 = df.set_index('Date').groupby(['Cardnum'])['Recnum'].rolling(window = '1D', closed = 'left').count().to_frame().reset_index().drop_duplicates(subset = ['Cardnum','Date'],keep = 'first')\n",
    "new_df = new_df.merge(df3.rename(columns = {'Recnum':'Freq_cn_1d'}), on = ['Cardnum','Date'])\n",
    "\n",
    "df3 = df.set_index('Date').groupby(['Cardnum'])['Recnum'].rolling(window = '4D', closed = 'left').count().to_frame().reset_index().drop_duplicates(subset = ['Cardnum','Date'],keep = 'first')\n",
    "new_df = new_df.merge(df3.rename(columns = {'Recnum':'Freq_cn_4d'}), on = ['Cardnum','Date'])\n",
    "\n",
    "df3 = df.set_index('Date').groupby(['Cardnum'])['Recnum'].rolling(window = '7D', closed = 'left').count().to_frame().reset_index().drop_duplicates(subset = ['Cardnum','Date'],keep = 'first')\n",
    "new_df = new_df.merge(df3.rename(columns = {'Recnum':'Freq_cn_7d'}), on = ['Cardnum','Date'])\n",
    "\n",
    "df3 = df.set_index('Date').groupby(['Cardnum'])['Recnum'].rolling(window = '14D', closed = 'left').count().to_frame().reset_index().drop_duplicates(subset = ['Cardnum','Date'],keep = 'first')\n",
    "new_df = new_df.merge(df3.rename(columns = {'Recnum':'Freq_cn_14d'}), on = ['Cardnum','Date'])\n",
    "\n",
    "df3 = df.set_index('Date').groupby(['Cardnum'])['Recnum'].rolling(window = '30D', closed = 'left').count().to_frame().reset_index().drop_duplicates(subset = ['Cardnum','Date'],keep = 'first')\n",
    "new_df = new_df.merge(df3.rename(columns = {'Recnum':'Freq_cn_30d'}), on = ['Cardnum','Date'])\n",
    "\n",
    "# Merchnum\n",
    "df3 = df.set_index('Date').groupby(['Merchnum'])['Recnum'].rolling(window = '1D', closed = 'left').count().to_frame().reset_index().drop_duplicates(subset = ['Merchnum','Date'],keep = 'first')\n",
    "new_df = new_df.merge(df3.rename(columns = {'Recnum':'Freq_mn_1d'}), on = ['Merchnum','Date'])\n",
    "\n",
    "df3 = df.set_index('Date').groupby(['Merchnum'])['Recnum'].rolling(window = '4D', closed = 'left').count().to_frame().reset_index().drop_duplicates(subset = ['Merchnum','Date'],keep = 'first')\n",
    "new_df = new_df.merge(df3.rename(columns = {'Recnum':'Freq_mn_4d'}), on = ['Merchnum','Date'])\n",
    "\n",
    "df3 = df.set_index('Date').groupby(['Merchnum'])['Recnum'].rolling(window = '7D', closed = 'left').count().to_frame().reset_index().drop_duplicates(subset = ['Merchnum','Date'],keep = 'first')\n",
    "new_df = new_df.merge(df3.rename(columns = {'Recnum':'Freq_mn_7d'}), on = ['Merchnum','Date'])\n",
    "\n",
    "df3 = df.set_index('Date').groupby(['Merchnum'])['Recnum'].rolling(window = '14D', closed = 'left').count().to_frame().reset_index().drop_duplicates(subset = ['Merchnum','Date'],keep = 'first')\n",
    "new_df = new_df.merge(df3.rename(columns = {'Recnum':'Freq_mn_14d'}), on = ['Merchnum','Date'])\n",
    "\n",
    "df3 = df.set_index('Date').groupby(['Merchnum'])['Recnum'].rolling(window = '30D', closed = 'left').count().to_frame().reset_index().drop_duplicates(subset = ['Merchnum','Date'],keep = 'first')\n",
    "new_df = new_df.merge(df3.rename(columns = {'Recnum':'Freq_mn_30d'}), on = ['Merchnum','Date'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cardnum & Merchnum\n",
    "df3 = df.set_index('Date').groupby(['Cardnum','Merchnum'])['Recnum'].rolling(window = '1D', closed = 'left').count().to_frame().reset_index().drop_duplicates(subset = ['Cardnum','Merchnum','Date'],keep = 'first')\n",
    "new_df = new_df.merge(df3.rename(columns = {'Recnum':'Freq_cn_mn_1d'}), on = ['Cardnum','Merchnum','Date'])\n",
    "\n",
    "df3 = df.set_index('Date').groupby(['Cardnum','Merchnum'])['Recnum'].rolling(window = '4D', closed = 'left').count().to_frame().reset_index().drop_duplicates(subset = ['Cardnum','Merchnum','Date'],keep = 'first')\n",
    "new_df = new_df.merge(df3.rename(columns = {'Recnum':'Freq_cn_mn_4d'}), on = ['Cardnum','Merchnum','Date'])\n",
    "\n",
    "df3 = df.set_index('Date').groupby(['Cardnum','Merchnum'])['Recnum'].rolling(window = '7D', closed = 'left').count().to_frame().reset_index().drop_duplicates(subset = ['Cardnum','Merchnum','Date'],keep = 'first')\n",
    "new_df = new_df.merge(df3.rename(columns = {'Recnum':'Freq_cn_mn_7d'}), on = ['Cardnum','Merchnum','Date'])\n",
    "\n",
    "df3 = df.set_index('Date').groupby(['Cardnum','Merchnum'])['Recnum'].rolling(window = '14D', closed = 'left').count().to_frame().reset_index().drop_duplicates(subset = ['Cardnum','Merchnum','Date'],keep = 'first')\n",
    "new_df = new_df.merge(df3.rename(columns = {'Recnum':'Freq_cn_mn_14d'}), on = ['Cardnum','Merchnum','Date'])\n",
    "\n",
    "df3 = df.set_index('Date').groupby(['Cardnum','Merchnum'])['Recnum'].rolling(window = '30D', closed = 'left').count().to_frame().reset_index().drop_duplicates(subset = ['Cardnum','Merchnum','Date'],keep = 'first')\n",
    "new_df = new_df.merge(df3.rename(columns = {'Recnum':'Freq_cn_mn_30d'}), on = ['Cardnum','Merchnum','Date'])\n",
    "\n",
    "# Cardnum & Merch zip\n",
    "df3 = df.set_index('Date').groupby(['Cardnum','Merch zip'])['Recnum'].rolling(window = '1D', closed = 'left').count().to_frame().reset_index().drop_duplicates(subset = ['Cardnum','Merch zip','Date'],keep = 'first')\n",
    "new_df = new_df.merge(df3.rename(columns = {'Recnum':'Freq_cn_zip_1d'}), on = ['Cardnum','Merch zip','Date'])\n",
    "\n",
    "df3 = df.set_index('Date').groupby(['Cardnum','Merch zip'])['Recnum'].rolling(window = '4D', closed = 'left').count().to_frame().reset_index().drop_duplicates(subset = ['Cardnum','Merch zip','Date'],keep = 'first')\n",
    "new_df = new_df.merge(df3.rename(columns = {'Recnum':'Freq_cn_zip_4d'}), on = ['Cardnum','Merch zip','Date'])\n",
    "\n",
    "df3 = df.set_index('Date').groupby(['Cardnum','Merch zip'])['Recnum'].rolling(window = '7D', closed = 'left').count().to_frame().reset_index().drop_duplicates(subset = ['Cardnum','Merch zip','Date'],keep = 'first')\n",
    "new_df = new_df.merge(df3.rename(columns = {'Recnum':'Freq_cn_zip_7d'}), on = ['Cardnum','Merch zip','Date'])\n",
    "\n",
    "df3 = df.set_index('Date').groupby(['Cardnum','Merch zip'])['Recnum'].rolling(window = '14D', closed = 'left').count().to_frame().reset_index().drop_duplicates(subset = ['Cardnum','Merch zip','Date'],keep = 'first')\n",
    "new_df = new_df.merge(df3.rename(columns = {'Recnum':'Freq_cn_zip_14d'}), on = ['Cardnum','Merch zip','Date'])\n",
    "\n",
    "df3 = df.set_index('Date').groupby(['Cardnum','Merch zip'])['Recnum'].rolling(window = '30D', closed = 'left').count().to_frame().reset_index().drop_duplicates(subset = ['Cardnum','Merch zip','Date'],keep = 'first')\n",
    "new_df = new_df.merge(df3.rename(columns = {'Recnum':'Freq_cn_zip_30d'}), on = ['Cardnum','Merch zip','Date'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cardnum & Merch state\n",
    "df3 = df.set_index('Date').groupby(['Cardnum','Merch state'])['Recnum'].rolling(window = '1D', closed = 'left').count().to_frame().reset_index().drop_duplicates(subset = ['Cardnum','Merch state','Date'],keep = 'first')\n",
    "new_df = new_df.merge(df3.rename(columns = {'Recnum':'Freq_cn_st_1d'}), on = ['Cardnum','Merch state','Date'])\n",
    "\n",
    "df3 = df.set_index('Date').groupby(['Cardnum','Merch state'])['Recnum'].rolling(window = '4D', closed = 'left').count().to_frame().reset_index().drop_duplicates(subset = ['Cardnum','Merch state','Date'],keep = 'first')\n",
    "new_df = new_df.merge(df3.rename(columns = {'Recnum':'Freq_cn_st_4d'}), on = ['Cardnum','Merch state','Date'])\n",
    "\n",
    "df3 = df.set_index('Date').groupby(['Cardnum','Merch state'])['Recnum'].rolling(window = '7D', closed = 'left').count().to_frame().reset_index().drop_duplicates(subset = ['Cardnum','Merch state','Date'],keep = 'first')\n",
    "new_df = new_df.merge(df3.rename(columns = {'Recnum':'Freq_cn_st_7d'}), on = ['Cardnum','Merch state','Date'])\n",
    "\n",
    "df3 = df.set_index('Date').groupby(['Cardnum','Merch state'])['Recnum'].rolling(window = '14D', closed = 'left').count().to_frame().reset_index().drop_duplicates(subset = ['Cardnum','Merch state','Date'],keep = 'first')\n",
    "new_df = new_df.merge(df3.rename(columns = {'Recnum':'Freq_cn_st_14d'}), on = ['Cardnum','Merch state','Date'])\n",
    "\n",
    "df3 = df.set_index('Date').groupby(['Cardnum','Merch state'])['Recnum'].rolling(window = '30D', closed = 'left').count().to_frame().reset_index().drop_duplicates(subset = ['Cardnum','Merch state','Date'],keep = 'first')\n",
    "new_df = new_df.merge(df3.rename(columns = {'Recnum':'Freq_cn_st_30d'}), on = ['Cardnum','Merch state','Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "165"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(new_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Days since expert variables\n",
    "df3 = df.set_index('Date').groupby(['Cardnum'])['Recnum'].rolling(window = '1D', closed = 'left').count().to_frame().reset_index().drop_duplicates(subset = ['Cardnum','Date'])\n",
    "df3['Date_lag'] = df3.groupby('Cardnum')['Date'].shift(1)\n",
    "df3['last_cn'] = (df3['Date'] - df3['Date_lag']).dt.days\n",
    "new_df = new_df.merge(df3[['Cardnum','Date','last_cn']])\n",
    "\n",
    "df3 = df.set_index('Date').groupby(['Merchnum'])['Recnum'].rolling(window = '1D', closed = 'left').count().to_frame().reset_index().drop_duplicates(subset = ['Merchnum','Date'])\n",
    "df3['Date_lag'] = df3.groupby('Merchnum')['Date'].shift(1)\n",
    "df3['last_mn'] = (df3['Date'] - df3['Date_lag']).dt.days\n",
    "new_df = new_df.merge(df3[['Merchnum','Date','last_mn']])\n",
    "\n",
    "df3 = df.set_index('Date').groupby(['Cardnum','Merchnum'])['Recnum'].rolling(window = '1D', closed = 'left').count().to_frame().reset_index().drop_duplicates(subset = ['Cardnum','Merchnum','Date'])\n",
    "df3['Date_lag'] = df3.groupby(['Cardnum','Merchnum'])['Date'].shift(1)\n",
    "df3['last_cn_mn'] = (df3['Date'] - df3['Date_lag']).dt.days\n",
    "new_df = new_df.merge(df3[['Cardnum','Merchnum','Date','last_cn_mn']])\n",
    "\n",
    "df3 = df.set_index('Date').groupby(['Cardnum','Merch zip'])['Recnum'].rolling(window = '1D', closed = 'left').count().to_frame().reset_index().drop_duplicates(subset = ['Cardnum','Merch zip','Date'])\n",
    "df3['Date_lag'] = df3.groupby(['Cardnum','Merch zip'])['Date'].shift(1)\n",
    "df3['last_cn_zip'] = (df3['Date'] - df3['Date_lag']).dt.days\n",
    "new_df = new_df.merge(df3[['Cardnum','Merch zip','Date','last_cn_zip']])\n",
    "\n",
    "df3 = df.set_index('Date').groupby(['Cardnum','Merch state'])['Recnum'].rolling(window = '1D', closed = 'left').count().to_frame().reset_index().drop_duplicates(subset = ['Cardnum','Merch state','Date'])\n",
    "df3['Date_lag'] = df3.groupby(['Cardnum','Merch state'])['Date'].shift(1)\n",
    "df3['last_cn_st'] = (df3['Date'] - df3['Date_lag']).dt.days\n",
    "new_df = new_df.merge(df3[['Cardnum','Merch state','Date','last_cn_st']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Recnum',\n",
       " 'Cardnum',\n",
       " 'Date',\n",
       " 'Merchnum',\n",
       " 'Merch description',\n",
       " 'Merch state',\n",
       " 'Merch zip',\n",
       " 'Transtype',\n",
       " 'Amount',\n",
       " 'Fraud',\n",
       " 'Amount_cn_actual',\n",
       " 'Amount_cn_1d_avg',\n",
       " 'Amount_cn_1d_sum',\n",
       " 'Amount_cn_1d_act-avg',\n",
       " 'Amount_cn_1d_act/avg',\n",
       " 'Amount_cn_1d_act/sum',\n",
       " 'Amount_cn_4d_avg',\n",
       " 'Amount_cn_4d_sum',\n",
       " 'Amount_cn_4d_act-avg',\n",
       " 'Amount_cn_4d_act/avg',\n",
       " 'Amount_cn_4d_act/sum',\n",
       " 'Amount_cn_7d_avg',\n",
       " 'Amount_cn_7d_sum',\n",
       " 'Amount_cn_7d_act-avg',\n",
       " 'Amount_cn_7d_act/avg',\n",
       " 'Amount_cn_7d_act/sum',\n",
       " 'Amount_cn_14d_avg',\n",
       " 'Amount_cn_14d_sum',\n",
       " 'Amount_cn_14d_act-avg',\n",
       " 'Amount_cn_14d_act/avg',\n",
       " 'Amount_cn_14d_act/sum',\n",
       " 'Amount_cn_30d_avg',\n",
       " 'Amount_cn_30d_sum',\n",
       " 'Amount_cn_30d_act-avg',\n",
       " 'Amount_cn_30d_act/avg',\n",
       " 'Amount_cn_30d_act/sum',\n",
       " 'Amount_mn_actual',\n",
       " 'Amount_mn_1d_avg',\n",
       " 'Amount_mn_1d_sum',\n",
       " 'Amount_mn_1d_act-avg',\n",
       " 'Amount_mn_1d_act/avg',\n",
       " 'Amount_mn_1d_act/sum',\n",
       " 'Amount_mn_4d_avg',\n",
       " 'Amount_mn_4d_sum',\n",
       " 'Amount_mn_4d_act-avg',\n",
       " 'Amount_mn_4d_act/avg',\n",
       " 'Amount_mn_4d_act/sum',\n",
       " 'Amount_mn_7d_avg',\n",
       " 'Amount_mn_7d_sum',\n",
       " 'Amount_mn_7d_act-avg',\n",
       " 'Amount_mn_7d_act/avg',\n",
       " 'Amount_mn_7d_act/sum',\n",
       " 'Amount_mn_14d_avg',\n",
       " 'Amount_mn_14d_sum',\n",
       " 'Amount_mn_14d_act-avg',\n",
       " 'Amount_mn_14d_act/avg',\n",
       " 'Amount_mn_14d_act/sum',\n",
       " 'Amount_mn_30d_avg',\n",
       " 'Amount_mn_30d_sum',\n",
       " 'Amount_mn_30d_act-avg',\n",
       " 'Amount_mn_30d_act/avg',\n",
       " 'Amount_mn_30d_act/sum',\n",
       " 'Amount_cn_mn_actual',\n",
       " 'Amount_cn_mn_1d_avg',\n",
       " 'Amount_cn_mn_1d_sum',\n",
       " 'Amount_cn_mn_1d_act-avg',\n",
       " 'Amount_cn_mn_1d_act/avg',\n",
       " 'Amount_cn_mn_1d_act/sum',\n",
       " 'Amount_cn_mn_4d_avg',\n",
       " 'Amount_cn_mn_4d_sum',\n",
       " 'Amount_cn_mn_4d_act-avg',\n",
       " 'Amount_cn_mn_4d_act/avg',\n",
       " 'Amount_cn_mn_4d_act/sum',\n",
       " 'Amount_cn_mn_7d_avg',\n",
       " 'Amount_cn_mn_7d_sum',\n",
       " 'Amount_cn_mn_7d_act-avg',\n",
       " 'Amount_cn_mn_7d_act/avg',\n",
       " 'Amount_cn_mn_7d_act/sum',\n",
       " 'Amount_cn_mn_14d_avg',\n",
       " 'Amount_cn_mn_14d_sum',\n",
       " 'Amount_cn_mn_14d_act-avg',\n",
       " 'Amount_cn_mn_14d_act/avg',\n",
       " 'Amount_cn_mn_14d_act/sum',\n",
       " 'Amount_cn_mn_30d_avg',\n",
       " 'Amount_cn_mn_30d_sum',\n",
       " 'Amount_cn_mn_30d_act-avg',\n",
       " 'Amount_cn_mn_30d_act/avg',\n",
       " 'Amount_cn_mn_30d_act/sum',\n",
       " 'Amount_cn_zip_actual',\n",
       " 'Amount_cn_zip_1d_avg',\n",
       " 'Amount_cn_zip_1d_sum',\n",
       " 'Amount_cn_zip_1d_act-avg',\n",
       " 'Amount_cn_zip_1d_act/avg',\n",
       " 'Amount_cn_zip_1d_act/sum',\n",
       " 'Amount_cn_zip_4d_avg',\n",
       " 'Amount_cn_zip_4d_sum',\n",
       " 'Amount_cn_zip_4d_act-avg',\n",
       " 'Amount_cn_zip_4d_act/avg',\n",
       " 'Amount_cn_zip_4d_act/sum',\n",
       " 'Amount_cn_zip_7d_avg',\n",
       " 'Amount_cn_zip_7d_sum',\n",
       " 'Amount_cn_zip_7d_act-avg',\n",
       " 'Amount_cn_zip_7d_act/avg',\n",
       " 'Amount_cn_zip_7d_act/sum',\n",
       " 'Amount_cn_zip_14d_avg',\n",
       " 'Amount_cn_zip_14d_sum',\n",
       " 'Amount_cn_zip_14d_act-avg',\n",
       " 'Amount_cn_zip_14d_act/avg',\n",
       " 'Amount_cn_zip_14d_act/sum',\n",
       " 'Amount_cn_zip_30d_avg',\n",
       " 'Amount_cn_zip_30d_sum',\n",
       " 'Amount_cn_zip_30d_act-avg',\n",
       " 'Amount_cn_zip_30d_act/avg',\n",
       " 'Amount_cn_zip_30d_act/sum',\n",
       " 'Amount_cn_st_actual',\n",
       " 'Amount_cn_st_1d_avg',\n",
       " 'Amount_cn_st_1d_sum',\n",
       " 'Amount_cn_st_1d_act-avg',\n",
       " 'Amount_cn_st_1d_act/avg',\n",
       " 'Amount_cn_st_1d_act/sum',\n",
       " 'Amount_cn_st_4d_avg',\n",
       " 'Amount_cn_st_4d_sum',\n",
       " 'Amount_cn_st_4d_act-avg',\n",
       " 'Amount_cn_st_4d_act/avg',\n",
       " 'Amount_cn_st_4d_act/sum',\n",
       " 'Amount_cn_st_7d_avg',\n",
       " 'Amount_cn_st_7d_sum',\n",
       " 'Amount_cn_st_7d_act-avg',\n",
       " 'Amount_cn_st_7d_act/avg',\n",
       " 'Amount_cn_st_7d_act/sum',\n",
       " 'Amount_cn_st_14d_avg',\n",
       " 'Amount_cn_st_14d_sum',\n",
       " 'Amount_cn_st_14d_act-avg',\n",
       " 'Amount_cn_st_14d_act/avg',\n",
       " 'Amount_cn_st_14d_act/sum',\n",
       " 'Amount_cn_st_30d_avg',\n",
       " 'Amount_cn_st_30d_sum',\n",
       " 'Amount_cn_st_30d_act-avg',\n",
       " 'Amount_cn_st_30d_act/avg',\n",
       " 'Amount_cn_st_30d_act/sum',\n",
       " 'Freq_cn_1d',\n",
       " 'Freq_cn_4d',\n",
       " 'Freq_cn_7d',\n",
       " 'Freq_cn_14d',\n",
       " 'Freq_cn_30d',\n",
       " 'Freq_mn_1d',\n",
       " 'Freq_mn_4d',\n",
       " 'Freq_mn_7d',\n",
       " 'Freq_mn_14d',\n",
       " 'Freq_mn_30d',\n",
       " 'Freq_cn_mn_1d',\n",
       " 'Freq_cn_mn_4d',\n",
       " 'Freq_cn_mn_7d',\n",
       " 'Freq_cn_mn_14d',\n",
       " 'Freq_cn_mn_30d',\n",
       " 'Freq_cn_zip_1d',\n",
       " 'Freq_cn_zip_4d',\n",
       " 'Freq_cn_zip_7d',\n",
       " 'Freq_cn_zip_14d',\n",
       " 'Freq_cn_zip_30d',\n",
       " 'Freq_cn_st_1d',\n",
       " 'Freq_cn_st_4d',\n",
       " 'Freq_cn_st_7d',\n",
       " 'Freq_cn_st_14d',\n",
       " 'Freq_cn_st_30d',\n",
       " 'last_cn',\n",
       " 'last_mn',\n",
       " 'last_cn_mn',\n",
       " 'last_cn_zip',\n",
       " 'last_cn_st']"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Velocity deviation\n",
    "new_df['velo_cn_avg7d'] = new_df['Freq_cn_1d']/(new_df['Freq_cn_7d']/7)\n",
    "new_df['velo_cn_avg14d'] = new_df['Freq_cn_1d']/(new_df['Freq_cn_14d']/14)\n",
    "new_df['velo_cn_avg30d'] = new_df['Freq_cn_1d']/(new_df['Freq_cn_30d']/30)\n",
    "new_df['velo_mn_avg7d'] = new_df['Freq_mn_1d']/(new_df['Freq_mn_7d']/7)\n",
    "new_df['velo_mn_avg14d'] = new_df['Freq_mn_1d']/(new_df['Freq_mn_14d']/14)\n",
    "new_df['velo_mn_avg30d'] = new_df['Freq_mn_1d']/(new_df['Freq_mn_30d']/30)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill na with 0\n",
    "new_df = new_df.fillna(0)\n",
    "\n",
    "# export amount expert variables\n",
    "new_df.to_csv('AmountVariables.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "176"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.tail()\n",
    "len(list(new_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_df = pd.read_csv('AmountVariables.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
