{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pandas import ExcelWriter\n",
    "import random\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import ks_2samp\n",
    "import random\n",
    "random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.4 s, sys: 287 ms, total: 15.7 s\n",
      "Wall time: 16 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = pd.read_excel('card transactions.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th># NaN</th>\n",
       "      <th>% populated</th>\n",
       "      <th># unique</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Recnum</td>\n",
       "      <td>0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>96753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cardnum</td>\n",
       "      <td>0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>1645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Date</td>\n",
       "      <td>0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Merchnum</td>\n",
       "      <td>3375</td>\n",
       "      <td>96.511736</td>\n",
       "      <td>13091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Merch description</td>\n",
       "      <td>0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>13126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Merch state</td>\n",
       "      <td>1195</td>\n",
       "      <td>98.764896</td>\n",
       "      <td>227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Merch zip</td>\n",
       "      <td>4656</td>\n",
       "      <td>95.187746</td>\n",
       "      <td>4567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Transtype</td>\n",
       "      <td>0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Amount</td>\n",
       "      <td>0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>34909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Fraud</td>\n",
       "      <td>0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            variable  # NaN  % populated # unique\n",
       "0             Recnum      0   100.000000    96753\n",
       "1            Cardnum      0   100.000000     1645\n",
       "2               Date      0   100.000000      365\n",
       "3           Merchnum   3375    96.511736    13091\n",
       "4  Merch description      0   100.000000    13126\n",
       "5        Merch state   1195    98.764896      227\n",
       "6          Merch zip   4656    95.187746     4567\n",
       "7          Transtype      0   100.000000        4\n",
       "8             Amount      0   100.000000    34909\n",
       "9              Fraud      0   100.000000        2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# summary\n",
    "numrecords = len(df)\n",
    "stat_df = pd.DataFrame(df.isnull().sum(axis = 0))\n",
    "stat_df = stat_df.reset_index().rename(columns = {'index':'variable', 0 :\"# NaN\"})\n",
    "stat_df[\"% populated\"] = (1 - stat_df[\"# NaN\"]/numrecords)*100\n",
    "stat_df[\"# unique\"] = ''\n",
    "\n",
    "for i in range(len(list(df))):\n",
    "    stat_df[\"# unique\"][i] = df[list(df)[i]].nunique()\n",
    "    \n",
    "stat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stat_df.to_excel('stat_df.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96397"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Identify any exclusions, bad records\n",
    "\n",
    "# Remove single large transaction outlier in Amount\n",
    "df = df[df['Amount']<3000000]\n",
    "\n",
    "# Remove all but P transaction type\n",
    "df = df[df['Transtype'] == 'P']\n",
    "\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1414"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --------------- Fill in NAs ----------\n",
    "\n",
    "### Merchnum \n",
    "# Transform 0 values into NA\n",
    "df.loc[df['Merchnum'] == '0', 'Merchnum'] = np.NaN\n",
    "\n",
    "# fill most frequenct merchnum using merch description\n",
    "dict1 = df.set_index('Merch description')['Merchnum'].to_dict()\n",
    "df['Merchnum'].fillna(df['Merch description'].map(dict1), inplace = True)\n",
    "\n",
    "# fill most frequenct merchnum in this zip\n",
    "dict1 = dict(zip(df['Merch zip'].dropna(), df['Merchnum']))\n",
    "df['Merchnum'].fillna(df['Merch zip'].map(dict1), inplace = True)\n",
    "\n",
    "pd.isnull(df['Merchnum']).sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3810"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Merch state and zip\n",
    "numrecords - (df['Merch state'].isna() == df['Merch zip'].isna()).sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "543"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Merch zip\n",
    "# df.groupby(['Merch description','Merch zip']).size()\n",
    "\n",
    "# fill NA in Merch zip using Merch description\n",
    "dict1 = df.set_index('Merch description')['Merch zip'].to_dict()\n",
    "df['Merch zip'].fillna(df['Merch description'].map(dict1), inplace = True)\n",
    "\n",
    "# fill NA in Merch zip using Merchnum\n",
    "dict1 = df.set_index('Merchnum')['Merch zip'].to_dict()\n",
    "df['Merch zip'].fillna(df['Merchnum'].map(dict1), inplace = True)\n",
    "\n",
    "# fill NA in Merch zip using Cardnum\n",
    "dict1 = df.set_index('Cardnum')['Merch zip'].to_dict()\n",
    "df['Merch zip'].fillna(df['Cardnum'].map(dict1), inplace = True)\n",
    "# It will automatically choose zip with highest frequency\n",
    "\n",
    "pd.isnull(df['Merch zip']).sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60108.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic = dict(zip(df['Cardnum'], df['Merch zip']))\n",
    "dic[5142310525]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "122"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Merch state\n",
    "# df.groupby(['Merch description','Merch state']).size()\n",
    "# Each Merch description has one matched state\n",
    "\n",
    "# fill NA in Merch state using Merch description\n",
    "dict1 = df.set_index('Merch description')['Merch state'].to_dict()\n",
    "df['Merch state'].fillna(df['Merch description'].map(dict1), inplace = True)\n",
    "\n",
    "# fill NA in Merch state using Merchnum\n",
    "dict1 = df.set_index('Merchnum')['Merch state'].to_dict()\n",
    "df['Merch state'].fillna(df['Merchnum'].map(dict1), inplace = True)\n",
    "\n",
    "# fill NA in Merch state using Merch zip\n",
    "\n",
    "dict1 = dict(zip(df['Merch zip'].dropna(), df['Merch state']))\n",
    "df['Merch state'].fillna(df['Merch zip'].map(dict1), inplace = True)\n",
    "\n",
    "# fill NA in Merch state using Cardnum\n",
    "dict1 = df.set_index('Cardnum')['Merch state'].to_dict()\n",
    "df['Merch state'].fillna(df['Cardnum'].map(dict1), inplace = True)\n",
    "\n",
    "pd.isnull(df['Merch state']).sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94631"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop remained NA in three variables\n",
    "df = df.dropna()\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.groupby(['Cardnum','Date'])['Amount'].value_counts()\n",
    "# df[df['Cardnum'] == 5142190439]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# --------------- Create variables ----------\n",
    "### Amount expert variables\n",
    "\n",
    "# Cardnum\n",
    "# sum the amount at the same day first and then rolling\n",
    "df2 = df.groupby(['Cardnum','Date'])['Amount'].sum().to_frame().reset_index().set_index('Date')\n",
    "new_df = df.join(df.groupby(['Cardnum','Date'])['Amount'].sum(),on = ['Cardnum','Date'], rsuffix = '_cn_actual')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (closed = 'left') in rolling function means when calculating past n days we exlude today's transactions\n",
    "\n",
    "def amount_mean_func(column, window, rsuffix):\n",
    "    dataframe = pd.DataFrame()\n",
    "    dataframe = new_df.join(df2.groupby([column])['Amount'].rolling(window = window, closed = 'left').mean(), on = [column,'Date'], rsuffix = rsuffix)\n",
    "    return dataframe\n",
    "\n",
    "# def amount_max_func(column, window, rsuffix):\n",
    "#     dataframe = pd.DataFrame()\n",
    "#     dataframe = new_df.join(df2.groupby([column])['Amount'].rolling(window = window).max(), on = [column,'Date'], rsuffix = rsuffix)\n",
    "#     return dataframe\n",
    "\n",
    "# def amount_median_func(column, window, rsuffix):\n",
    "#     dataframe = pd.DataFrame()\n",
    "#     dataframe = new_df.join(df2.groupby([column])['Amount'].rolling(window = window).median(), on = [column,'Date'], rsuffix = rsuffix)\n",
    "#     return dataframe\n",
    "\n",
    "def amount_sum_func(column, window, rsuffix):\n",
    "    dataframe = pd.DataFrame()\n",
    "    dataframe = new_df.join(df2.groupby([column])['Amount'].rolling(window = window, closed = 'left').sum(), on = [column,'Date'], rsuffix = rsuffix)\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.groupby(['Cardnum','Date'])['Amount'].sum().to_frame().reset_index().set_index('Date')\n",
    "new_df = df.join(df.groupby(['Cardnum','Date'])['Amount'].sum(),on = ['Cardnum','Date'], rsuffix = '_cn_actual')\n",
    "\n",
    "new_df = amount_mean_func(column = 'Cardnum',window = '1D',rsuffix = '_cn_1d_avg')\n",
    "# new_df = amount_max_func(column = 'Cardnum',window = '1D',rsuffix = '_cn_1d_max')\n",
    "# new_df = amount_median_func(column = 'Cardnum',window = '1D',rsuffix = '_cn_1d_median')\n",
    "new_df = amount_sum_func(column = 'Cardnum',window = '1D',rsuffix = '_cn_1d_sum')\n",
    "new_df['Amount_cn_1d_act-avg'] = new_df['Amount_cn_actual'] - new_df['Amount_cn_1d_avg']\n",
    "# new_df['Amount_cn_1d_act-median'] = new_df['Amount_cn_actual'] - new_df['Amount_cn_1d_median']\n",
    "new_df['Amount_cn_1d_act/avg'] = new_df['Amount_cn_actual']/new_df['Amount_cn_1d_avg']\n",
    "# new_df['Amount_cn_1d_act/max'] = new_df['Amount_cn_actual']/new_df['Amount_cn_1d_max']\n",
    "new_df['Amount_cn_1d_act/sum'] = new_df['Amount_cn_actual']/new_df['Amount_cn_1d_sum']\n",
    "# new_df['Amount_cn_1d_act/median'] = new_df['Amount_cn_actual']/new_df['Amount_cn_1d_median']\n",
    "\n",
    "new_df = amount_mean_func(column = 'Cardnum',window = '4D',rsuffix = '_cn_4d_avg')\n",
    "new_df = amount_sum_func(column = 'Cardnum',window = '4D',rsuffix = '_cn_4d_sum')\n",
    "new_df['Amount_cn_4d_act-avg'] = new_df['Amount_cn_actual'] - new_df['Amount_cn_4d_avg']\n",
    "new_df['Amount_cn_4d_act/avg'] = new_df['Amount_cn_actual']/new_df['Amount_cn_4d_avg']\n",
    "new_df['Amount_cn_4d_act/sum'] = new_df['Amount_cn_actual']/new_df['Amount_cn_4d_sum']\n",
    "\n",
    "new_df = amount_mean_func(column = 'Cardnum',window = '7D',rsuffix = '_cn_7d_avg')\n",
    "new_df = amount_sum_func(column = 'Cardnum',window = '7D',rsuffix = '_cn_7d_sum')\n",
    "new_df['Amount_cn_7d_act-avg'] = new_df['Amount_cn_actual'] - new_df['Amount_cn_7d_avg']\n",
    "new_df['Amount_cn_7d_act/avg'] = new_df['Amount_cn_actual']/new_df['Amount_cn_7d_avg']\n",
    "new_df['Amount_cn_7d_act/sum'] = new_df['Amount_cn_actual']/new_df['Amount_cn_7d_sum']\n",
    "\n",
    "new_df = amount_mean_func(column = 'Cardnum',window = '14D',rsuffix = '_cn_14d_avg')\n",
    "new_df = amount_sum_func(column = 'Cardnum',window = '14D',rsuffix = '_cn_14d_sum')\n",
    "new_df['Amount_cn_14d_act-avg'] = new_df['Amount_cn_actual'] - new_df['Amount_cn_14d_avg']\n",
    "new_df['Amount_cn_14d_act/avg'] = new_df['Amount_cn_actual']/new_df['Amount_cn_14d_avg']\n",
    "new_df['Amount_cn_14d_act/sum'] = new_df['Amount_cn_actual']/new_df['Amount_cn_14d_sum']\n",
    "\n",
    "new_df = amount_mean_func(column = 'Cardnum',window = '30D',rsuffix = '_cn_30d_avg')\n",
    "new_df = amount_sum_func(column = 'Cardnum',window = '30D',rsuffix = '_cn_30d_sum')\n",
    "new_df['Amount_cn_30d_act-avg'] = new_df['Amount_cn_actual'] - new_df['Amount_cn_30d_avg']\n",
    "new_df['Amount_cn_30d_act/avg'] = new_df['Amount_cn_actual']/new_df['Amount_cn_30d_avg']\n",
    "new_df['Amount_cn_30d_act/sum'] = new_df['Amount_cn_actual']/new_df['Amount_cn_30d_sum']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.groupby(['Merchnum','Date'])['Amount'].sum().to_frame().reset_index().set_index('Date')\n",
    "new_df = new_df.join(df.groupby(['Merchnum','Date'])['Amount'].sum(),on = ['Merchnum','Date'], rsuffix = '_mn_actual')\n",
    "\n",
    "new_df = amount_mean_func(column = 'Merchnum',window = '1D',rsuffix = '_mn_1d_avg')\n",
    "new_df = amount_sum_func(column = 'Merchnum',window = '1D',rsuffix = '_mn_1d_sum')\n",
    "new_df['Amount_mn_1d_act-avg'] = new_df['Amount_mn_actual'] - new_df['Amount_mn_1d_avg']\n",
    "new_df['Amount_mn_1d_act/avg'] = new_df['Amount_mn_actual']/new_df['Amount_mn_1d_avg']\n",
    "new_df['Amount_mn_1d_act/sum'] = new_df['Amount_mn_actual']/new_df['Amount_mn_1d_sum']\n",
    "\n",
    "new_df = amount_mean_func(column = 'Merchnum',window = '4D',rsuffix = '_mn_4d_avg')\n",
    "new_df = amount_sum_func(column = 'Merchnum',window = '4D',rsuffix = '_mn_4d_sum')\n",
    "new_df['Amount_mn_4d_act-avg'] = new_df['Amount_mn_actual'] - new_df['Amount_mn_4d_avg']\n",
    "new_df['Amount_mn_4d_act/avg'] = new_df['Amount_mn_actual']/new_df['Amount_mn_4d_avg']\n",
    "new_df['Amount_mn_4d_act/sum'] = new_df['Amount_mn_actual']/new_df['Amount_mn_4d_sum']\n",
    "\n",
    "new_df = amount_mean_func(column = 'Merchnum',window = '7D',rsuffix = '_mn_7d_avg')\n",
    "new_df = amount_sum_func(column = 'Merchnum',window = '7D',rsuffix = '_mn_7d_sum')\n",
    "new_df['Amount_mn_7d_act-avg'] = new_df['Amount_mn_actual'] - new_df['Amount_mn_7d_avg']\n",
    "new_df['Amount_mn_7d_act/avg'] = new_df['Amount_mn_actual']/new_df['Amount_mn_7d_avg']\n",
    "new_df['Amount_mn_7d_act/sum'] = new_df['Amount_mn_actual']/new_df['Amount_mn_7d_sum']\n",
    "\n",
    "new_df = amount_mean_func(column = 'Merchnum',window = '14D',rsuffix = '_mn_14d_avg')\n",
    "new_df = amount_sum_func(column = 'Merchnum',window = '14D',rsuffix = '_mn_14d_sum')\n",
    "new_df['Amount_mn_14d_act-avg'] = new_df['Amount_mn_actual'] - new_df['Amount_mn_14d_avg']\n",
    "new_df['Amount_mn_14d_act/avg'] = new_df['Amount_mn_actual']/new_df['Amount_mn_14d_avg']\n",
    "new_df['Amount_mn_14d_act/sum'] = new_df['Amount_mn_actual']/new_df['Amount_mn_14d_sum']\n",
    "\n",
    "new_df = amount_mean_func(column = 'Merchnum',window = '30D',rsuffix = '_mn_30d_avg')\n",
    "new_df = amount_sum_func(column = 'Merchnum',window = '30D',rsuffix = '_mn_30d_sum')\n",
    "new_df['Amount_mn_30d_act-avg'] = new_df['Amount_mn_actual'] - new_df['Amount_mn_30d_avg']\n",
    "new_df['Amount_mn_30d_act/avg'] = new_df['Amount_mn_actual']/new_df['Amount_mn_30d_avg']\n",
    "new_df['Amount_mn_30d_act/sum'] = new_df['Amount_mn_actual']/new_df['Amount_mn_30d_sum']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.groupby(['Cardnum','Merchnum','Date'])['Amount'].sum().to_frame().reset_index().set_index('Date')\n",
    "new_df = new_df.join(df.groupby(['Cardnum','Merchnum','Date'])['Amount'].sum(),on = ['Cardnum','Merchnum','Date'], rsuffix = '_cn_mn_actual')\n",
    "\n",
    "new_df = new_df.join(df2.groupby(['Cardnum','Merchnum'])['Amount'].rolling(window = '1D', closed = 'left').mean(), on = ['Cardnum','Merchnum','Date'], rsuffix = '_cn_mn_1d_avg')\n",
    "new_df = new_df.join(df2.groupby(['Cardnum','Merchnum'])['Amount'].rolling(window = '1D', closed = 'left').sum(), on = ['Cardnum','Merchnum','Date'], rsuffix = '_cn_mn_1d_sum')\n",
    "new_df['Amount_cn_mn_1d_act-avg'] = new_df['Amount_cn_mn_actual'] - new_df['Amount_cn_mn_1d_avg']\n",
    "new_df['Amount_cn_mn_1d_act/avg'] = new_df['Amount_cn_mn_actual']/new_df['Amount_cn_mn_1d_avg']\n",
    "new_df['Amount_cn_mn_1d_act/sum'] = new_df['Amount_cn_mn_actual']/new_df['Amount_cn_mn_1d_sum']\n",
    "\n",
    "new_df = new_df.join(df2.groupby(['Cardnum','Merchnum'])['Amount'].rolling(window = '4D', closed = 'left').mean(), on = ['Cardnum','Merchnum','Date'], rsuffix = '_cn_mn_4d_avg')\n",
    "new_df = new_df.join(df2.groupby(['Cardnum','Merchnum'])['Amount'].rolling(window = '4D', closed = 'left').sum(), on = ['Cardnum','Merchnum','Date'], rsuffix = '_cn_mn_4d_sum')\n",
    "new_df['Amount_cn_mn_4d_act-avg'] = new_df['Amount_cn_mn_actual'] - new_df['Amount_cn_mn_4d_avg']\n",
    "new_df['Amount_cn_mn_4d_act/avg'] = new_df['Amount_cn_mn_actual']/new_df['Amount_cn_mn_4d_avg']\n",
    "new_df['Amount_cn_mn_4d_act/sum'] = new_df['Amount_cn_mn_actual']/new_df['Amount_cn_mn_4d_sum']\n",
    "\n",
    "new_df = new_df.join(df2.groupby(['Cardnum','Merchnum'])['Amount'].rolling(window = '7D', closed = 'left').mean(), on = ['Cardnum','Merchnum','Date'], rsuffix = '_cn_mn_7d_avg')\n",
    "new_df = new_df.join(df2.groupby(['Cardnum','Merchnum'])['Amount'].rolling(window = '7D', closed = 'left').sum(), on = ['Cardnum','Merchnum','Date'], rsuffix = '_cn_mn_7d_sum')\n",
    "new_df['Amount_cn_mn_7d_act-avg'] = new_df['Amount_cn_mn_actual'] - new_df['Amount_cn_mn_7d_avg']\n",
    "new_df['Amount_cn_mn_7d_act/avg'] = new_df['Amount_cn_mn_actual']/new_df['Amount_cn_mn_7d_avg']\n",
    "new_df['Amount_cn_mn_7d_act/sum'] = new_df['Amount_cn_mn_actual']/new_df['Amount_cn_mn_7d_sum']\n",
    "\n",
    "new_df = new_df.join(df2.groupby(['Cardnum','Merchnum'])['Amount'].rolling(window = '14D', closed = 'left').mean(), on = ['Cardnum','Merchnum','Date'], rsuffix = '_cn_mn_14d_avg')\n",
    "new_df = new_df.join(df2.groupby(['Cardnum','Merchnum'])['Amount'].rolling(window = '14D', closed = 'left').sum(), on = ['Cardnum','Merchnum','Date'], rsuffix = '_cn_mn_14d_sum')\n",
    "new_df['Amount_cn_mn_14d_act-avg'] = new_df['Amount_cn_mn_actual'] - new_df['Amount_cn_mn_14d_avg']\n",
    "new_df['Amount_cn_mn_14d_act/avg'] = new_df['Amount_cn_mn_actual']/new_df['Amount_cn_mn_14d_avg']\n",
    "new_df['Amount_cn_mn_14d_act/sum'] = new_df['Amount_cn_mn_actual']/new_df['Amount_cn_mn_14d_sum']\n",
    "\n",
    "new_df = new_df.join(df2.groupby(['Cardnum','Merchnum'])['Amount'].rolling(window = '30D', closed = 'left').mean(), on = ['Cardnum','Merchnum','Date'], rsuffix = '_cn_mn_30d_avg')\n",
    "new_df = new_df.join(df2.groupby(['Cardnum','Merchnum'])['Amount'].rolling(window = '30D', closed = 'left').sum(), on = ['Cardnum','Merchnum','Date'], rsuffix = '_cn_mn_30d_sum')\n",
    "new_df['Amount_cn_mn_30d_act-avg'] = new_df['Amount_cn_mn_actual'] - new_df['Amount_cn_mn_30d_avg']\n",
    "new_df['Amount_cn_mn_30d_act/avg'] = new_df['Amount_cn_mn_actual']/new_df['Amount_cn_mn_30d_avg']\n",
    "new_df['Amount_cn_mn_30d_act/sum'] = new_df['Amount_cn_mn_actual']/new_df['Amount_cn_mn_30d_sum']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.groupby(['Cardnum','Merch zip','Date'])['Amount'].sum().to_frame().reset_index().set_index('Date')\n",
    "new_df = new_df.join(df.groupby(['Cardnum','Merch zip','Date'])['Amount'].sum(),on = ['Cardnum','Merch zip','Date'], rsuffix = '_cn_zip_actual')\n",
    "\n",
    "new_df = new_df.join(df2.groupby(['Cardnum','Merch zip'])['Amount'].rolling(window = '1D', closed = 'left').mean(), on = ['Cardnum','Merch zip','Date'], rsuffix = '_cn_zip_1d_avg')\n",
    "new_df = new_df.join(df2.groupby(['Cardnum','Merch zip'])['Amount'].rolling(window = '1D', closed = 'left').sum(), on = ['Cardnum','Merch zip','Date'], rsuffix = '_cn_zip_1d_sum')\n",
    "new_df['Amount_cn_zip_1d_act-avg'] = new_df['Amount_cn_zip_actual'] - new_df['Amount_cn_zip_1d_avg']\n",
    "new_df['Amount_cn_zip_1d_act/avg'] = new_df['Amount_cn_zip_actual']/new_df['Amount_cn_zip_1d_avg']\n",
    "new_df['Amount_cn_zip_1d_act/sum'] = new_df['Amount_cn_zip_actual']/new_df['Amount_cn_zip_1d_sum']\n",
    "\n",
    "new_df = new_df.join(df2.groupby(['Cardnum','Merch zip'])['Amount'].rolling(window = '4D', closed = 'left').mean(), on = ['Cardnum','Merch zip','Date'], rsuffix = '_cn_zip_4d_avg')\n",
    "new_df = new_df.join(df2.groupby(['Cardnum','Merch zip'])['Amount'].rolling(window = '4D', closed = 'left').sum(), on = ['Cardnum','Merch zip','Date'], rsuffix = '_cn_zip_4d_sum')\n",
    "new_df['Amount_cn_zip_4d_act-avg'] = new_df['Amount_cn_zip_actual'] - new_df['Amount_cn_zip_4d_avg']\n",
    "new_df['Amount_cn_zip_4d_act/avg'] = new_df['Amount_cn_zip_actual']/new_df['Amount_cn_zip_4d_avg']\n",
    "new_df['Amount_cn_zip_4d_act/sum'] = new_df['Amount_cn_zip_actual']/new_df['Amount_cn_zip_4d_sum']\n",
    "\n",
    "new_df = new_df.join(df2.groupby(['Cardnum','Merch zip'])['Amount'].rolling(window = '7D', closed = 'left').mean(), on = ['Cardnum','Merch zip','Date'], rsuffix = '_cn_zip_7d_avg')\n",
    "new_df = new_df.join(df2.groupby(['Cardnum','Merch zip'])['Amount'].rolling(window = '7D', closed = 'left').sum(), on = ['Cardnum','Merch zip','Date'], rsuffix = '_cn_zip_7d_sum')\n",
    "new_df['Amount_cn_zip_7d_act-avg'] = new_df['Amount_cn_zip_actual'] - new_df['Amount_cn_zip_7d_avg']\n",
    "new_df['Amount_cn_zip_7d_act/avg'] = new_df['Amount_cn_zip_actual']/new_df['Amount_cn_zip_7d_avg']\n",
    "new_df['Amount_cn_zip_7d_act/sum'] = new_df['Amount_cn_zip_actual']/new_df['Amount_cn_zip_7d_sum']\n",
    "\n",
    "new_df = new_df.join(df2.groupby(['Cardnum','Merch zip'])['Amount'].rolling(window = '14D', closed = 'left').mean(), on = ['Cardnum','Merch zip','Date'], rsuffix = '_cn_zip_14d_avg')\n",
    "new_df = new_df.join(df2.groupby(['Cardnum','Merch zip'])['Amount'].rolling(window = '14D', closed = 'left').sum(), on = ['Cardnum','Merch zip','Date'], rsuffix = '_cn_zip_14d_sum')\n",
    "new_df['Amount_cn_zip_14d_act-avg'] = new_df['Amount_cn_zip_actual'] - new_df['Amount_cn_zip_14d_avg']\n",
    "new_df['Amount_cn_zip_14d_act/avg'] = new_df['Amount_cn_zip_actual']/new_df['Amount_cn_zip_14d_avg']\n",
    "new_df['Amount_cn_zip_14d_act/sum'] = new_df['Amount_cn_zip_actual']/new_df['Amount_cn_zip_14d_sum']\n",
    "\n",
    "new_df = new_df.join(df2.groupby(['Cardnum','Merch zip'])['Amount'].rolling(window = '30D', closed = 'left').mean(), on = ['Cardnum','Merch zip','Date'], rsuffix = '_cn_zip_30d_avg')\n",
    "new_df = new_df.join(df2.groupby(['Cardnum','Merch zip'])['Amount'].rolling(window = '30D', closed = 'left').sum(), on = ['Cardnum','Merch zip','Date'], rsuffix = '_cn_zip_30d_sum')\n",
    "new_df['Amount_cn_zip_30d_act-avg'] = new_df['Amount_cn_zip_actual'] - new_df['Amount_cn_zip_30d_avg']\n",
    "new_df['Amount_cn_zip_30d_act/avg'] = new_df['Amount_cn_zip_actual']/new_df['Amount_cn_zip_30d_avg']\n",
    "new_df['Amount_cn_zip_30d_act/sum'] = new_df['Amount_cn_zip_actual']/new_df['Amount_cn_zip_30d_sum']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.groupby(['Cardnum','Merch state','Date'])['Amount'].sum().to_frame().reset_index().set_index('Date')\n",
    "new_df = new_df.join(df.groupby(['Cardnum','Merch state','Date'])['Amount'].sum(),on = ['Cardnum','Merch state','Date'], rsuffix = '_cn_st_actual')\n",
    "\n",
    "new_df = new_df.join(df2.groupby(['Cardnum','Merch state'])['Amount'].rolling(window = '1D', closed = 'left').mean(), on = ['Cardnum','Merch state','Date'], rsuffix = '_cn_st_1d_avg')\n",
    "new_df = new_df.join(df2.groupby(['Cardnum','Merch state'])['Amount'].rolling(window = '1D', closed = 'left').sum(), on = ['Cardnum','Merch state','Date'], rsuffix = '_cn_st_1d_sum')\n",
    "new_df['Amount_cn_st_1d_act-avg'] = new_df['Amount_cn_st_actual'] - new_df['Amount_cn_st_1d_avg']\n",
    "new_df['Amount_cn_st_1d_act/avg'] = new_df['Amount_cn_st_actual']/new_df['Amount_cn_st_1d_avg']\n",
    "new_df['Amount_cn_st_1d_act/sum'] = new_df['Amount_cn_st_actual']/new_df['Amount_cn_st_1d_sum']\n",
    "\n",
    "new_df = new_df.join(df2.groupby(['Cardnum','Merch state'])['Amount'].rolling(window = '4D', closed = 'left').mean(), on = ['Cardnum','Merch state','Date'], rsuffix = '_cn_st_4d_avg')\n",
    "new_df = new_df.join(df2.groupby(['Cardnum','Merch state'])['Amount'].rolling(window = '4D', closed = 'left').sum(), on = ['Cardnum','Merch state','Date'], rsuffix = '_cn_st_4d_sum')\n",
    "new_df['Amount_cn_st_4d_act-avg'] = new_df['Amount_cn_st_actual'] - new_df['Amount_cn_st_4d_avg']\n",
    "new_df['Amount_cn_st_4d_act/avg'] = new_df['Amount_cn_st_actual']/new_df['Amount_cn_st_4d_avg']\n",
    "new_df['Amount_cn_st_4d_act/sum'] = new_df['Amount_cn_st_actual']/new_df['Amount_cn_st_4d_sum']\n",
    "\n",
    "new_df = new_df.join(df2.groupby(['Cardnum','Merch state'])['Amount'].rolling(window = '7D', closed = 'left').mean(), on = ['Cardnum','Merch state','Date'], rsuffix = '_cn_st_7d_avg')\n",
    "new_df = new_df.join(df2.groupby(['Cardnum','Merch state'])['Amount'].rolling(window = '7D', closed = 'left').sum(), on = ['Cardnum','Merch state','Date'], rsuffix = '_cn_st_7d_sum')\n",
    "new_df['Amount_cn_st_7d_act-avg'] = new_df['Amount_cn_st_actual'] - new_df['Amount_cn_st_7d_avg']\n",
    "new_df['Amount_cn_st_7d_act/avg'] = new_df['Amount_cn_st_actual']/new_df['Amount_cn_st_7d_avg']\n",
    "new_df['Amount_cn_st_7d_act/sum'] = new_df['Amount_cn_st_actual']/new_df['Amount_cn_st_7d_sum']\n",
    "\n",
    "new_df = new_df.join(df2.groupby(['Cardnum','Merch state'])['Amount'].rolling(window = '14D', closed = 'left').mean(), on = ['Cardnum','Merch state','Date'], rsuffix = '_cn_st_14d_avg')\n",
    "new_df = new_df.join(df2.groupby(['Cardnum','Merch state'])['Amount'].rolling(window = '14D', closed = 'left').sum(), on = ['Cardnum','Merch state','Date'], rsuffix = '_cn_st_14d_sum')\n",
    "new_df['Amount_cn_st_14d_act-avg'] = new_df['Amount_cn_st_actual'] - new_df['Amount_cn_st_14d_avg']\n",
    "new_df['Amount_cn_st_14d_act/avg'] = new_df['Amount_cn_st_actual']/new_df['Amount_cn_st_14d_avg']\n",
    "new_df['Amount_cn_st_14d_act/sum'] = new_df['Amount_cn_st_actual']/new_df['Amount_cn_st_14d_sum']\n",
    "\n",
    "new_df = new_df.join(df2.groupby(['Cardnum','Merch state'])['Amount'].rolling(window = '30D', closed = 'left').mean(), on = ['Cardnum','Merch state','Date'], rsuffix = '_cn_st_30d_avg')\n",
    "new_df = new_df.join(df2.groupby(['Cardnum','Merch state'])['Amount'].rolling(window = '30D', closed = 'left').sum(), on = ['Cardnum','Merch state','Date'], rsuffix = '_cn_st_30d_sum')\n",
    "new_df['Amount_cn_st_30d_act-avg'] = new_df['Amount_cn_st_actual'] - new_df['Amount_cn_st_30d_avg']\n",
    "new_df['Amount_cn_st_30d_act/avg'] = new_df['Amount_cn_st_actual']/new_df['Amount_cn_st_30d_avg']\n",
    "new_df['Amount_cn_st_30d_act/sum'] = new_df['Amount_cn_st_actual']/new_df['Amount_cn_st_30d_sum']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### frequency variables\n",
    "new_df['Date'] = new_df['Date'].astype('datetime64[ns]')\n",
    "\n",
    "# Cardnum\n",
    "df3 = df.set_index('Date').groupby(['Cardnum'])['Recnum'].rolling(window = '1D', closed = 'left').count().to_frame().reset_index().drop_duplicates(subset = ['Cardnum','Date'],keep = 'first')\n",
    "new_df = new_df.merge(df3.rename(columns = {'Recnum':'Freq_cn_1d'}), on = ['Cardnum','Date'])\n",
    "\n",
    "df3 = df.set_index('Date').groupby(['Cardnum'])['Recnum'].rolling(window = '4D', closed = 'left').count().to_frame().reset_index().drop_duplicates(subset = ['Cardnum','Date'],keep = 'first')\n",
    "new_df = new_df.merge(df3.rename(columns = {'Recnum':'Freq_cn_4d'}), on = ['Cardnum','Date'])\n",
    "\n",
    "df3 = df.set_index('Date').groupby(['Cardnum'])['Recnum'].rolling(window = '7D', closed = 'left').count().to_frame().reset_index().drop_duplicates(subset = ['Cardnum','Date'],keep = 'first')\n",
    "new_df = new_df.merge(df3.rename(columns = {'Recnum':'Freq_cn_7d'}), on = ['Cardnum','Date'])\n",
    "\n",
    "df3 = df.set_index('Date').groupby(['Cardnum'])['Recnum'].rolling(window = '14D', closed = 'left').count().to_frame().reset_index().drop_duplicates(subset = ['Cardnum','Date'],keep = 'first')\n",
    "new_df = new_df.merge(df3.rename(columns = {'Recnum':'Freq_cn_14d'}), on = ['Cardnum','Date'])\n",
    "\n",
    "df3 = df.set_index('Date').groupby(['Cardnum'])['Recnum'].rolling(window = '30D', closed = 'left').count().to_frame().reset_index().drop_duplicates(subset = ['Cardnum','Date'],keep = 'first')\n",
    "new_df = new_df.merge(df3.rename(columns = {'Recnum':'Freq_cn_30d'}), on = ['Cardnum','Date'])\n",
    "\n",
    "# Merchnum\n",
    "df3 = df.set_index('Date').groupby(['Merchnum'])['Recnum'].rolling(window = '1D', closed = 'left').count().to_frame().reset_index().drop_duplicates(subset = ['Merchnum','Date'],keep = 'first')\n",
    "new_df = new_df.merge(df3.rename(columns = {'Recnum':'Freq_mn_1d'}), on = ['Merchnum','Date'])\n",
    "\n",
    "df3 = df.set_index('Date').groupby(['Merchnum'])['Recnum'].rolling(window = '4D', closed = 'left').count().to_frame().reset_index().drop_duplicates(subset = ['Merchnum','Date'],keep = 'first')\n",
    "new_df = new_df.merge(df3.rename(columns = {'Recnum':'Freq_mn_4d'}), on = ['Merchnum','Date'])\n",
    "\n",
    "df3 = df.set_index('Date').groupby(['Merchnum'])['Recnum'].rolling(window = '7D', closed = 'left').count().to_frame().reset_index().drop_duplicates(subset = ['Merchnum','Date'],keep = 'first')\n",
    "new_df = new_df.merge(df3.rename(columns = {'Recnum':'Freq_mn_7d'}), on = ['Merchnum','Date'])\n",
    "\n",
    "df3 = df.set_index('Date').groupby(['Merchnum'])['Recnum'].rolling(window = '14D', closed = 'left').count().to_frame().reset_index().drop_duplicates(subset = ['Merchnum','Date'],keep = 'first')\n",
    "new_df = new_df.merge(df3.rename(columns = {'Recnum':'Freq_mn_14d'}), on = ['Merchnum','Date'])\n",
    "\n",
    "df3 = df.set_index('Date').groupby(['Merchnum'])['Recnum'].rolling(window = '30D', closed = 'left').count().to_frame().reset_index().drop_duplicates(subset = ['Merchnum','Date'],keep = 'first')\n",
    "new_df = new_df.merge(df3.rename(columns = {'Recnum':'Freq_mn_30d'}), on = ['Merchnum','Date'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cardnum & Merchnum\n",
    "df3 = df.set_index('Date').groupby(['Cardnum','Merchnum'])['Recnum'].rolling(window = '1D', closed = 'left').count().to_frame().reset_index().drop_duplicates(subset = ['Cardnum','Merchnum','Date'],keep = 'first')\n",
    "new_df = new_df.merge(df3.rename(columns = {'Recnum':'Freq_cn_mn_1d'}), on = ['Cardnum','Merchnum','Date'])\n",
    "\n",
    "df3 = df.set_index('Date').groupby(['Cardnum','Merchnum'])['Recnum'].rolling(window = '4D', closed = 'left').count().to_frame().reset_index().drop_duplicates(subset = ['Cardnum','Merchnum','Date'],keep = 'first')\n",
    "new_df = new_df.merge(df3.rename(columns = {'Recnum':'Freq_cn_mn_4d'}), on = ['Cardnum','Merchnum','Date'])\n",
    "\n",
    "df3 = df.set_index('Date').groupby(['Cardnum','Merchnum'])['Recnum'].rolling(window = '7D', closed = 'left').count().to_frame().reset_index().drop_duplicates(subset = ['Cardnum','Merchnum','Date'],keep = 'first')\n",
    "new_df = new_df.merge(df3.rename(columns = {'Recnum':'Freq_cn_mn_7d'}), on = ['Cardnum','Merchnum','Date'])\n",
    "\n",
    "df3 = df.set_index('Date').groupby(['Cardnum','Merchnum'])['Recnum'].rolling(window = '14D', closed = 'left').count().to_frame().reset_index().drop_duplicates(subset = ['Cardnum','Merchnum','Date'],keep = 'first')\n",
    "new_df = new_df.merge(df3.rename(columns = {'Recnum':'Freq_cn_mn_14d'}), on = ['Cardnum','Merchnum','Date'])\n",
    "\n",
    "df3 = df.set_index('Date').groupby(['Cardnum','Merchnum'])['Recnum'].rolling(window = '30D', closed = 'left').count().to_frame().reset_index().drop_duplicates(subset = ['Cardnum','Merchnum','Date'],keep = 'first')\n",
    "new_df = new_df.merge(df3.rename(columns = {'Recnum':'Freq_cn_mn_30d'}), on = ['Cardnum','Merchnum','Date'])\n",
    "\n",
    "# Cardnum & Merch zip\n",
    "df3 = df.set_index('Date').groupby(['Cardnum','Merch zip'])['Recnum'].rolling(window = '1D', closed = 'left').count().to_frame().reset_index().drop_duplicates(subset = ['Cardnum','Merch zip','Date'],keep = 'first')\n",
    "new_df = new_df.merge(df3.rename(columns = {'Recnum':'Freq_cn_zip_1d'}), on = ['Cardnum','Merch zip','Date'])\n",
    "\n",
    "df3 = df.set_index('Date').groupby(['Cardnum','Merch zip'])['Recnum'].rolling(window = '4D', closed = 'left').count().to_frame().reset_index().drop_duplicates(subset = ['Cardnum','Merch zip','Date'],keep = 'first')\n",
    "new_df = new_df.merge(df3.rename(columns = {'Recnum':'Freq_cn_zip_4d'}), on = ['Cardnum','Merch zip','Date'])\n",
    "\n",
    "df3 = df.set_index('Date').groupby(['Cardnum','Merch zip'])['Recnum'].rolling(window = '7D', closed = 'left').count().to_frame().reset_index().drop_duplicates(subset = ['Cardnum','Merch zip','Date'],keep = 'first')\n",
    "new_df = new_df.merge(df3.rename(columns = {'Recnum':'Freq_cn_zip_7d'}), on = ['Cardnum','Merch zip','Date'])\n",
    "\n",
    "df3 = df.set_index('Date').groupby(['Cardnum','Merch zip'])['Recnum'].rolling(window = '14D', closed = 'left').count().to_frame().reset_index().drop_duplicates(subset = ['Cardnum','Merch zip','Date'],keep = 'first')\n",
    "new_df = new_df.merge(df3.rename(columns = {'Recnum':'Freq_cn_zip_14d'}), on = ['Cardnum','Merch zip','Date'])\n",
    "\n",
    "df3 = df.set_index('Date').groupby(['Cardnum','Merch zip'])['Recnum'].rolling(window = '30D', closed = 'left').count().to_frame().reset_index().drop_duplicates(subset = ['Cardnum','Merch zip','Date'],keep = 'first')\n",
    "new_df = new_df.merge(df3.rename(columns = {'Recnum':'Freq_cn_zip_30d'}), on = ['Cardnum','Merch zip','Date'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cardnum & Merch state\n",
    "df3 = df.set_index('Date').groupby(['Cardnum','Merch state'])['Recnum'].rolling(window = '1D', closed = 'left').count().to_frame().reset_index().drop_duplicates(subset = ['Cardnum','Merch state','Date'],keep = 'first')\n",
    "new_df = new_df.merge(df3.rename(columns = {'Recnum':'Freq_cn_st_1d'}), on = ['Cardnum','Merch state','Date'])\n",
    "\n",
    "df3 = df.set_index('Date').groupby(['Cardnum','Merch state'])['Recnum'].rolling(window = '4D', closed = 'left').count().to_frame().reset_index().drop_duplicates(subset = ['Cardnum','Merch state','Date'],keep = 'first')\n",
    "new_df = new_df.merge(df3.rename(columns = {'Recnum':'Freq_cn_st_4d'}), on = ['Cardnum','Merch state','Date'])\n",
    "\n",
    "df3 = df.set_index('Date').groupby(['Cardnum','Merch state'])['Recnum'].rolling(window = '7D', closed = 'left').count().to_frame().reset_index().drop_duplicates(subset = ['Cardnum','Merch state','Date'],keep = 'first')\n",
    "new_df = new_df.merge(df3.rename(columns = {'Recnum':'Freq_cn_st_7d'}), on = ['Cardnum','Merch state','Date'])\n",
    "\n",
    "df3 = df.set_index('Date').groupby(['Cardnum','Merch state'])['Recnum'].rolling(window = '14D', closed = 'left').count().to_frame().reset_index().drop_duplicates(subset = ['Cardnum','Merch state','Date'],keep = 'first')\n",
    "new_df = new_df.merge(df3.rename(columns = {'Recnum':'Freq_cn_st_14d'}), on = ['Cardnum','Merch state','Date'])\n",
    "\n",
    "df3 = df.set_index('Date').groupby(['Cardnum','Merch state'])['Recnum'].rolling(window = '30D', closed = 'left').count().to_frame().reset_index().drop_duplicates(subset = ['Cardnum','Merch state','Date'],keep = 'first')\n",
    "new_df = new_df.merge(df3.rename(columns = {'Recnum':'Freq_cn_st_30d'}), on = ['Cardnum','Merch state','Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "165"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(new_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Days since expert variables\n",
    "df3 = df.set_index('Date').groupby(['Cardnum'])['Recnum'].rolling(window = '1D', closed = 'left').count().to_frame().reset_index().drop_duplicates(subset = ['Cardnum','Date'])\n",
    "df3['Date_lag'] = df3.groupby('Cardnum')['Date'].shift(1)\n",
    "df3['last_cn'] = (df3['Date'] - df3['Date_lag']).dt.days\n",
    "new_df = new_df.merge(df3[['Cardnum','Date','last_cn']])\n",
    "\n",
    "df3 = df.set_index('Date').groupby(['Merchnum'])['Recnum'].rolling(window = '1D', closed = 'left').count().to_frame().reset_index().drop_duplicates(subset = ['Merchnum','Date'])\n",
    "df3['Date_lag'] = df3.groupby('Merchnum')['Date'].shift(1)\n",
    "df3['last_mn'] = (df3['Date'] - df3['Date_lag']).dt.days\n",
    "new_df = new_df.merge(df3[['Merchnum','Date','last_mn']])\n",
    "\n",
    "df3 = df.set_index('Date').groupby(['Cardnum','Merchnum'])['Recnum'].rolling(window = '1D', closed = 'left').count().to_frame().reset_index().drop_duplicates(subset = ['Cardnum','Merchnum','Date'])\n",
    "df3['Date_lag'] = df3.groupby(['Cardnum','Merchnum'])['Date'].shift(1)\n",
    "df3['last_cn_mn'] = (df3['Date'] - df3['Date_lag']).dt.days\n",
    "new_df = new_df.merge(df3[['Cardnum','Merchnum','Date','last_cn_mn']])\n",
    "\n",
    "df3 = df.set_index('Date').groupby(['Cardnum','Merch zip'])['Recnum'].rolling(window = '1D', closed = 'left').count().to_frame().reset_index().drop_duplicates(subset = ['Cardnum','Merch zip','Date'])\n",
    "df3['Date_lag'] = df3.groupby(['Cardnum','Merch zip'])['Date'].shift(1)\n",
    "df3['last_cn_zip'] = (df3['Date'] - df3['Date_lag']).dt.days\n",
    "new_df = new_df.merge(df3[['Cardnum','Merch zip','Date','last_cn_zip']])\n",
    "\n",
    "df3 = df.set_index('Date').groupby(['Cardnum','Merch state'])['Recnum'].rolling(window = '1D', closed = 'left').count().to_frame().reset_index().drop_duplicates(subset = ['Cardnum','Merch state','Date'])\n",
    "df3['Date_lag'] = df3.groupby(['Cardnum','Merch state'])['Date'].shift(1)\n",
    "df3['last_cn_st'] = (df3['Date'] - df3['Date_lag']).dt.days\n",
    "new_df = new_df.merge(df3[['Cardnum','Merch state','Date','last_cn_st']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Velocity deviation\n",
    "new_df['velo_cn_avg7d'] = new_df['Freq_cn_1d']/(new_df['Freq_cn_7d']/7)\n",
    "new_df['velo_cn_avg14d'] = new_df['Freq_cn_1d']/(new_df['Freq_cn_14d']/14)\n",
    "new_df['velo_cn_avg30d'] = new_df['Freq_cn_1d']/(new_df['Freq_cn_30d']/30)\n",
    "new_df['velo_mn_avg7d'] = new_df['Freq_mn_1d']/(new_df['Freq_mn_7d']/7)\n",
    "new_df['velo_mn_avg14d'] = new_df['Freq_mn_1d']/(new_df['Freq_mn_14d']/14)\n",
    "new_df['velo_mn_avg30d'] = new_df['Freq_mn_1d']/(new_df['Freq_mn_30d']/30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill na with 0\n",
    "new_df = new_df.fillna(0)\n",
    "\n",
    "# export amount expert variables\n",
    "new_df.to_csv('AmountVariables.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.read_csv('AmountVariables.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## add a dummy variable as for sanity checks\n",
    "new_df['random'] = np.random.randint(0, 100, new_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## calculate ks score for all variables\n",
    "from scipy.stats import ks_2samp\n",
    "\n",
    "ks_df = pd.DataFrame()\n",
    "# ks_df['col'] = list(new_df)[10,:]\n",
    "ks_df['col'] = list(new_df[new_df.columns[~new_df.columns.isin(['Amount_cn_actual','Amount_mn_actual','Amount_cn_mn_actual','Amount_cn_zip_actual','Amount_cn_st_actual'])]])[10:]\n",
    "\n",
    "ks_df['p_value'] = ''\n",
    "ks_df['ks_score'] = ''\n",
    "for i in range(len(ks_df)):\n",
    "    ks_df['ks_score'][i] = ks_2samp(new_df[new_df['Fraud'] == 0][ks_df['col'][i]], new_df[new_df['Fraud'] == 1][ks_df['col'][i]])[0]\n",
    "    ks_df['p_value'][i] = ks_2samp(new_df[new_df['Fraud'] == 0][ks_df['col'][i]], new_df[new_df['Fraud'] == 1][ks_df['col'][i]])[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## calculate fraud detection rate for all variables\n",
    "def fdr_cal(row):\n",
    "    col_name = row['col']\n",
    "    df_temp1 = new_df.sort_values(col_name, ascending = False)\n",
    "    df_temp_top1 = df_temp1[:round(len(new_df)*0.03)]\n",
    "    fdr1 = sum(df_temp_top1['Fraud'])/sum(df_temp1['Fraud'])\n",
    "    df_temp2 = new_df.sort_values(col_name, ascending = True)\n",
    "    df_temp_top2 = df_temp2[:round(len(new_df)*0.03)]\n",
    "    fdr2 = sum(df_temp_top2['Fraud'])/sum(df_temp2['Fraud'])\n",
    "    return max(fdr1, fdr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks_df['fdr'] = ks_df.apply(lambda row: fdr_cal(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## sort variables by fdr\n",
    "fdr_sorted_list = ks_df.sort_values('fdr', ascending = False)\n",
    "# fdr_sorted_list.to_pickle('fdr_sorted_list.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## sort variables by ks_score\n",
    "ks_score_sorted_list = ks_df.sort_values('ks_score', ascending = False)\n",
    "# ks_score_sorted_list.to_pickle('ks_score_sorted_list.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks_df['ks_rank'] = ks_df['ks_score'].rank(ascending = False)\n",
    "ks_df['fdr_rank'] = ks_df['fdr'].rank(ascending = False)\n",
    "ks_df['avg_rank'] = ks_df['ks_rank'] * 0.6 + ks_df['fdr_rank'] * 0.4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ks_df.to_excel('ks_df.xlsx')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Divide into OOT and Train/Test\n",
    "int_df = new_df[new_df[\"Date\"] < new_df[\"Date\"][84461]] \n",
    "oot_df = new_df[new_df[\"Date\"] > new_df[\"Date\"][84288]]\n",
    "train, test = train_test_split(int_df, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## calculate ks score for all variables\n",
    "def fdr_cal(row, df):\n",
    "    col_name = row['col']\n",
    "    df_temp = df.sort_values(col_name, ascending = False)\n",
    "    df_temp_top = df_temp[:round(len(df)*0.03)]\n",
    "    df_temp_bot = df_temp.tail(round(len(df)*0.03))\n",
    "    top_fdr= sum(df_temp_top['Fraud'])/sum(df_temp['Fraud'])\n",
    "    bot_fdr= sum(df_temp_bot['Fraud'])/sum(df_temp['Fraud'])\n",
    "#     print(str(top_fdr)+ \" \"+str(bot_fdr))\n",
    "    return(max(top_fdr, bot_fdr))\n",
    "\n",
    "def ks_fdr(df):\n",
    "    ks_df = pd.DataFrame()\n",
    "    ks_df['col'] = list(df)[10:]\n",
    "    ks_df['p_value'] = ''\n",
    "    ks_df['ks_score'] = ''\n",
    "    # Calc KS\n",
    "    for i in range(len(ks_df)):\n",
    "        ks_df['ks_score'][i] = ks_2samp(df[df['Fraud'] == 0][ks_df['col'][i]], df[df['Fraud'] == 1][ks_df['col'][i]])[0]\n",
    "        ks_df['p_value'][i] = ks_2samp(df[df['Fraud'] == 0][ks_df['col'][i]], df[df['Fraud'] == 1][ks_df['col'][i]])[1]\n",
    "    # Calc FDR\n",
    "    ks_df['fdr'] = ks_df.apply(lambda row: fdr_cal(row, df), axis=1)\n",
    "    return ks_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ks_fdr_int = ks_fdr(int_df)\n",
    "ks_fdr_oot = ks_fdr(oot_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks_fdr_int['ks_rank'] = ks_fdr_int['ks_score'].rank(ascending = False)\n",
    "ks_fdr_int['fdr_rank'] = ks_fdr_int['fdr'].rank(ascending = False)\n",
    "ks_fdr_int['avg_rank'] = ks_fdr_int['ks_rank'] * 0.6 + ks_fdr_int['fdr_rank'] * 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                          Fraud\n",
       "79          Amount_cn_zip_actual\n",
       "53           Amount_cn_mn_actual\n",
       "105          Amount_cn_st_actual\n",
       "27              Amount_mn_actual\n",
       "1               Amount_cn_actual\n",
       "24         Amount_cn_30d_act-avg\n",
       "50         Amount_mn_30d_act-avg\n",
       "19         Amount_cn_14d_act-avg\n",
       "45         Amount_mn_14d_act-avg\n",
       "40          Amount_mn_7d_act-avg\n",
       "14          Amount_cn_7d_act-avg\n",
       "117          Amount_cn_st_7d_sum\n",
       "35          Amount_mn_4d_act-avg\n",
       "112          Amount_cn_st_4d_sum\n",
       "111          Amount_cn_st_4d_avg\n",
       "86          Amount_cn_zip_4d_sum\n",
       "18             Amount_cn_14d_sum\n",
       "85          Amount_cn_zip_4d_avg\n",
       "13              Amount_cn_7d_sum\n",
       "122         Amount_cn_st_14d_sum\n",
       "59           Amount_cn_mn_4d_avg\n",
       "128     Amount_cn_st_30d_act-avg\n",
       "60           Amount_cn_mn_4d_sum\n",
       "116          Amount_cn_st_7d_avg\n",
       "91          Amount_cn_zip_7d_sum\n",
       "8               Amount_cn_4d_sum\n",
       "7               Amount_cn_4d_avg\n",
       "51         Amount_mn_30d_act/avg\n",
       "127         Amount_cn_st_30d_sum\n",
       "                 ...            \n",
       "100        Amount_cn_zip_30d_avg\n",
       "52         Amount_mn_30d_act/sum\n",
       "101        Amount_cn_zip_30d_sum\n",
       "69          Amount_cn_mn_14d_avg\n",
       "123     Amount_cn_st_14d_act-avg\n",
       "3               Amount_cn_1d_sum\n",
       "2               Amount_cn_1d_avg\n",
       "75          Amount_cn_mn_30d_sum\n",
       "47         Amount_mn_14d_act/sum\n",
       "43             Amount_mn_14d_avg\n",
       "20         Amount_cn_14d_act/avg\n",
       "41          Amount_mn_7d_act/avg\n",
       "74          Amount_cn_mn_30d_avg\n",
       "38              Amount_mn_7d_avg\n",
       "80          Amount_cn_zip_1d_avg\n",
       "81          Amount_cn_zip_1d_sum\n",
       "39              Amount_mn_7d_sum\n",
       "102    Amount_cn_zip_30d_act-avg\n",
       "113      Amount_cn_st_4d_act-avg\n",
       "118      Amount_cn_st_7d_act-avg\n",
       "28              Amount_mn_1d_avg\n",
       "29              Amount_mn_1d_sum\n",
       "48             Amount_mn_30d_avg\n",
       "76      Amount_cn_mn_30d_act-avg\n",
       "55           Amount_cn_mn_1d_sum\n",
       "54           Amount_cn_mn_1d_avg\n",
       "21         Amount_cn_14d_act/sum\n",
       "42          Amount_mn_7d_act/sum\n",
       "152                Freq_cn_st_4d\n",
       "36          Amount_mn_4d_act/avg\n",
       "Name: col, Length: 80, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_features = ks_fdr_int.sort_values(\"avg_rank\")[\"col\"].head(80)\n",
    "top_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                      Fraud\n",
       "51     Amount_mn_30d_act/avg\n",
       "17         Amount_cn_14d_avg\n",
       "25     Amount_cn_30d_act/avg\n",
       "22         Amount_cn_30d_avg\n",
       "26     Amount_cn_30d_act/sum\n",
       "46     Amount_mn_14d_act/avg\n",
       "34          Amount_mn_4d_sum\n",
       "95     Amount_cn_zip_14d_avg\n",
       "52     Amount_mn_30d_act/sum\n",
       "69      Amount_cn_mn_14d_avg\n",
       "47     Amount_mn_14d_act/sum\n",
       "20     Amount_cn_14d_act/avg\n",
       "39          Amount_mn_7d_sum\n",
       "48         Amount_mn_30d_avg\n",
       "55       Amount_cn_mn_1d_sum\n",
       "54       Amount_cn_mn_1d_avg\n",
       "21     Amount_cn_14d_act/sum\n",
       "42      Amount_mn_7d_act/sum\n",
       "152            Freq_cn_st_4d\n",
       "Name: col, dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "estimator = LogisticRegression(solver=\"liblinear\", max_iter=300)\n",
    "selector = RFE(estimator, 20, step=1)\n",
    "selector = selector.fit(int_df[top_features], int_df[\"Fraud\"])\n",
    "top_features[selector.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 53.3 s, sys: 1.65 s, total: 55 s\n",
      "Wall time: 53.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# ---- Z scale to prepare for dimensionality reduction ----\n",
    "# Create the Scaler object\n",
    "scaler = StandardScaler()\n",
    "# Fit your data on the scaler object\n",
    "scaled_df = scaler.fit_transform(new_df[list(new_df)[10:]])\n",
    "scaled_df = pd.DataFrame(scaled_df, columns=list(scaled_df))\n",
    "# Convert fraud back to 1 and 0\n",
    "scaled_df[\"Fraud_att\"] = new_df[\"Fraud\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
