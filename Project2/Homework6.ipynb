{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pandas import ExcelWriter\n",
    "import random\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import ks_2samp\n",
    "import random\n",
    "random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15 s, sys: 287 ms, total: 15.3 s\n",
      "Wall time: 15.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = pd.read_excel('card transactions.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th># NaN</th>\n",
       "      <th>% populated</th>\n",
       "      <th># unique</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Recnum</td>\n",
       "      <td>0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>96753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cardnum</td>\n",
       "      <td>0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>1645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Date</td>\n",
       "      <td>0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Merchnum</td>\n",
       "      <td>3375</td>\n",
       "      <td>96.511736</td>\n",
       "      <td>13091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Merch description</td>\n",
       "      <td>0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>13126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Merch state</td>\n",
       "      <td>1195</td>\n",
       "      <td>98.764896</td>\n",
       "      <td>227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Merch zip</td>\n",
       "      <td>4656</td>\n",
       "      <td>95.187746</td>\n",
       "      <td>4567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Transtype</td>\n",
       "      <td>0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Amount</td>\n",
       "      <td>0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>34909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Fraud</td>\n",
       "      <td>0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            variable  # NaN  % populated # unique\n",
       "0             Recnum      0   100.000000    96753\n",
       "1            Cardnum      0   100.000000     1645\n",
       "2               Date      0   100.000000      365\n",
       "3           Merchnum   3375    96.511736    13091\n",
       "4  Merch description      0   100.000000    13126\n",
       "5        Merch state   1195    98.764896      227\n",
       "6          Merch zip   4656    95.187746     4567\n",
       "7          Transtype      0   100.000000        4\n",
       "8             Amount      0   100.000000    34909\n",
       "9              Fraud      0   100.000000        2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# summary\n",
    "numrecords = len(df)\n",
    "stat_df = pd.DataFrame(df.isnull().sum(axis = 0))\n",
    "stat_df = stat_df.reset_index().rename(columns = {'index':'variable', 0 :\"# NaN\"})\n",
    "stat_df[\"% populated\"] = (1 - stat_df[\"# NaN\"]/numrecords)*100\n",
    "stat_df[\"# unique\"] = ''\n",
    "\n",
    "for i in range(len(list(df))):\n",
    "    stat_df[\"# unique\"][i] = df[list(df)[i]].nunique()\n",
    "    \n",
    "stat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stat_df.to_excel('stat_df.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96397"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Identify any exclusions, bad records\n",
    "\n",
    "# Remove single large transaction outlier in Amount\n",
    "df = df[df['Amount']<3000000]\n",
    "\n",
    "# Remove all but P transaction type\n",
    "df = df[df['Transtype'] == 'P']\n",
    "\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1414"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --------------- Fill in NAs ----------\n",
    "\n",
    "### Merchnum \n",
    "# Transform 0 values into NA\n",
    "df.loc[df['Merchnum'] == '0', 'Merchnum'] = np.NaN\n",
    "\n",
    "# fill most frequenct merchnum using merch description\n",
    "dict1 = df.set_index('Merch description')['Merchnum'].to_dict()\n",
    "df['Merchnum'].fillna(df['Merch description'].map(dict1), inplace = True)\n",
    "\n",
    "# fill most frequenct merchnum in this zip\n",
    "dict1 = dict(zip(df['Merch zip'].dropna(), df['Merchnum']))\n",
    "df['Merchnum'].fillna(df['Merch zip'].map(dict1), inplace = True)\n",
    "\n",
    "pd.isnull(df['Merchnum']).sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3810"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Merch state and zip\n",
    "numrecords - (df['Merch state'].isna() == df['Merch zip'].isna()).sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "543"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Merch zip\n",
    "# df.groupby(['Merch description','Merch zip']).size()\n",
    "\n",
    "# fill NA in Merch zip using Merch description\n",
    "dict1 = df.set_index('Merch description')['Merch zip'].to_dict()\n",
    "df['Merch zip'].fillna(df['Merch description'].map(dict1), inplace = True)\n",
    "\n",
    "# fill NA in Merch zip using Merchnum\n",
    "dict1 = df.set_index('Merchnum')['Merch zip'].to_dict()\n",
    "df['Merch zip'].fillna(df['Merchnum'].map(dict1), inplace = True)\n",
    "\n",
    "# fill NA in Merch zip using Cardnum\n",
    "dict1 = df.set_index('Cardnum')['Merch zip'].to_dict()\n",
    "df['Merch zip'].fillna(df['Cardnum'].map(dict1), inplace = True)\n",
    "# It will automatically choose zip with highest frequency\n",
    "\n",
    "pd.isnull(df['Merch zip']).sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60108.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic = dict(zip(df['Cardnum'], df['Merch zip']))\n",
    "dic[5142310525]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "122"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Merch state\n",
    "# df.groupby(['Merch description','Merch state']).size()\n",
    "# Each Merch description has one matched state\n",
    "\n",
    "# fill NA in Merch state using Merch description\n",
    "dict1 = df.set_index('Merch description')['Merch state'].to_dict()\n",
    "df['Merch state'].fillna(df['Merch description'].map(dict1), inplace = True)\n",
    "\n",
    "# fill NA in Merch state using Merchnum\n",
    "dict1 = df.set_index('Merchnum')['Merch state'].to_dict()\n",
    "df['Merch state'].fillna(df['Merchnum'].map(dict1), inplace = True)\n",
    "\n",
    "# fill NA in Merch state using Merch zip\n",
    "\n",
    "dict1 = dict(zip(df['Merch zip'].dropna(), df['Merch state']))\n",
    "df['Merch state'].fillna(df['Merch zip'].map(dict1), inplace = True)\n",
    "\n",
    "# fill NA in Merch state using Cardnum\n",
    "dict1 = df.set_index('Cardnum')['Merch state'].to_dict()\n",
    "df['Merch state'].fillna(df['Cardnum'].map(dict1), inplace = True)\n",
    "\n",
    "pd.isnull(df['Merch state']).sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94631"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop remained NA in three variables\n",
    "df = df.dropna()\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.groupby(['Cardnum','Date'])['Amount'].value_counts()\n",
    "# df[df['Cardnum'] == 5142190439]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# --------------- Create variables ----------\n",
    "### Amount expert variables\n",
    "\n",
    "# Cardnum\n",
    "# sum the amount at the same day first and then rolling\n",
    "df2 = df.groupby(['Cardnum','Date'])['Amount'].sum().to_frame().reset_index().set_index('Date')\n",
    "new_df = df.join(df.groupby(['Cardnum','Date'])['Amount'].sum(),on = ['Cardnum','Date'], rsuffix = '_cn_actual')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (closed = 'left') in rolling function means when calculating past n days we exlude today's transactions\n",
    "\n",
    "def amount_mean_func(column, window, rsuffix):\n",
    "    dataframe = pd.DataFrame()\n",
    "    dataframe = new_df.join(df2.groupby([column])['Amount'].rolling(window = window, closed = 'left').mean(), on = [column,'Date'], rsuffix = rsuffix)\n",
    "    return dataframe\n",
    "\n",
    "# def amount_max_func(column, window, rsuffix):\n",
    "#     dataframe = pd.DataFrame()\n",
    "#     dataframe = new_df.join(df2.groupby([column])['Amount'].rolling(window = window).max(), on = [column,'Date'], rsuffix = rsuffix)\n",
    "#     return dataframe\n",
    "\n",
    "# def amount_median_func(column, window, rsuffix):\n",
    "#     dataframe = pd.DataFrame()\n",
    "#     dataframe = new_df.join(df2.groupby([column])['Amount'].rolling(window = window).median(), on = [column,'Date'], rsuffix = rsuffix)\n",
    "#     return dataframe\n",
    "\n",
    "def amount_sum_func(column, window, rsuffix):\n",
    "    dataframe = pd.DataFrame()\n",
    "    dataframe = new_df.join(df2.groupby([column])['Amount'].rolling(window = window, closed = 'left').sum(), on = [column,'Date'], rsuffix = rsuffix)\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.groupby(['Cardnum','Date'])['Amount'].sum().to_frame().reset_index().set_index('Date')\n",
    "new_df = df.join(df.groupby(['Cardnum','Date'])['Amount'].sum(),on = ['Cardnum','Date'], rsuffix = '_cn_actual')\n",
    "\n",
    "new_df = amount_mean_func(column = 'Cardnum',window = '1D',rsuffix = '_cn_1d_avg')\n",
    "# new_df = amount_max_func(column = 'Cardnum',window = '1D',rsuffix = '_cn_1d_max')\n",
    "# new_df = amount_median_func(column = 'Cardnum',window = '1D',rsuffix = '_cn_1d_median')\n",
    "new_df = amount_sum_func(column = 'Cardnum',window = '1D',rsuffix = '_cn_1d_sum')\n",
    "new_df['Amount_cn_1d_act-avg'] = new_df['Amount_cn_actual'] - new_df['Amount_cn_1d_avg']\n",
    "# new_df['Amount_cn_1d_act-median'] = new_df['Amount_cn_actual'] - new_df['Amount_cn_1d_median']\n",
    "new_df['Amount_cn_1d_act/avg'] = new_df['Amount_cn_actual']/new_df['Amount_cn_1d_avg']\n",
    "# new_df['Amount_cn_1d_act/max'] = new_df['Amount_cn_actual']/new_df['Amount_cn_1d_max']\n",
    "new_df['Amount_cn_1d_act/sum'] = new_df['Amount_cn_actual']/new_df['Amount_cn_1d_sum']\n",
    "# new_df['Amount_cn_1d_act/median'] = new_df['Amount_cn_actual']/new_df['Amount_cn_1d_median']\n",
    "\n",
    "new_df = amount_mean_func(column = 'Cardnum',window = '4D',rsuffix = '_cn_4d_avg')\n",
    "new_df = amount_sum_func(column = 'Cardnum',window = '4D',rsuffix = '_cn_4d_sum')\n",
    "new_df['Amount_cn_4d_act-avg'] = new_df['Amount_cn_actual'] - new_df['Amount_cn_4d_avg']\n",
    "new_df['Amount_cn_4d_act/avg'] = new_df['Amount_cn_actual']/new_df['Amount_cn_4d_avg']\n",
    "new_df['Amount_cn_4d_act/sum'] = new_df['Amount_cn_actual']/new_df['Amount_cn_4d_sum']\n",
    "\n",
    "new_df = amount_mean_func(column = 'Cardnum',window = '7D',rsuffix = '_cn_7d_avg')\n",
    "new_df = amount_sum_func(column = 'Cardnum',window = '7D',rsuffix = '_cn_7d_sum')\n",
    "new_df['Amount_cn_7d_act-avg'] = new_df['Amount_cn_actual'] - new_df['Amount_cn_7d_avg']\n",
    "new_df['Amount_cn_7d_act/avg'] = new_df['Amount_cn_actual']/new_df['Amount_cn_7d_avg']\n",
    "new_df['Amount_cn_7d_act/sum'] = new_df['Amount_cn_actual']/new_df['Amount_cn_7d_sum']\n",
    "\n",
    "new_df = amount_mean_func(column = 'Cardnum',window = '14D',rsuffix = '_cn_14d_avg')\n",
    "new_df = amount_sum_func(column = 'Cardnum',window = '14D',rsuffix = '_cn_14d_sum')\n",
    "new_df['Amount_cn_14d_act-avg'] = new_df['Amount_cn_actual'] - new_df['Amount_cn_14d_avg']\n",
    "new_df['Amount_cn_14d_act/avg'] = new_df['Amount_cn_actual']/new_df['Amount_cn_14d_avg']\n",
    "new_df['Amount_cn_14d_act/sum'] = new_df['Amount_cn_actual']/new_df['Amount_cn_14d_sum']\n",
    "\n",
    "new_df = amount_mean_func(column = 'Cardnum',window = '30D',rsuffix = '_cn_30d_avg')\n",
    "new_df = amount_sum_func(column = 'Cardnum',window = '30D',rsuffix = '_cn_30d_sum')\n",
    "new_df['Amount_cn_30d_act-avg'] = new_df['Amount_cn_actual'] - new_df['Amount_cn_30d_avg']\n",
    "new_df['Amount_cn_30d_act/avg'] = new_df['Amount_cn_actual']/new_df['Amount_cn_30d_avg']\n",
    "new_df['Amount_cn_30d_act/sum'] = new_df['Amount_cn_actual']/new_df['Amount_cn_30d_sum']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.groupby(['Merchnum','Date'])['Amount'].sum().to_frame().reset_index().set_index('Date')\n",
    "new_df = new_df.join(df.groupby(['Merchnum','Date'])['Amount'].sum(),on = ['Merchnum','Date'], rsuffix = '_mn_actual')\n",
    "\n",
    "new_df = amount_mean_func(column = 'Merchnum',window = '1D',rsuffix = '_mn_1d_avg')\n",
    "new_df = amount_sum_func(column = 'Merchnum',window = '1D',rsuffix = '_mn_1d_sum')\n",
    "new_df['Amount_mn_1d_act-avg'] = new_df['Amount_mn_actual'] - new_df['Amount_mn_1d_avg']\n",
    "new_df['Amount_mn_1d_act/avg'] = new_df['Amount_mn_actual']/new_df['Amount_mn_1d_avg']\n",
    "new_df['Amount_mn_1d_act/sum'] = new_df['Amount_mn_actual']/new_df['Amount_mn_1d_sum']\n",
    "\n",
    "new_df = amount_mean_func(column = 'Merchnum',window = '4D',rsuffix = '_mn_4d_avg')\n",
    "new_df = amount_sum_func(column = 'Merchnum',window = '4D',rsuffix = '_mn_4d_sum')\n",
    "new_df['Amount_mn_4d_act-avg'] = new_df['Amount_mn_actual'] - new_df['Amount_mn_4d_avg']\n",
    "new_df['Amount_mn_4d_act/avg'] = new_df['Amount_mn_actual']/new_df['Amount_mn_4d_avg']\n",
    "new_df['Amount_mn_4d_act/sum'] = new_df['Amount_mn_actual']/new_df['Amount_mn_4d_sum']\n",
    "\n",
    "new_df = amount_mean_func(column = 'Merchnum',window = '7D',rsuffix = '_mn_7d_avg')\n",
    "new_df = amount_sum_func(column = 'Merchnum',window = '7D',rsuffix = '_mn_7d_sum')\n",
    "new_df['Amount_mn_7d_act-avg'] = new_df['Amount_mn_actual'] - new_df['Amount_mn_7d_avg']\n",
    "new_df['Amount_mn_7d_act/avg'] = new_df['Amount_mn_actual']/new_df['Amount_mn_7d_avg']\n",
    "new_df['Amount_mn_7d_act/sum'] = new_df['Amount_mn_actual']/new_df['Amount_mn_7d_sum']\n",
    "\n",
    "new_df = amount_mean_func(column = 'Merchnum',window = '14D',rsuffix = '_mn_14d_avg')\n",
    "new_df = amount_sum_func(column = 'Merchnum',window = '14D',rsuffix = '_mn_14d_sum')\n",
    "new_df['Amount_mn_14d_act-avg'] = new_df['Amount_mn_actual'] - new_df['Amount_mn_14d_avg']\n",
    "new_df['Amount_mn_14d_act/avg'] = new_df['Amount_mn_actual']/new_df['Amount_mn_14d_avg']\n",
    "new_df['Amount_mn_14d_act/sum'] = new_df['Amount_mn_actual']/new_df['Amount_mn_14d_sum']\n",
    "\n",
    "new_df = amount_mean_func(column = 'Merchnum',window = '30D',rsuffix = '_mn_30d_avg')\n",
    "new_df = amount_sum_func(column = 'Merchnum',window = '30D',rsuffix = '_mn_30d_sum')\n",
    "new_df['Amount_mn_30d_act-avg'] = new_df['Amount_mn_actual'] - new_df['Amount_mn_30d_avg']\n",
    "new_df['Amount_mn_30d_act/avg'] = new_df['Amount_mn_actual']/new_df['Amount_mn_30d_avg']\n",
    "new_df['Amount_mn_30d_act/sum'] = new_df['Amount_mn_actual']/new_df['Amount_mn_30d_sum']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.groupby(['Cardnum','Merchnum','Date'])['Amount'].sum().to_frame().reset_index().set_index('Date')\n",
    "new_df = new_df.join(df.groupby(['Cardnum','Merchnum','Date'])['Amount'].sum(),on = ['Cardnum','Merchnum','Date'], rsuffix = '_cn_mn_actual')\n",
    "\n",
    "new_df = new_df.join(df2.groupby(['Cardnum','Merchnum'])['Amount'].rolling(window = '1D', closed = 'left').mean(), on = ['Cardnum','Merchnum','Date'], rsuffix = '_cn_mn_1d_avg')\n",
    "new_df = new_df.join(df2.groupby(['Cardnum','Merchnum'])['Amount'].rolling(window = '1D', closed = 'left').sum(), on = ['Cardnum','Merchnum','Date'], rsuffix = '_cn_mn_1d_sum')\n",
    "new_df['Amount_cn_mn_1d_act-avg'] = new_df['Amount_cn_mn_actual'] - new_df['Amount_cn_mn_1d_avg']\n",
    "new_df['Amount_cn_mn_1d_act/avg'] = new_df['Amount_cn_mn_actual']/new_df['Amount_cn_mn_1d_avg']\n",
    "new_df['Amount_cn_mn_1d_act/sum'] = new_df['Amount_cn_mn_actual']/new_df['Amount_cn_mn_1d_sum']\n",
    "\n",
    "new_df = new_df.join(df2.groupby(['Cardnum','Merchnum'])['Amount'].rolling(window = '4D', closed = 'left').mean(), on = ['Cardnum','Merchnum','Date'], rsuffix = '_cn_mn_4d_avg')\n",
    "new_df = new_df.join(df2.groupby(['Cardnum','Merchnum'])['Amount'].rolling(window = '4D', closed = 'left').sum(), on = ['Cardnum','Merchnum','Date'], rsuffix = '_cn_mn_4d_sum')\n",
    "new_df['Amount_cn_mn_4d_act-avg'] = new_df['Amount_cn_mn_actual'] - new_df['Amount_cn_mn_4d_avg']\n",
    "new_df['Amount_cn_mn_4d_act/avg'] = new_df['Amount_cn_mn_actual']/new_df['Amount_cn_mn_4d_avg']\n",
    "new_df['Amount_cn_mn_4d_act/sum'] = new_df['Amount_cn_mn_actual']/new_df['Amount_cn_mn_4d_sum']\n",
    "\n",
    "new_df = new_df.join(df2.groupby(['Cardnum','Merchnum'])['Amount'].rolling(window = '7D', closed = 'left').mean(), on = ['Cardnum','Merchnum','Date'], rsuffix = '_cn_mn_7d_avg')\n",
    "new_df = new_df.join(df2.groupby(['Cardnum','Merchnum'])['Amount'].rolling(window = '7D', closed = 'left').sum(), on = ['Cardnum','Merchnum','Date'], rsuffix = '_cn_mn_7d_sum')\n",
    "new_df['Amount_cn_mn_7d_act-avg'] = new_df['Amount_cn_mn_actual'] - new_df['Amount_cn_mn_7d_avg']\n",
    "new_df['Amount_cn_mn_7d_act/avg'] = new_df['Amount_cn_mn_actual']/new_df['Amount_cn_mn_7d_avg']\n",
    "new_df['Amount_cn_mn_7d_act/sum'] = new_df['Amount_cn_mn_actual']/new_df['Amount_cn_mn_7d_sum']\n",
    "\n",
    "new_df = new_df.join(df2.groupby(['Cardnum','Merchnum'])['Amount'].rolling(window = '14D', closed = 'left').mean(), on = ['Cardnum','Merchnum','Date'], rsuffix = '_cn_mn_14d_avg')\n",
    "new_df = new_df.join(df2.groupby(['Cardnum','Merchnum'])['Amount'].rolling(window = '14D', closed = 'left').sum(), on = ['Cardnum','Merchnum','Date'], rsuffix = '_cn_mn_14d_sum')\n",
    "new_df['Amount_cn_mn_14d_act-avg'] = new_df['Amount_cn_mn_actual'] - new_df['Amount_cn_mn_14d_avg']\n",
    "new_df['Amount_cn_mn_14d_act/avg'] = new_df['Amount_cn_mn_actual']/new_df['Amount_cn_mn_14d_avg']\n",
    "new_df['Amount_cn_mn_14d_act/sum'] = new_df['Amount_cn_mn_actual']/new_df['Amount_cn_mn_14d_sum']\n",
    "\n",
    "new_df = new_df.join(df2.groupby(['Cardnum','Merchnum'])['Amount'].rolling(window = '30D', closed = 'left').mean(), on = ['Cardnum','Merchnum','Date'], rsuffix = '_cn_mn_30d_avg')\n",
    "new_df = new_df.join(df2.groupby(['Cardnum','Merchnum'])['Amount'].rolling(window = '30D', closed = 'left').sum(), on = ['Cardnum','Merchnum','Date'], rsuffix = '_cn_mn_30d_sum')\n",
    "new_df['Amount_cn_mn_30d_act-avg'] = new_df['Amount_cn_mn_actual'] - new_df['Amount_cn_mn_30d_avg']\n",
    "new_df['Amount_cn_mn_30d_act/avg'] = new_df['Amount_cn_mn_actual']/new_df['Amount_cn_mn_30d_avg']\n",
    "new_df['Amount_cn_mn_30d_act/sum'] = new_df['Amount_cn_mn_actual']/new_df['Amount_cn_mn_30d_sum']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.groupby(['Cardnum','Merch zip','Date'])['Amount'].sum().to_frame().reset_index().set_index('Date')\n",
    "new_df = new_df.join(df.groupby(['Cardnum','Merch zip','Date'])['Amount'].sum(),on = ['Cardnum','Merch zip','Date'], rsuffix = '_cn_zip_actual')\n",
    "\n",
    "new_df = new_df.join(df2.groupby(['Cardnum','Merch zip'])['Amount'].rolling(window = '1D', closed = 'left').mean(), on = ['Cardnum','Merch zip','Date'], rsuffix = '_cn_zip_1d_avg')\n",
    "new_df = new_df.join(df2.groupby(['Cardnum','Merch zip'])['Amount'].rolling(window = '1D', closed = 'left').sum(), on = ['Cardnum','Merch zip','Date'], rsuffix = '_cn_zip_1d_sum')\n",
    "new_df['Amount_cn_zip_1d_act-avg'] = new_df['Amount_cn_zip_actual'] - new_df['Amount_cn_zip_1d_avg']\n",
    "new_df['Amount_cn_zip_1d_act/avg'] = new_df['Amount_cn_zip_actual']/new_df['Amount_cn_zip_1d_avg']\n",
    "new_df['Amount_cn_zip_1d_act/sum'] = new_df['Amount_cn_zip_actual']/new_df['Amount_cn_zip_1d_sum']\n",
    "\n",
    "new_df = new_df.join(df2.groupby(['Cardnum','Merch zip'])['Amount'].rolling(window = '4D', closed = 'left').mean(), on = ['Cardnum','Merch zip','Date'], rsuffix = '_cn_zip_4d_avg')\n",
    "new_df = new_df.join(df2.groupby(['Cardnum','Merch zip'])['Amount'].rolling(window = '4D', closed = 'left').sum(), on = ['Cardnum','Merch zip','Date'], rsuffix = '_cn_zip_4d_sum')\n",
    "new_df['Amount_cn_zip_4d_act-avg'] = new_df['Amount_cn_zip_actual'] - new_df['Amount_cn_zip_4d_avg']\n",
    "new_df['Amount_cn_zip_4d_act/avg'] = new_df['Amount_cn_zip_actual']/new_df['Amount_cn_zip_4d_avg']\n",
    "new_df['Amount_cn_zip_4d_act/sum'] = new_df['Amount_cn_zip_actual']/new_df['Amount_cn_zip_4d_sum']\n",
    "\n",
    "new_df = new_df.join(df2.groupby(['Cardnum','Merch zip'])['Amount'].rolling(window = '7D', closed = 'left').mean(), on = ['Cardnum','Merch zip','Date'], rsuffix = '_cn_zip_7d_avg')\n",
    "new_df = new_df.join(df2.groupby(['Cardnum','Merch zip'])['Amount'].rolling(window = '7D', closed = 'left').sum(), on = ['Cardnum','Merch zip','Date'], rsuffix = '_cn_zip_7d_sum')\n",
    "new_df['Amount_cn_zip_7d_act-avg'] = new_df['Amount_cn_zip_actual'] - new_df['Amount_cn_zip_7d_avg']\n",
    "new_df['Amount_cn_zip_7d_act/avg'] = new_df['Amount_cn_zip_actual']/new_df['Amount_cn_zip_7d_avg']\n",
    "new_df['Amount_cn_zip_7d_act/sum'] = new_df['Amount_cn_zip_actual']/new_df['Amount_cn_zip_7d_sum']\n",
    "\n",
    "new_df = new_df.join(df2.groupby(['Cardnum','Merch zip'])['Amount'].rolling(window = '14D', closed = 'left').mean(), on = ['Cardnum','Merch zip','Date'], rsuffix = '_cn_zip_14d_avg')\n",
    "new_df = new_df.join(df2.groupby(['Cardnum','Merch zip'])['Amount'].rolling(window = '14D', closed = 'left').sum(), on = ['Cardnum','Merch zip','Date'], rsuffix = '_cn_zip_14d_sum')\n",
    "new_df['Amount_cn_zip_14d_act-avg'] = new_df['Amount_cn_zip_actual'] - new_df['Amount_cn_zip_14d_avg']\n",
    "new_df['Amount_cn_zip_14d_act/avg'] = new_df['Amount_cn_zip_actual']/new_df['Amount_cn_zip_14d_avg']\n",
    "new_df['Amount_cn_zip_14d_act/sum'] = new_df['Amount_cn_zip_actual']/new_df['Amount_cn_zip_14d_sum']\n",
    "\n",
    "new_df = new_df.join(df2.groupby(['Cardnum','Merch zip'])['Amount'].rolling(window = '30D', closed = 'left').mean(), on = ['Cardnum','Merch zip','Date'], rsuffix = '_cn_zip_30d_avg')\n",
    "new_df = new_df.join(df2.groupby(['Cardnum','Merch zip'])['Amount'].rolling(window = '30D', closed = 'left').sum(), on = ['Cardnum','Merch zip','Date'], rsuffix = '_cn_zip_30d_sum')\n",
    "new_df['Amount_cn_zip_30d_act-avg'] = new_df['Amount_cn_zip_actual'] - new_df['Amount_cn_zip_30d_avg']\n",
    "new_df['Amount_cn_zip_30d_act/avg'] = new_df['Amount_cn_zip_actual']/new_df['Amount_cn_zip_30d_avg']\n",
    "new_df['Amount_cn_zip_30d_act/sum'] = new_df['Amount_cn_zip_actual']/new_df['Amount_cn_zip_30d_sum']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.groupby(['Cardnum','Merch state','Date'])['Amount'].sum().to_frame().reset_index().set_index('Date')\n",
    "new_df = new_df.join(df.groupby(['Cardnum','Merch state','Date'])['Amount'].sum(),on = ['Cardnum','Merch state','Date'], rsuffix = '_cn_st_actual')\n",
    "\n",
    "new_df = new_df.join(df2.groupby(['Cardnum','Merch state'])['Amount'].rolling(window = '1D', closed = 'left').mean(), on = ['Cardnum','Merch state','Date'], rsuffix = '_cn_st_1d_avg')\n",
    "new_df = new_df.join(df2.groupby(['Cardnum','Merch state'])['Amount'].rolling(window = '1D', closed = 'left').sum(), on = ['Cardnum','Merch state','Date'], rsuffix = '_cn_st_1d_sum')\n",
    "new_df['Amount_cn_st_1d_act-avg'] = new_df['Amount_cn_st_actual'] - new_df['Amount_cn_st_1d_avg']\n",
    "new_df['Amount_cn_st_1d_act/avg'] = new_df['Amount_cn_st_actual']/new_df['Amount_cn_st_1d_avg']\n",
    "new_df['Amount_cn_st_1d_act/sum'] = new_df['Amount_cn_st_actual']/new_df['Amount_cn_st_1d_sum']\n",
    "\n",
    "new_df = new_df.join(df2.groupby(['Cardnum','Merch state'])['Amount'].rolling(window = '4D', closed = 'left').mean(), on = ['Cardnum','Merch state','Date'], rsuffix = '_cn_st_4d_avg')\n",
    "new_df = new_df.join(df2.groupby(['Cardnum','Merch state'])['Amount'].rolling(window = '4D', closed = 'left').sum(), on = ['Cardnum','Merch state','Date'], rsuffix = '_cn_st_4d_sum')\n",
    "new_df['Amount_cn_st_4d_act-avg'] = new_df['Amount_cn_st_actual'] - new_df['Amount_cn_st_4d_avg']\n",
    "new_df['Amount_cn_st_4d_act/avg'] = new_df['Amount_cn_st_actual']/new_df['Amount_cn_st_4d_avg']\n",
    "new_df['Amount_cn_st_4d_act/sum'] = new_df['Amount_cn_st_actual']/new_df['Amount_cn_st_4d_sum']\n",
    "\n",
    "new_df = new_df.join(df2.groupby(['Cardnum','Merch state'])['Amount'].rolling(window = '7D', closed = 'left').mean(), on = ['Cardnum','Merch state','Date'], rsuffix = '_cn_st_7d_avg')\n",
    "new_df = new_df.join(df2.groupby(['Cardnum','Merch state'])['Amount'].rolling(window = '7D', closed = 'left').sum(), on = ['Cardnum','Merch state','Date'], rsuffix = '_cn_st_7d_sum')\n",
    "new_df['Amount_cn_st_7d_act-avg'] = new_df['Amount_cn_st_actual'] - new_df['Amount_cn_st_7d_avg']\n",
    "new_df['Amount_cn_st_7d_act/avg'] = new_df['Amount_cn_st_actual']/new_df['Amount_cn_st_7d_avg']\n",
    "new_df['Amount_cn_st_7d_act/sum'] = new_df['Amount_cn_st_actual']/new_df['Amount_cn_st_7d_sum']\n",
    "\n",
    "new_df = new_df.join(df2.groupby(['Cardnum','Merch state'])['Amount'].rolling(window = '14D', closed = 'left').mean(), on = ['Cardnum','Merch state','Date'], rsuffix = '_cn_st_14d_avg')\n",
    "new_df = new_df.join(df2.groupby(['Cardnum','Merch state'])['Amount'].rolling(window = '14D', closed = 'left').sum(), on = ['Cardnum','Merch state','Date'], rsuffix = '_cn_st_14d_sum')\n",
    "new_df['Amount_cn_st_14d_act-avg'] = new_df['Amount_cn_st_actual'] - new_df['Amount_cn_st_14d_avg']\n",
    "new_df['Amount_cn_st_14d_act/avg'] = new_df['Amount_cn_st_actual']/new_df['Amount_cn_st_14d_avg']\n",
    "new_df['Amount_cn_st_14d_act/sum'] = new_df['Amount_cn_st_actual']/new_df['Amount_cn_st_14d_sum']\n",
    "\n",
    "new_df = new_df.join(df2.groupby(['Cardnum','Merch state'])['Amount'].rolling(window = '30D', closed = 'left').mean(), on = ['Cardnum','Merch state','Date'], rsuffix = '_cn_st_30d_avg')\n",
    "new_df = new_df.join(df2.groupby(['Cardnum','Merch state'])['Amount'].rolling(window = '30D', closed = 'left').sum(), on = ['Cardnum','Merch state','Date'], rsuffix = '_cn_st_30d_sum')\n",
    "new_df['Amount_cn_st_30d_act-avg'] = new_df['Amount_cn_st_actual'] - new_df['Amount_cn_st_30d_avg']\n",
    "new_df['Amount_cn_st_30d_act/avg'] = new_df['Amount_cn_st_actual']/new_df['Amount_cn_st_30d_avg']\n",
    "new_df['Amount_cn_st_30d_act/sum'] = new_df['Amount_cn_st_actual']/new_df['Amount_cn_st_30d_sum']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "### frequency variables\n",
    "new_df['Date'] = new_df['Date'].astype('datetime64[ns]')\n",
    "\n",
    "# Cardnum\n",
    "df3 = df.set_index('Date').groupby(['Cardnum'])['Recnum'].rolling(window = '1D', closed = 'left').count().to_frame().reset_index().drop_duplicates(subset = ['Cardnum','Date'],keep = 'first')\n",
    "new_df = new_df.merge(df3.rename(columns = {'Recnum':'Freq_cn_1d'}), on = ['Cardnum','Date'])\n",
    "\n",
    "df3 = df.set_index('Date').groupby(['Cardnum'])['Recnum'].rolling(window = '4D', closed = 'left').count().to_frame().reset_index().drop_duplicates(subset = ['Cardnum','Date'],keep = 'first')\n",
    "new_df = new_df.merge(df3.rename(columns = {'Recnum':'Freq_cn_4d'}), on = ['Cardnum','Date'])\n",
    "\n",
    "df3 = df.set_index('Date').groupby(['Cardnum'])['Recnum'].rolling(window = '7D', closed = 'left').count().to_frame().reset_index().drop_duplicates(subset = ['Cardnum','Date'],keep = 'first')\n",
    "new_df = new_df.merge(df3.rename(columns = {'Recnum':'Freq_cn_7d'}), on = ['Cardnum','Date'])\n",
    "\n",
    "df3 = df.set_index('Date').groupby(['Cardnum'])['Recnum'].rolling(window = '14D', closed = 'left').count().to_frame().reset_index().drop_duplicates(subset = ['Cardnum','Date'],keep = 'first')\n",
    "new_df = new_df.merge(df3.rename(columns = {'Recnum':'Freq_cn_14d'}), on = ['Cardnum','Date'])\n",
    "\n",
    "df3 = df.set_index('Date').groupby(['Cardnum'])['Recnum'].rolling(window = '30D', closed = 'left').count().to_frame().reset_index().drop_duplicates(subset = ['Cardnum','Date'],keep = 'first')\n",
    "new_df = new_df.merge(df3.rename(columns = {'Recnum':'Freq_cn_30d'}), on = ['Cardnum','Date'])\n",
    "\n",
    "# Merchnum\n",
    "df3 = df.set_index('Date').groupby(['Merchnum'])['Recnum'].rolling(window = '1D', closed = 'left').count().to_frame().reset_index().drop_duplicates(subset = ['Merchnum','Date'],keep = 'first')\n",
    "new_df = new_df.merge(df3.rename(columns = {'Recnum':'Freq_mn_1d'}), on = ['Merchnum','Date'])\n",
    "\n",
    "df3 = df.set_index('Date').groupby(['Merchnum'])['Recnum'].rolling(window = '4D', closed = 'left').count().to_frame().reset_index().drop_duplicates(subset = ['Merchnum','Date'],keep = 'first')\n",
    "new_df = new_df.merge(df3.rename(columns = {'Recnum':'Freq_mn_4d'}), on = ['Merchnum','Date'])\n",
    "\n",
    "df3 = df.set_index('Date').groupby(['Merchnum'])['Recnum'].rolling(window = '7D', closed = 'left').count().to_frame().reset_index().drop_duplicates(subset = ['Merchnum','Date'],keep = 'first')\n",
    "new_df = new_df.merge(df3.rename(columns = {'Recnum':'Freq_mn_7d'}), on = ['Merchnum','Date'])\n",
    "\n",
    "df3 = df.set_index('Date').groupby(['Merchnum'])['Recnum'].rolling(window = '14D', closed = 'left').count().to_frame().reset_index().drop_duplicates(subset = ['Merchnum','Date'],keep = 'first')\n",
    "new_df = new_df.merge(df3.rename(columns = {'Recnum':'Freq_mn_14d'}), on = ['Merchnum','Date'])\n",
    "\n",
    "df3 = df.set_index('Date').groupby(['Merchnum'])['Recnum'].rolling(window = '30D', closed = 'left').count().to_frame().reset_index().drop_duplicates(subset = ['Merchnum','Date'],keep = 'first')\n",
    "new_df = new_df.merge(df3.rename(columns = {'Recnum':'Freq_mn_30d'}), on = ['Merchnum','Date'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cardnum & Merchnum\n",
    "df3 = df.set_index('Date').groupby(['Cardnum','Merchnum'])['Recnum'].rolling(window = '1D', closed = 'left').count().to_frame().reset_index().drop_duplicates(subset = ['Cardnum','Merchnum','Date'],keep = 'first')\n",
    "new_df = new_df.merge(df3.rename(columns = {'Recnum':'Freq_cn_mn_1d'}), on = ['Cardnum','Merchnum','Date'])\n",
    "\n",
    "df3 = df.set_index('Date').groupby(['Cardnum','Merchnum'])['Recnum'].rolling(window = '4D', closed = 'left').count().to_frame().reset_index().drop_duplicates(subset = ['Cardnum','Merchnum','Date'],keep = 'first')\n",
    "new_df = new_df.merge(df3.rename(columns = {'Recnum':'Freq_cn_mn_4d'}), on = ['Cardnum','Merchnum','Date'])\n",
    "\n",
    "df3 = df.set_index('Date').groupby(['Cardnum','Merchnum'])['Recnum'].rolling(window = '7D', closed = 'left').count().to_frame().reset_index().drop_duplicates(subset = ['Cardnum','Merchnum','Date'],keep = 'first')\n",
    "new_df = new_df.merge(df3.rename(columns = {'Recnum':'Freq_cn_mn_7d'}), on = ['Cardnum','Merchnum','Date'])\n",
    "\n",
    "df3 = df.set_index('Date').groupby(['Cardnum','Merchnum'])['Recnum'].rolling(window = '14D', closed = 'left').count().to_frame().reset_index().drop_duplicates(subset = ['Cardnum','Merchnum','Date'],keep = 'first')\n",
    "new_df = new_df.merge(df3.rename(columns = {'Recnum':'Freq_cn_mn_14d'}), on = ['Cardnum','Merchnum','Date'])\n",
    "\n",
    "df3 = df.set_index('Date').groupby(['Cardnum','Merchnum'])['Recnum'].rolling(window = '30D', closed = 'left').count().to_frame().reset_index().drop_duplicates(subset = ['Cardnum','Merchnum','Date'],keep = 'first')\n",
    "new_df = new_df.merge(df3.rename(columns = {'Recnum':'Freq_cn_mn_30d'}), on = ['Cardnum','Merchnum','Date'])\n",
    "\n",
    "# Cardnum & Merch zip\n",
    "df3 = df.set_index('Date').groupby(['Cardnum','Merch zip'])['Recnum'].rolling(window = '1D', closed = 'left').count().to_frame().reset_index().drop_duplicates(subset = ['Cardnum','Merch zip','Date'],keep = 'first')\n",
    "new_df = new_df.merge(df3.rename(columns = {'Recnum':'Freq_cn_zip_1d'}), on = ['Cardnum','Merch zip','Date'])\n",
    "\n",
    "df3 = df.set_index('Date').groupby(['Cardnum','Merch zip'])['Recnum'].rolling(window = '4D', closed = 'left').count().to_frame().reset_index().drop_duplicates(subset = ['Cardnum','Merch zip','Date'],keep = 'first')\n",
    "new_df = new_df.merge(df3.rename(columns = {'Recnum':'Freq_cn_zip_4d'}), on = ['Cardnum','Merch zip','Date'])\n",
    "\n",
    "df3 = df.set_index('Date').groupby(['Cardnum','Merch zip'])['Recnum'].rolling(window = '7D', closed = 'left').count().to_frame().reset_index().drop_duplicates(subset = ['Cardnum','Merch zip','Date'],keep = 'first')\n",
    "new_df = new_df.merge(df3.rename(columns = {'Recnum':'Freq_cn_zip_7d'}), on = ['Cardnum','Merch zip','Date'])\n",
    "\n",
    "df3 = df.set_index('Date').groupby(['Cardnum','Merch zip'])['Recnum'].rolling(window = '14D', closed = 'left').count().to_frame().reset_index().drop_duplicates(subset = ['Cardnum','Merch zip','Date'],keep = 'first')\n",
    "new_df = new_df.merge(df3.rename(columns = {'Recnum':'Freq_cn_zip_14d'}), on = ['Cardnum','Merch zip','Date'])\n",
    "\n",
    "df3 = df.set_index('Date').groupby(['Cardnum','Merch zip'])['Recnum'].rolling(window = '30D', closed = 'left').count().to_frame().reset_index().drop_duplicates(subset = ['Cardnum','Merch zip','Date'],keep = 'first')\n",
    "new_df = new_df.merge(df3.rename(columns = {'Recnum':'Freq_cn_zip_30d'}), on = ['Cardnum','Merch zip','Date'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cardnum & Merch state\n",
    "df3 = df.set_index('Date').groupby(['Cardnum','Merch state'])['Recnum'].rolling(window = '1D', closed = 'left').count().to_frame().reset_index().drop_duplicates(subset = ['Cardnum','Merch state','Date'],keep = 'first')\n",
    "new_df = new_df.merge(df3.rename(columns = {'Recnum':'Freq_cn_st_1d'}), on = ['Cardnum','Merch state','Date'])\n",
    "\n",
    "df3 = df.set_index('Date').groupby(['Cardnum','Merch state'])['Recnum'].rolling(window = '4D', closed = 'left').count().to_frame().reset_index().drop_duplicates(subset = ['Cardnum','Merch state','Date'],keep = 'first')\n",
    "new_df = new_df.merge(df3.rename(columns = {'Recnum':'Freq_cn_st_4d'}), on = ['Cardnum','Merch state','Date'])\n",
    "\n",
    "df3 = df.set_index('Date').groupby(['Cardnum','Merch state'])['Recnum'].rolling(window = '7D', closed = 'left').count().to_frame().reset_index().drop_duplicates(subset = ['Cardnum','Merch state','Date'],keep = 'first')\n",
    "new_df = new_df.merge(df3.rename(columns = {'Recnum':'Freq_cn_st_7d'}), on = ['Cardnum','Merch state','Date'])\n",
    "\n",
    "df3 = df.set_index('Date').groupby(['Cardnum','Merch state'])['Recnum'].rolling(window = '14D', closed = 'left').count().to_frame().reset_index().drop_duplicates(subset = ['Cardnum','Merch state','Date'],keep = 'first')\n",
    "new_df = new_df.merge(df3.rename(columns = {'Recnum':'Freq_cn_st_14d'}), on = ['Cardnum','Merch state','Date'])\n",
    "\n",
    "df3 = df.set_index('Date').groupby(['Cardnum','Merch state'])['Recnum'].rolling(window = '30D', closed = 'left').count().to_frame().reset_index().drop_duplicates(subset = ['Cardnum','Merch state','Date'],keep = 'first')\n",
    "new_df = new_df.merge(df3.rename(columns = {'Recnum':'Freq_cn_st_30d'}), on = ['Cardnum','Merch state','Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "165"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(new_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Days since expert variables\n",
    "df3 = df.set_index('Date').groupby(['Cardnum'])['Recnum'].rolling(window = '1D', closed = 'left').count().to_frame().reset_index().drop_duplicates(subset = ['Cardnum','Date'])\n",
    "df3['Date_lag'] = df3.groupby('Cardnum')['Date'].shift(1)\n",
    "df3['last_cn'] = (df3['Date'] - df3['Date_lag']).dt.days\n",
    "new_df = new_df.merge(df3[['Cardnum','Date','last_cn']])\n",
    "\n",
    "df3 = df.set_index('Date').groupby(['Merchnum'])['Recnum'].rolling(window = '1D', closed = 'left').count().to_frame().reset_index().drop_duplicates(subset = ['Merchnum','Date'])\n",
    "df3['Date_lag'] = df3.groupby('Merchnum')['Date'].shift(1)\n",
    "df3['last_mn'] = (df3['Date'] - df3['Date_lag']).dt.days\n",
    "new_df = new_df.merge(df3[['Merchnum','Date','last_mn']])\n",
    "\n",
    "df3 = df.set_index('Date').groupby(['Cardnum','Merchnum'])['Recnum'].rolling(window = '1D', closed = 'left').count().to_frame().reset_index().drop_duplicates(subset = ['Cardnum','Merchnum','Date'])\n",
    "df3['Date_lag'] = df3.groupby(['Cardnum','Merchnum'])['Date'].shift(1)\n",
    "df3['last_cn_mn'] = (df3['Date'] - df3['Date_lag']).dt.days\n",
    "new_df = new_df.merge(df3[['Cardnum','Merchnum','Date','last_cn_mn']])\n",
    "\n",
    "df3 = df.set_index('Date').groupby(['Cardnum','Merch zip'])['Recnum'].rolling(window = '1D', closed = 'left').count().to_frame().reset_index().drop_duplicates(subset = ['Cardnum','Merch zip','Date'])\n",
    "df3['Date_lag'] = df3.groupby(['Cardnum','Merch zip'])['Date'].shift(1)\n",
    "df3['last_cn_zip'] = (df3['Date'] - df3['Date_lag']).dt.days\n",
    "new_df = new_df.merge(df3[['Cardnum','Merch zip','Date','last_cn_zip']])\n",
    "\n",
    "df3 = df.set_index('Date').groupby(['Cardnum','Merch state'])['Recnum'].rolling(window = '1D', closed = 'left').count().to_frame().reset_index().drop_duplicates(subset = ['Cardnum','Merch state','Date'])\n",
    "df3['Date_lag'] = df3.groupby(['Cardnum','Merch state'])['Date'].shift(1)\n",
    "df3['last_cn_st'] = (df3['Date'] - df3['Date_lag']).dt.days\n",
    "new_df = new_df.merge(df3[['Cardnum','Merch state','Date','last_cn_st']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Velocity deviation\n",
    "new_df['velo_cn_avg7d'] = new_df['Freq_cn_1d']/(new_df['Freq_cn_7d']/7)\n",
    "new_df['velo_cn_avg14d'] = new_df['Freq_cn_1d']/(new_df['Freq_cn_14d']/14)\n",
    "new_df['velo_cn_avg30d'] = new_df['Freq_cn_1d']/(new_df['Freq_cn_30d']/30)\n",
    "new_df['velo_mn_avg7d'] = new_df['Freq_mn_1d']/(new_df['Freq_mn_7d']/7)\n",
    "new_df['velo_mn_avg14d'] = new_df['Freq_mn_1d']/(new_df['Freq_mn_14d']/14)\n",
    "new_df['velo_mn_avg30d'] = new_df['Freq_mn_1d']/(new_df['Freq_mn_30d']/30)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill na with 0\n",
    "new_df = new_df.fillna(0)\n",
    "\n",
    "# export amount expert variables\n",
    "new_df.to_csv('AmountVariables.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.read_csv('AmountVariables.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "## add a dummy variable as for sanity checks\n",
    "new_df['random'] = np.random.randint(0, 100, new_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "## calculate ks score for all variables\n",
    "from scipy.stats import ks_2samp\n",
    "\n",
    "ks_df = pd.DataFrame()\n",
    "# ks_df['col'] = list(new_df)[10,:]\n",
    "ks_df['col'] = list(new_df[new_df.columns[~new_df.columns.isin(['Amount_cn_actual','Amount_mn_actual','Amount_cn_mn_actual','Amount_cn_zip_actual','Amount_cn_st_actual'])]])[10:]\n",
    "\n",
    "ks_df['p_value'] = ''\n",
    "ks_df['ks_score'] = ''\n",
    "for i in range(len(ks_df)):\n",
    "    ks_df['ks_score'][i] = ks_2samp(new_df[new_df['Fraud'] == 0][ks_df['col'][i]], new_df[new_df['Fraud'] == 1][ks_df['col'][i]])[0]\n",
    "    ks_df['p_value'][i] = ks_2samp(new_df[new_df['Fraud'] == 0][ks_df['col'][i]], new_df[new_df['Fraud'] == 1][ks_df['col'][i]])[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "## calculate fraud detection rate for all variables\n",
    "def dfr_cal(col_name):\n",
    "    df_temp = new_df.sort_values(col_name, ascending = False)\n",
    "    df_temp_top = df_temp[:round(len(new_df)*0.03)]\n",
    "    return sum(df_temp_top['Fraud'])/sum(df_temp['Fraud'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks_df['fdr'] = ''\n",
    "for i in range(len(ks_df)):\n",
    "    ks_df['fdr'][i] = dfr_cal(ks_df['col'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "## sort variables by fdr\n",
    "fdr_sorted_list = ks_df.sort_values('fdr', ascending = False)\n",
    "# fdr_sorted_list.to_pickle('fdr_sorted_list.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "## sort variables by ks_score\n",
    "ks_score_sorted_list = ks_df.sort_values('ks_score', ascending = False)\n",
    "# ks_score_sorted_list.to_pickle('ks_score_sorted_list.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks_df['ks_rank'] = ks_df['ks_score'].rank(ascending = False)\n",
    "ks_df['fdr_rank'] = ks_df['fdr'].rank(ascending = False)\n",
    "ks_df['avg_rank'] = ks_df['ks_rank'] * 0.6 + ks_df['fdr_rank'] * 0.4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ks_df.to_excel('ks_df.xlsx')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Divide into OOT and Train/Test\n",
    "int_df = new_df[new_df[\"Date\"] < new_df[\"Date\"][84461]] \n",
    "oot_df = new_df[new_df[\"Date\"] > new_df[\"Date\"][84288]]\n",
    "train, test = train_test_split(int_df, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "## calculate ks score for all variables\n",
    "def fdr_cal(col_name, df):\n",
    "    df_temp = df.sort_values(col_name, ascending = False)\n",
    "    df_temp_top = df_temp[:round(numrecords*0.03)]\n",
    "    return sum(df_temp_top['Fraud'])/sum(df_temp['Fraud'])\n",
    "\n",
    "def ks_fdr(df):\n",
    "    ks_df = pd.DataFrame()\n",
    "    ks_df['col'] = list(df)[10:]\n",
    "    ks_df['p_value'] = ''\n",
    "    ks_df['ks_score'] = ''\n",
    "    ks_df['fdr'] = ''\n",
    "    # Calc KS\n",
    "    for i in range(len(ks_df)):\n",
    "        ks_df['ks_score'][i] = ks_2samp(df[df['Fraud'] == 0][ks_df['col'][i]], df[df['Fraud'] == 1][ks_df['col'][i]])[0]\n",
    "        ks_df['p_value'][i] = ks_2samp(df[df['Fraud'] == 0][ks_df['col'][i]], df[df['Fraud'] == 1][ks_df['col'][i]])[1]\n",
    "    # Calc FDR\n",
    "    for i in range(len(ks_df)):\n",
    "        ks_df['fdr'][i] = fdr_cal(ks_df['col'][i], df)\n",
    "    return ks_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks_fdr_int = ks_fdr(int_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
