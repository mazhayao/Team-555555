{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pandas import ExcelWriter\n",
    "import random\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import ks_2samp\n",
    "import random\n",
    "random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.6 s, sys: 230 ms, total: 14.8 s\n",
      "Wall time: 15 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = pd.read_excel('card transactions.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th># NaN</th>\n",
       "      <th>% populated</th>\n",
       "      <th># unique</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Recnum</td>\n",
       "      <td>0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>96753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cardnum</td>\n",
       "      <td>0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>1645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Date</td>\n",
       "      <td>0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Merchnum</td>\n",
       "      <td>3375</td>\n",
       "      <td>96.511736</td>\n",
       "      <td>13091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Merch description</td>\n",
       "      <td>0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>13126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Merch state</td>\n",
       "      <td>1195</td>\n",
       "      <td>98.764896</td>\n",
       "      <td>227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Merch zip</td>\n",
       "      <td>4656</td>\n",
       "      <td>95.187746</td>\n",
       "      <td>4567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Transtype</td>\n",
       "      <td>0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Amount</td>\n",
       "      <td>0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>34909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Fraud</td>\n",
       "      <td>0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            variable  # NaN  % populated # unique\n",
       "0             Recnum      0   100.000000    96753\n",
       "1            Cardnum      0   100.000000     1645\n",
       "2               Date      0   100.000000      365\n",
       "3           Merchnum   3375    96.511736    13091\n",
       "4  Merch description      0   100.000000    13126\n",
       "5        Merch state   1195    98.764896      227\n",
       "6          Merch zip   4656    95.187746     4567\n",
       "7          Transtype      0   100.000000        4\n",
       "8             Amount      0   100.000000    34909\n",
       "9              Fraud      0   100.000000        2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# summary\n",
    "numrecords = len(df)\n",
    "stat_df = pd.DataFrame(df.isnull().sum(axis = 0))\n",
    "stat_df = stat_df.reset_index().rename(columns = {'index':'variable', 0 :\"# NaN\"})\n",
    "stat_df[\"% populated\"] = (1 - stat_df[\"# NaN\"]/numrecords)*100\n",
    "stat_df[\"# unique\"] = ''\n",
    "\n",
    "for i in range(len(list(df))):\n",
    "    stat_df[\"# unique\"][i] = df[list(df)[i]].nunique()\n",
    "    \n",
    "stat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stat_df.to_excel('stat_df.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96397"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Identify any exclusions, bad records\n",
    "\n",
    "# Remove single large transaction outlier in Amount\n",
    "df = df[df['Amount']<3000000]\n",
    "\n",
    "# Remove all but P transaction type\n",
    "df = df[df['Transtype'] == 'P']\n",
    "\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1414"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --------------- Fill in NAs ----------\n",
    "\n",
    "### Merchnum \n",
    "# Transform 0 values into NA\n",
    "df.loc[df['Merchnum'] == '0', 'Merchnum'] = np.NaN\n",
    "\n",
    "# fill most frequenct merchnum using merch description\n",
    "dict1 = df.set_index('Merch description')['Merchnum'].to_dict()\n",
    "df['Merchnum'].fillna(df['Merch description'].map(dict1), inplace = True)\n",
    "\n",
    "# fill most frequenct merchnum in this zip\n",
    "dict1 = dict(zip(df['Merch zip'].dropna(), df['Merchnum']))\n",
    "df['Merchnum'].fillna(df['Merch zip'].map(dict1), inplace = True)\n",
    "\n",
    "pd.isnull(df['Merchnum']).sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3810"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Merch state and zip\n",
    "numrecords - (df['Merch state'].isna() == df['Merch zip'].isna()).sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "543"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Merch zip\n",
    "# df.groupby(['Merch description','Merch zip']).size()\n",
    "\n",
    "# fill NA in Merch zip using Merch description\n",
    "dict1 = df.set_index('Merch description')['Merch zip'].to_dict()\n",
    "df['Merch zip'].fillna(df['Merch description'].map(dict1), inplace = True)\n",
    "\n",
    "# fill NA in Merch zip using Merchnum\n",
    "dict1 = df.set_index('Merchnum')['Merch zip'].to_dict()\n",
    "df['Merch zip'].fillna(df['Merchnum'].map(dict1), inplace = True)\n",
    "\n",
    "# fill NA in Merch zip using Cardnum\n",
    "dict1 = df.set_index('Cardnum')['Merch zip'].to_dict()\n",
    "df['Merch zip'].fillna(df['Cardnum'].map(dict1), inplace = True)\n",
    "# It will automatically choose zip with highest frequency\n",
    "\n",
    "pd.isnull(df['Merch zip']).sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60108.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic = dict(zip(df['Cardnum'], df['Merch zip']))\n",
    "dic[5142310525]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "122"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Merch state\n",
    "# df.groupby(['Merch description','Merch state']).size()\n",
    "# Each Merch description has one matched state\n",
    "\n",
    "# fill NA in Merch state using Merch description\n",
    "dict1 = df.set_index('Merch description')['Merch state'].to_dict()\n",
    "df['Merch state'].fillna(df['Merch description'].map(dict1), inplace = True)\n",
    "\n",
    "# fill NA in Merch state using Merchnum\n",
    "dict1 = df.set_index('Merchnum')['Merch state'].to_dict()\n",
    "df['Merch state'].fillna(df['Merchnum'].map(dict1), inplace = True)\n",
    "\n",
    "# fill NA in Merch state using Merch zip\n",
    "\n",
    "dict1 = dict(zip(df['Merch zip'].dropna(), df['Merch state']))\n",
    "df['Merch state'].fillna(df['Merch zip'].map(dict1), inplace = True)\n",
    "\n",
    "# fill NA in Merch state using Cardnum\n",
    "dict1 = df.set_index('Cardnum')['Merch state'].to_dict()\n",
    "df['Merch state'].fillna(df['Cardnum'].map(dict1), inplace = True)\n",
    "\n",
    "pd.isnull(df['Merch state']).sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94631"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop remained NA in three variables\n",
    "df = df.dropna()\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.groupby(['Cardnum','Date'])['Amount'].value_counts()\n",
    "# df[df['Cardnum'] == 5142190439]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# --------------- Create variables ----------\n",
    "### Amount expert variables\n",
    "\n",
    "# Cardnum\n",
    "# sum the amount at the same day first and then rolling\n",
    "df2 = df.groupby(['Cardnum','Date'])['Amount'].sum().to_frame().reset_index().set_index('Date')\n",
    "new_df = df.join(df.groupby(['Cardnum','Date'])['Amount'].sum(),on = ['Cardnum','Date'], rsuffix = '_cn_actual')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (closed = 'left') in rolling function means when calculating past n days we exlude today's transactions\n",
    "\n",
    "def amount_mean_func(column, window, rsuffix):\n",
    "    dataframe = pd.DataFrame()\n",
    "    dataframe = new_df.join(df2.groupby([column])['Amount'].rolling(window = window, closed = 'left').mean(), on = [column,'Date'], rsuffix = rsuffix)\n",
    "    return dataframe\n",
    "\n",
    "# def amount_max_func(column, window, rsuffix):\n",
    "#     dataframe = pd.DataFrame()\n",
    "#     dataframe = new_df.join(df2.groupby([column])['Amount'].rolling(window = window).max(), on = [column,'Date'], rsuffix = rsuffix)\n",
    "#     return dataframe\n",
    "\n",
    "# def amount_median_func(column, window, rsuffix):\n",
    "#     dataframe = pd.DataFrame()\n",
    "#     dataframe = new_df.join(df2.groupby([column])['Amount'].rolling(window = window).median(), on = [column,'Date'], rsuffix = rsuffix)\n",
    "#     return dataframe\n",
    "\n",
    "def amount_sum_func(column, window, rsuffix):\n",
    "    dataframe = pd.DataFrame()\n",
    "    dataframe = new_df.join(df2.groupby([column])['Amount'].rolling(window = window, closed = 'left').sum(), on = [column,'Date'], rsuffix = rsuffix)\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.groupby(['Cardnum','Date'])['Amount'].sum().to_frame().reset_index().set_index('Date')\n",
    "new_df = df.join(df.groupby(['Cardnum','Date'])['Amount'].sum(),on = ['Cardnum','Date'], rsuffix = '_cn_actual')\n",
    "\n",
    "new_df = amount_mean_func(column = 'Cardnum',window = '1D',rsuffix = '_cn_1d_avg')\n",
    "# new_df = amount_max_func(column = 'Cardnum',window = '1D',rsuffix = '_cn_1d_max')\n",
    "# new_df = amount_median_func(column = 'Cardnum',window = '1D',rsuffix = '_cn_1d_median')\n",
    "new_df = amount_sum_func(column = 'Cardnum',window = '1D',rsuffix = '_cn_1d_sum')\n",
    "new_df['Amount_cn_1d_act-avg'] = new_df['Amount_cn_actual'] - new_df['Amount_cn_1d_avg']\n",
    "# new_df['Amount_cn_1d_act-median'] = new_df['Amount_cn_actual'] - new_df['Amount_cn_1d_median']\n",
    "new_df['Amount_cn_1d_act/avg'] = new_df['Amount_cn_actual']/new_df['Amount_cn_1d_avg']\n",
    "# new_df['Amount_cn_1d_act/max'] = new_df['Amount_cn_actual']/new_df['Amount_cn_1d_max']\n",
    "new_df['Amount_cn_1d_act/sum'] = new_df['Amount_cn_actual']/new_df['Amount_cn_1d_sum']\n",
    "# new_df['Amount_cn_1d_act/median'] = new_df['Amount_cn_actual']/new_df['Amount_cn_1d_median']\n",
    "\n",
    "new_df = amount_mean_func(column = 'Cardnum',window = '4D',rsuffix = '_cn_4d_avg')\n",
    "new_df = amount_sum_func(column = 'Cardnum',window = '4D',rsuffix = '_cn_4d_sum')\n",
    "new_df['Amount_cn_4d_act-avg'] = new_df['Amount_cn_actual'] - new_df['Amount_cn_4d_avg']\n",
    "new_df['Amount_cn_4d_act/avg'] = new_df['Amount_cn_actual']/new_df['Amount_cn_4d_avg']\n",
    "new_df['Amount_cn_4d_act/sum'] = new_df['Amount_cn_actual']/new_df['Amount_cn_4d_sum']\n",
    "\n",
    "new_df = amount_mean_func(column = 'Cardnum',window = '7D',rsuffix = '_cn_7d_avg')\n",
    "new_df = amount_sum_func(column = 'Cardnum',window = '7D',rsuffix = '_cn_7d_sum')\n",
    "new_df['Amount_cn_7d_act-avg'] = new_df['Amount_cn_actual'] - new_df['Amount_cn_7d_avg']\n",
    "new_df['Amount_cn_7d_act/avg'] = new_df['Amount_cn_actual']/new_df['Amount_cn_7d_avg']\n",
    "new_df['Amount_cn_7d_act/sum'] = new_df['Amount_cn_actual']/new_df['Amount_cn_7d_sum']\n",
    "\n",
    "new_df = amount_mean_func(column = 'Cardnum',window = '14D',rsuffix = '_cn_14d_avg')\n",
    "new_df = amount_sum_func(column = 'Cardnum',window = '14D',rsuffix = '_cn_14d_sum')\n",
    "new_df['Amount_cn_14d_act-avg'] = new_df['Amount_cn_actual'] - new_df['Amount_cn_14d_avg']\n",
    "new_df['Amount_cn_14d_act/avg'] = new_df['Amount_cn_actual']/new_df['Amount_cn_14d_avg']\n",
    "new_df['Amount_cn_14d_act/sum'] = new_df['Amount_cn_actual']/new_df['Amount_cn_14d_sum']\n",
    "\n",
    "new_df = amount_mean_func(column = 'Cardnum',window = '30D',rsuffix = '_cn_30d_avg')\n",
    "new_df = amount_sum_func(column = 'Cardnum',window = '30D',rsuffix = '_cn_30d_sum')\n",
    "new_df['Amount_cn_30d_act-avg'] = new_df['Amount_cn_actual'] - new_df['Amount_cn_30d_avg']\n",
    "new_df['Amount_cn_30d_act/avg'] = new_df['Amount_cn_actual']/new_df['Amount_cn_30d_avg']\n",
    "new_df['Amount_cn_30d_act/sum'] = new_df['Amount_cn_actual']/new_df['Amount_cn_30d_sum']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.groupby(['Merchnum','Date'])['Amount'].sum().to_frame().reset_index().set_index('Date')\n",
    "new_df = new_df.join(df.groupby(['Merchnum','Date'])['Amount'].sum(),on = ['Merchnum','Date'], rsuffix = '_mn_actual')\n",
    "\n",
    "new_df = amount_mean_func(column = 'Merchnum',window = '1D',rsuffix = '_mn_1d_avg')\n",
    "new_df = amount_sum_func(column = 'Merchnum',window = '1D',rsuffix = '_mn_1d_sum')\n",
    "new_df['Amount_mn_1d_act-avg'] = new_df['Amount_mn_actual'] - new_df['Amount_mn_1d_avg']\n",
    "new_df['Amount_mn_1d_act/avg'] = new_df['Amount_mn_actual']/new_df['Amount_mn_1d_avg']\n",
    "new_df['Amount_mn_1d_act/sum'] = new_df['Amount_mn_actual']/new_df['Amount_mn_1d_sum']\n",
    "\n",
    "new_df = amount_mean_func(column = 'Merchnum',window = '4D',rsuffix = '_mn_4d_avg')\n",
    "new_df = amount_sum_func(column = 'Merchnum',window = '4D',rsuffix = '_mn_4d_sum')\n",
    "new_df['Amount_mn_4d_act-avg'] = new_df['Amount_mn_actual'] - new_df['Amount_mn_4d_avg']\n",
    "new_df['Amount_mn_4d_act/avg'] = new_df['Amount_mn_actual']/new_df['Amount_mn_4d_avg']\n",
    "new_df['Amount_mn_4d_act/sum'] = new_df['Amount_mn_actual']/new_df['Amount_mn_4d_sum']\n",
    "\n",
    "new_df = amount_mean_func(column = 'Merchnum',window = '7D',rsuffix = '_mn_7d_avg')\n",
    "new_df = amount_sum_func(column = 'Merchnum',window = '7D',rsuffix = '_mn_7d_sum')\n",
    "new_df['Amount_mn_7d_act-avg'] = new_df['Amount_mn_actual'] - new_df['Amount_mn_7d_avg']\n",
    "new_df['Amount_mn_7d_act/avg'] = new_df['Amount_mn_actual']/new_df['Amount_mn_7d_avg']\n",
    "new_df['Amount_mn_7d_act/sum'] = new_df['Amount_mn_actual']/new_df['Amount_mn_7d_sum']\n",
    "\n",
    "new_df = amount_mean_func(column = 'Merchnum',window = '14D',rsuffix = '_mn_14d_avg')\n",
    "new_df = amount_sum_func(column = 'Merchnum',window = '14D',rsuffix = '_mn_14d_sum')\n",
    "new_df['Amount_mn_14d_act-avg'] = new_df['Amount_mn_actual'] - new_df['Amount_mn_14d_avg']\n",
    "new_df['Amount_mn_14d_act/avg'] = new_df['Amount_mn_actual']/new_df['Amount_mn_14d_avg']\n",
    "new_df['Amount_mn_14d_act/sum'] = new_df['Amount_mn_actual']/new_df['Amount_mn_14d_sum']\n",
    "\n",
    "new_df = amount_mean_func(column = 'Merchnum',window = '30D',rsuffix = '_mn_30d_avg')\n",
    "new_df = amount_sum_func(column = 'Merchnum',window = '30D',rsuffix = '_mn_30d_sum')\n",
    "new_df['Amount_mn_30d_act-avg'] = new_df['Amount_mn_actual'] - new_df['Amount_mn_30d_avg']\n",
    "new_df['Amount_mn_30d_act/avg'] = new_df['Amount_mn_actual']/new_df['Amount_mn_30d_avg']\n",
    "new_df['Amount_mn_30d_act/sum'] = new_df['Amount_mn_actual']/new_df['Amount_mn_30d_sum']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.groupby(['Cardnum','Merchnum','Date'])['Amount'].sum().to_frame().reset_index().set_index('Date')\n",
    "new_df = new_df.join(df.groupby(['Cardnum','Merchnum','Date'])['Amount'].sum(),on = ['Cardnum','Merchnum','Date'], rsuffix = '_cn_mn_actual')\n",
    "\n",
    "new_df = new_df.join(df2.groupby(['Cardnum','Merchnum'])['Amount'].rolling(window = '1D', closed = 'left').mean(), on = ['Cardnum','Merchnum','Date'], rsuffix = '_cn_mn_1d_avg')\n",
    "new_df = new_df.join(df2.groupby(['Cardnum','Merchnum'])['Amount'].rolling(window = '1D', closed = 'left').sum(), on = ['Cardnum','Merchnum','Date'], rsuffix = '_cn_mn_1d_sum')\n",
    "new_df['Amount_cn_mn_1d_act-avg'] = new_df['Amount_cn_mn_actual'] - new_df['Amount_cn_mn_1d_avg']\n",
    "new_df['Amount_cn_mn_1d_act/avg'] = new_df['Amount_cn_mn_actual']/new_df['Amount_cn_mn_1d_avg']\n",
    "new_df['Amount_cn_mn_1d_act/sum'] = new_df['Amount_cn_mn_actual']/new_df['Amount_cn_mn_1d_sum']\n",
    "\n",
    "new_df = new_df.join(df2.groupby(['Cardnum','Merchnum'])['Amount'].rolling(window = '4D', closed = 'left').mean(), on = ['Cardnum','Merchnum','Date'], rsuffix = '_cn_mn_4d_avg')\n",
    "new_df = new_df.join(df2.groupby(['Cardnum','Merchnum'])['Amount'].rolling(window = '4D', closed = 'left').sum(), on = ['Cardnum','Merchnum','Date'], rsuffix = '_cn_mn_4d_sum')\n",
    "new_df['Amount_cn_mn_4d_act-avg'] = new_df['Amount_cn_mn_actual'] - new_df['Amount_cn_mn_4d_avg']\n",
    "new_df['Amount_cn_mn_4d_act/avg'] = new_df['Amount_cn_mn_actual']/new_df['Amount_cn_mn_4d_avg']\n",
    "new_df['Amount_cn_mn_4d_act/sum'] = new_df['Amount_cn_mn_actual']/new_df['Amount_cn_mn_4d_sum']\n",
    "\n",
    "new_df = new_df.join(df2.groupby(['Cardnum','Merchnum'])['Amount'].rolling(window = '7D', closed = 'left').mean(), on = ['Cardnum','Merchnum','Date'], rsuffix = '_cn_mn_7d_avg')\n",
    "new_df = new_df.join(df2.groupby(['Cardnum','Merchnum'])['Amount'].rolling(window = '7D', closed = 'left').sum(), on = ['Cardnum','Merchnum','Date'], rsuffix = '_cn_mn_7d_sum')\n",
    "new_df['Amount_cn_mn_7d_act-avg'] = new_df['Amount_cn_mn_actual'] - new_df['Amount_cn_mn_7d_avg']\n",
    "new_df['Amount_cn_mn_7d_act/avg'] = new_df['Amount_cn_mn_actual']/new_df['Amount_cn_mn_7d_avg']\n",
    "new_df['Amount_cn_mn_7d_act/sum'] = new_df['Amount_cn_mn_actual']/new_df['Amount_cn_mn_7d_sum']\n",
    "\n",
    "new_df = new_df.join(df2.groupby(['Cardnum','Merchnum'])['Amount'].rolling(window = '14D', closed = 'left').mean(), on = ['Cardnum','Merchnum','Date'], rsuffix = '_cn_mn_14d_avg')\n",
    "new_df = new_df.join(df2.groupby(['Cardnum','Merchnum'])['Amount'].rolling(window = '14D', closed = 'left').sum(), on = ['Cardnum','Merchnum','Date'], rsuffix = '_cn_mn_14d_sum')\n",
    "new_df['Amount_cn_mn_14d_act-avg'] = new_df['Amount_cn_mn_actual'] - new_df['Amount_cn_mn_14d_avg']\n",
    "new_df['Amount_cn_mn_14d_act/avg'] = new_df['Amount_cn_mn_actual']/new_df['Amount_cn_mn_14d_avg']\n",
    "new_df['Amount_cn_mn_14d_act/sum'] = new_df['Amount_cn_mn_actual']/new_df['Amount_cn_mn_14d_sum']\n",
    "\n",
    "new_df = new_df.join(df2.groupby(['Cardnum','Merchnum'])['Amount'].rolling(window = '30D', closed = 'left').mean(), on = ['Cardnum','Merchnum','Date'], rsuffix = '_cn_mn_30d_avg')\n",
    "new_df = new_df.join(df2.groupby(['Cardnum','Merchnum'])['Amount'].rolling(window = '30D', closed = 'left').sum(), on = ['Cardnum','Merchnum','Date'], rsuffix = '_cn_mn_30d_sum')\n",
    "new_df['Amount_cn_mn_30d_act-avg'] = new_df['Amount_cn_mn_actual'] - new_df['Amount_cn_mn_30d_avg']\n",
    "new_df['Amount_cn_mn_30d_act/avg'] = new_df['Amount_cn_mn_actual']/new_df['Amount_cn_mn_30d_avg']\n",
    "new_df['Amount_cn_mn_30d_act/sum'] = new_df['Amount_cn_mn_actual']/new_df['Amount_cn_mn_30d_sum']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.groupby(['Cardnum','Merch zip','Date'])['Amount'].sum().to_frame().reset_index().set_index('Date')\n",
    "new_df = new_df.join(df.groupby(['Cardnum','Merch zip','Date'])['Amount'].sum(),on = ['Cardnum','Merch zip','Date'], rsuffix = '_cn_zip_actual')\n",
    "\n",
    "new_df = new_df.join(df2.groupby(['Cardnum','Merch zip'])['Amount'].rolling(window = '1D', closed = 'left').mean(), on = ['Cardnum','Merch zip','Date'], rsuffix = '_cn_zip_1d_avg')\n",
    "new_df = new_df.join(df2.groupby(['Cardnum','Merch zip'])['Amount'].rolling(window = '1D', closed = 'left').sum(), on = ['Cardnum','Merch zip','Date'], rsuffix = '_cn_zip_1d_sum')\n",
    "new_df['Amount_cn_zip_1d_act-avg'] = new_df['Amount_cn_zip_actual'] - new_df['Amount_cn_zip_1d_avg']\n",
    "new_df['Amount_cn_zip_1d_act/avg'] = new_df['Amount_cn_zip_actual']/new_df['Amount_cn_zip_1d_avg']\n",
    "new_df['Amount_cn_zip_1d_act/sum'] = new_df['Amount_cn_zip_actual']/new_df['Amount_cn_zip_1d_sum']\n",
    "\n",
    "new_df = new_df.join(df2.groupby(['Cardnum','Merch zip'])['Amount'].rolling(window = '4D', closed = 'left').mean(), on = ['Cardnum','Merch zip','Date'], rsuffix = '_cn_zip_4d_avg')\n",
    "new_df = new_df.join(df2.groupby(['Cardnum','Merch zip'])['Amount'].rolling(window = '4D', closed = 'left').sum(), on = ['Cardnum','Merch zip','Date'], rsuffix = '_cn_zip_4d_sum')\n",
    "new_df['Amount_cn_zip_4d_act-avg'] = new_df['Amount_cn_zip_actual'] - new_df['Amount_cn_zip_4d_avg']\n",
    "new_df['Amount_cn_zip_4d_act/avg'] = new_df['Amount_cn_zip_actual']/new_df['Amount_cn_zip_4d_avg']\n",
    "new_df['Amount_cn_zip_4d_act/sum'] = new_df['Amount_cn_zip_actual']/new_df['Amount_cn_zip_4d_sum']\n",
    "\n",
    "new_df = new_df.join(df2.groupby(['Cardnum','Merch zip'])['Amount'].rolling(window = '7D', closed = 'left').mean(), on = ['Cardnum','Merch zip','Date'], rsuffix = '_cn_zip_7d_avg')\n",
    "new_df = new_df.join(df2.groupby(['Cardnum','Merch zip'])['Amount'].rolling(window = '7D', closed = 'left').sum(), on = ['Cardnum','Merch zip','Date'], rsuffix = '_cn_zip_7d_sum')\n",
    "new_df['Amount_cn_zip_7d_act-avg'] = new_df['Amount_cn_zip_actual'] - new_df['Amount_cn_zip_7d_avg']\n",
    "new_df['Amount_cn_zip_7d_act/avg'] = new_df['Amount_cn_zip_actual']/new_df['Amount_cn_zip_7d_avg']\n",
    "new_df['Amount_cn_zip_7d_act/sum'] = new_df['Amount_cn_zip_actual']/new_df['Amount_cn_zip_7d_sum']\n",
    "\n",
    "new_df = new_df.join(df2.groupby(['Cardnum','Merch zip'])['Amount'].rolling(window = '14D', closed = 'left').mean(), on = ['Cardnum','Merch zip','Date'], rsuffix = '_cn_zip_14d_avg')\n",
    "new_df = new_df.join(df2.groupby(['Cardnum','Merch zip'])['Amount'].rolling(window = '14D', closed = 'left').sum(), on = ['Cardnum','Merch zip','Date'], rsuffix = '_cn_zip_14d_sum')\n",
    "new_df['Amount_cn_zip_14d_act-avg'] = new_df['Amount_cn_zip_actual'] - new_df['Amount_cn_zip_14d_avg']\n",
    "new_df['Amount_cn_zip_14d_act/avg'] = new_df['Amount_cn_zip_actual']/new_df['Amount_cn_zip_14d_avg']\n",
    "new_df['Amount_cn_zip_14d_act/sum'] = new_df['Amount_cn_zip_actual']/new_df['Amount_cn_zip_14d_sum']\n",
    "\n",
    "new_df = new_df.join(df2.groupby(['Cardnum','Merch zip'])['Amount'].rolling(window = '30D', closed = 'left').mean(), on = ['Cardnum','Merch zip','Date'], rsuffix = '_cn_zip_30d_avg')\n",
    "new_df = new_df.join(df2.groupby(['Cardnum','Merch zip'])['Amount'].rolling(window = '30D', closed = 'left').sum(), on = ['Cardnum','Merch zip','Date'], rsuffix = '_cn_zip_30d_sum')\n",
    "new_df['Amount_cn_zip_30d_act-avg'] = new_df['Amount_cn_zip_actual'] - new_df['Amount_cn_zip_30d_avg']\n",
    "new_df['Amount_cn_zip_30d_act/avg'] = new_df['Amount_cn_zip_actual']/new_df['Amount_cn_zip_30d_avg']\n",
    "new_df['Amount_cn_zip_30d_act/sum'] = new_df['Amount_cn_zip_actual']/new_df['Amount_cn_zip_30d_sum']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.groupby(['Cardnum','Merch state','Date'])['Amount'].sum().to_frame().reset_index().set_index('Date')\n",
    "new_df = new_df.join(df.groupby(['Cardnum','Merch state','Date'])['Amount'].sum(),on = ['Cardnum','Merch state','Date'], rsuffix = '_cn_st_actual')\n",
    "\n",
    "new_df = new_df.join(df2.groupby(['Cardnum','Merch state'])['Amount'].rolling(window = '1D', closed = 'left').mean(), on = ['Cardnum','Merch state','Date'], rsuffix = '_cn_st_1d_avg')\n",
    "new_df = new_df.join(df2.groupby(['Cardnum','Merch state'])['Amount'].rolling(window = '1D', closed = 'left').sum(), on = ['Cardnum','Merch state','Date'], rsuffix = '_cn_st_1d_sum')\n",
    "new_df['Amount_cn_st_1d_act-avg'] = new_df['Amount_cn_st_actual'] - new_df['Amount_cn_st_1d_avg']\n",
    "new_df['Amount_cn_st_1d_act/avg'] = new_df['Amount_cn_st_actual']/new_df['Amount_cn_st_1d_avg']\n",
    "new_df['Amount_cn_st_1d_act/sum'] = new_df['Amount_cn_st_actual']/new_df['Amount_cn_st_1d_sum']\n",
    "\n",
    "new_df = new_df.join(df2.groupby(['Cardnum','Merch state'])['Amount'].rolling(window = '4D', closed = 'left').mean(), on = ['Cardnum','Merch state','Date'], rsuffix = '_cn_st_4d_avg')\n",
    "new_df = new_df.join(df2.groupby(['Cardnum','Merch state'])['Amount'].rolling(window = '4D', closed = 'left').sum(), on = ['Cardnum','Merch state','Date'], rsuffix = '_cn_st_4d_sum')\n",
    "new_df['Amount_cn_st_4d_act-avg'] = new_df['Amount_cn_st_actual'] - new_df['Amount_cn_st_4d_avg']\n",
    "new_df['Amount_cn_st_4d_act/avg'] = new_df['Amount_cn_st_actual']/new_df['Amount_cn_st_4d_avg']\n",
    "new_df['Amount_cn_st_4d_act/sum'] = new_df['Amount_cn_st_actual']/new_df['Amount_cn_st_4d_sum']\n",
    "\n",
    "new_df = new_df.join(df2.groupby(['Cardnum','Merch state'])['Amount'].rolling(window = '7D', closed = 'left').mean(), on = ['Cardnum','Merch state','Date'], rsuffix = '_cn_st_7d_avg')\n",
    "new_df = new_df.join(df2.groupby(['Cardnum','Merch state'])['Amount'].rolling(window = '7D', closed = 'left').sum(), on = ['Cardnum','Merch state','Date'], rsuffix = '_cn_st_7d_sum')\n",
    "new_df['Amount_cn_st_7d_act-avg'] = new_df['Amount_cn_st_actual'] - new_df['Amount_cn_st_7d_avg']\n",
    "new_df['Amount_cn_st_7d_act/avg'] = new_df['Amount_cn_st_actual']/new_df['Amount_cn_st_7d_avg']\n",
    "new_df['Amount_cn_st_7d_act/sum'] = new_df['Amount_cn_st_actual']/new_df['Amount_cn_st_7d_sum']\n",
    "\n",
    "new_df = new_df.join(df2.groupby(['Cardnum','Merch state'])['Amount'].rolling(window = '14D', closed = 'left').mean(), on = ['Cardnum','Merch state','Date'], rsuffix = '_cn_st_14d_avg')\n",
    "new_df = new_df.join(df2.groupby(['Cardnum','Merch state'])['Amount'].rolling(window = '14D', closed = 'left').sum(), on = ['Cardnum','Merch state','Date'], rsuffix = '_cn_st_14d_sum')\n",
    "new_df['Amount_cn_st_14d_act-avg'] = new_df['Amount_cn_st_actual'] - new_df['Amount_cn_st_14d_avg']\n",
    "new_df['Amount_cn_st_14d_act/avg'] = new_df['Amount_cn_st_actual']/new_df['Amount_cn_st_14d_avg']\n",
    "new_df['Amount_cn_st_14d_act/sum'] = new_df['Amount_cn_st_actual']/new_df['Amount_cn_st_14d_sum']\n",
    "\n",
    "new_df = new_df.join(df2.groupby(['Cardnum','Merch state'])['Amount'].rolling(window = '30D', closed = 'left').mean(), on = ['Cardnum','Merch state','Date'], rsuffix = '_cn_st_30d_avg')\n",
    "new_df = new_df.join(df2.groupby(['Cardnum','Merch state'])['Amount'].rolling(window = '30D', closed = 'left').sum(), on = ['Cardnum','Merch state','Date'], rsuffix = '_cn_st_30d_sum')\n",
    "new_df['Amount_cn_st_30d_act-avg'] = new_df['Amount_cn_st_actual'] - new_df['Amount_cn_st_30d_avg']\n",
    "new_df['Amount_cn_st_30d_act/avg'] = new_df['Amount_cn_st_actual']/new_df['Amount_cn_st_30d_avg']\n",
    "new_df['Amount_cn_st_30d_act/sum'] = new_df['Amount_cn_st_actual']/new_df['Amount_cn_st_30d_sum']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### frequency variables\n",
    "new_df['Date'] = new_df['Date'].astype('datetime64[ns]')\n",
    "\n",
    "# Cardnum\n",
    "df3 = df.set_index('Date').groupby(['Cardnum'])['Recnum'].rolling(window = '1D', closed = 'left').count().to_frame().reset_index().drop_duplicates(subset = ['Cardnum','Date'],keep = 'first')\n",
    "new_df = new_df.merge(df3.rename(columns = {'Recnum':'Freq_cn_1d'}), on = ['Cardnum','Date'])\n",
    "\n",
    "df3 = df.set_index('Date').groupby(['Cardnum'])['Recnum'].rolling(window = '4D', closed = 'left').count().to_frame().reset_index().drop_duplicates(subset = ['Cardnum','Date'],keep = 'first')\n",
    "new_df = new_df.merge(df3.rename(columns = {'Recnum':'Freq_cn_4d'}), on = ['Cardnum','Date'])\n",
    "\n",
    "df3 = df.set_index('Date').groupby(['Cardnum'])['Recnum'].rolling(window = '7D', closed = 'left').count().to_frame().reset_index().drop_duplicates(subset = ['Cardnum','Date'],keep = 'first')\n",
    "new_df = new_df.merge(df3.rename(columns = {'Recnum':'Freq_cn_7d'}), on = ['Cardnum','Date'])\n",
    "\n",
    "df3 = df.set_index('Date').groupby(['Cardnum'])['Recnum'].rolling(window = '14D', closed = 'left').count().to_frame().reset_index().drop_duplicates(subset = ['Cardnum','Date'],keep = 'first')\n",
    "new_df = new_df.merge(df3.rename(columns = {'Recnum':'Freq_cn_14d'}), on = ['Cardnum','Date'])\n",
    "\n",
    "df3 = df.set_index('Date').groupby(['Cardnum'])['Recnum'].rolling(window = '30D', closed = 'left').count().to_frame().reset_index().drop_duplicates(subset = ['Cardnum','Date'],keep = 'first')\n",
    "new_df = new_df.merge(df3.rename(columns = {'Recnum':'Freq_cn_30d'}), on = ['Cardnum','Date'])\n",
    "\n",
    "# Merchnum\n",
    "df3 = df.set_index('Date').groupby(['Merchnum'])['Recnum'].rolling(window = '1D', closed = 'left').count().to_frame().reset_index().drop_duplicates(subset = ['Merchnum','Date'],keep = 'first')\n",
    "new_df = new_df.merge(df3.rename(columns = {'Recnum':'Freq_mn_1d'}), on = ['Merchnum','Date'])\n",
    "\n",
    "df3 = df.set_index('Date').groupby(['Merchnum'])['Recnum'].rolling(window = '4D', closed = 'left').count().to_frame().reset_index().drop_duplicates(subset = ['Merchnum','Date'],keep = 'first')\n",
    "new_df = new_df.merge(df3.rename(columns = {'Recnum':'Freq_mn_4d'}), on = ['Merchnum','Date'])\n",
    "\n",
    "df3 = df.set_index('Date').groupby(['Merchnum'])['Recnum'].rolling(window = '7D', closed = 'left').count().to_frame().reset_index().drop_duplicates(subset = ['Merchnum','Date'],keep = 'first')\n",
    "new_df = new_df.merge(df3.rename(columns = {'Recnum':'Freq_mn_7d'}), on = ['Merchnum','Date'])\n",
    "\n",
    "df3 = df.set_index('Date').groupby(['Merchnum'])['Recnum'].rolling(window = '14D', closed = 'left').count().to_frame().reset_index().drop_duplicates(subset = ['Merchnum','Date'],keep = 'first')\n",
    "new_df = new_df.merge(df3.rename(columns = {'Recnum':'Freq_mn_14d'}), on = ['Merchnum','Date'])\n",
    "\n",
    "df3 = df.set_index('Date').groupby(['Merchnum'])['Recnum'].rolling(window = '30D', closed = 'left').count().to_frame().reset_index().drop_duplicates(subset = ['Merchnum','Date'],keep = 'first')\n",
    "new_df = new_df.merge(df3.rename(columns = {'Recnum':'Freq_mn_30d'}), on = ['Merchnum','Date'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cardnum & Merchnum\n",
    "df3 = df.set_index('Date').groupby(['Cardnum','Merchnum'])['Recnum'].rolling(window = '1D', closed = 'left').count().to_frame().reset_index().drop_duplicates(subset = ['Cardnum','Merchnum','Date'],keep = 'first')\n",
    "new_df = new_df.merge(df3.rename(columns = {'Recnum':'Freq_cn_mn_1d'}), on = ['Cardnum','Merchnum','Date'])\n",
    "\n",
    "df3 = df.set_index('Date').groupby(['Cardnum','Merchnum'])['Recnum'].rolling(window = '4D', closed = 'left').count().to_frame().reset_index().drop_duplicates(subset = ['Cardnum','Merchnum','Date'],keep = 'first')\n",
    "new_df = new_df.merge(df3.rename(columns = {'Recnum':'Freq_cn_mn_4d'}), on = ['Cardnum','Merchnum','Date'])\n",
    "\n",
    "df3 = df.set_index('Date').groupby(['Cardnum','Merchnum'])['Recnum'].rolling(window = '7D', closed = 'left').count().to_frame().reset_index().drop_duplicates(subset = ['Cardnum','Merchnum','Date'],keep = 'first')\n",
    "new_df = new_df.merge(df3.rename(columns = {'Recnum':'Freq_cn_mn_7d'}), on = ['Cardnum','Merchnum','Date'])\n",
    "\n",
    "df3 = df.set_index('Date').groupby(['Cardnum','Merchnum'])['Recnum'].rolling(window = '14D', closed = 'left').count().to_frame().reset_index().drop_duplicates(subset = ['Cardnum','Merchnum','Date'],keep = 'first')\n",
    "new_df = new_df.merge(df3.rename(columns = {'Recnum':'Freq_cn_mn_14d'}), on = ['Cardnum','Merchnum','Date'])\n",
    "\n",
    "df3 = df.set_index('Date').groupby(['Cardnum','Merchnum'])['Recnum'].rolling(window = '30D', closed = 'left').count().to_frame().reset_index().drop_duplicates(subset = ['Cardnum','Merchnum','Date'],keep = 'first')\n",
    "new_df = new_df.merge(df3.rename(columns = {'Recnum':'Freq_cn_mn_30d'}), on = ['Cardnum','Merchnum','Date'])\n",
    "\n",
    "# Cardnum & Merch zip\n",
    "df3 = df.set_index('Date').groupby(['Cardnum','Merch zip'])['Recnum'].rolling(window = '1D', closed = 'left').count().to_frame().reset_index().drop_duplicates(subset = ['Cardnum','Merch zip','Date'],keep = 'first')\n",
    "new_df = new_df.merge(df3.rename(columns = {'Recnum':'Freq_cn_zip_1d'}), on = ['Cardnum','Merch zip','Date'])\n",
    "\n",
    "df3 = df.set_index('Date').groupby(['Cardnum','Merch zip'])['Recnum'].rolling(window = '4D', closed = 'left').count().to_frame().reset_index().drop_duplicates(subset = ['Cardnum','Merch zip','Date'],keep = 'first')\n",
    "new_df = new_df.merge(df3.rename(columns = {'Recnum':'Freq_cn_zip_4d'}), on = ['Cardnum','Merch zip','Date'])\n",
    "\n",
    "df3 = df.set_index('Date').groupby(['Cardnum','Merch zip'])['Recnum'].rolling(window = '7D', closed = 'left').count().to_frame().reset_index().drop_duplicates(subset = ['Cardnum','Merch zip','Date'],keep = 'first')\n",
    "new_df = new_df.merge(df3.rename(columns = {'Recnum':'Freq_cn_zip_7d'}), on = ['Cardnum','Merch zip','Date'])\n",
    "\n",
    "df3 = df.set_index('Date').groupby(['Cardnum','Merch zip'])['Recnum'].rolling(window = '14D', closed = 'left').count().to_frame().reset_index().drop_duplicates(subset = ['Cardnum','Merch zip','Date'],keep = 'first')\n",
    "new_df = new_df.merge(df3.rename(columns = {'Recnum':'Freq_cn_zip_14d'}), on = ['Cardnum','Merch zip','Date'])\n",
    "\n",
    "df3 = df.set_index('Date').groupby(['Cardnum','Merch zip'])['Recnum'].rolling(window = '30D', closed = 'left').count().to_frame().reset_index().drop_duplicates(subset = ['Cardnum','Merch zip','Date'],keep = 'first')\n",
    "new_df = new_df.merge(df3.rename(columns = {'Recnum':'Freq_cn_zip_30d'}), on = ['Cardnum','Merch zip','Date'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cardnum & Merch state\n",
    "df3 = df.set_index('Date').groupby(['Cardnum','Merch state'])['Recnum'].rolling(window = '1D', closed = 'left').count().to_frame().reset_index().drop_duplicates(subset = ['Cardnum','Merch state','Date'],keep = 'first')\n",
    "new_df = new_df.merge(df3.rename(columns = {'Recnum':'Freq_cn_st_1d'}), on = ['Cardnum','Merch state','Date'])\n",
    "\n",
    "df3 = df.set_index('Date').groupby(['Cardnum','Merch state'])['Recnum'].rolling(window = '4D', closed = 'left').count().to_frame().reset_index().drop_duplicates(subset = ['Cardnum','Merch state','Date'],keep = 'first')\n",
    "new_df = new_df.merge(df3.rename(columns = {'Recnum':'Freq_cn_st_4d'}), on = ['Cardnum','Merch state','Date'])\n",
    "\n",
    "df3 = df.set_index('Date').groupby(['Cardnum','Merch state'])['Recnum'].rolling(window = '7D', closed = 'left').count().to_frame().reset_index().drop_duplicates(subset = ['Cardnum','Merch state','Date'],keep = 'first')\n",
    "new_df = new_df.merge(df3.rename(columns = {'Recnum':'Freq_cn_st_7d'}), on = ['Cardnum','Merch state','Date'])\n",
    "\n",
    "df3 = df.set_index('Date').groupby(['Cardnum','Merch state'])['Recnum'].rolling(window = '14D', closed = 'left').count().to_frame().reset_index().drop_duplicates(subset = ['Cardnum','Merch state','Date'],keep = 'first')\n",
    "new_df = new_df.merge(df3.rename(columns = {'Recnum':'Freq_cn_st_14d'}), on = ['Cardnum','Merch state','Date'])\n",
    "\n",
    "df3 = df.set_index('Date').groupby(['Cardnum','Merch state'])['Recnum'].rolling(window = '30D', closed = 'left').count().to_frame().reset_index().drop_duplicates(subset = ['Cardnum','Merch state','Date'],keep = 'first')\n",
    "new_df = new_df.merge(df3.rename(columns = {'Recnum':'Freq_cn_st_30d'}), on = ['Cardnum','Merch state','Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "165"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(new_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Days since expert variables\n",
    "df3 = df.set_index('Date').groupby(['Cardnum'])['Recnum'].rolling(window = '1D', closed = 'left').count().to_frame().reset_index().drop_duplicates(subset = ['Cardnum','Date'])\n",
    "df3['Date_lag'] = df3.groupby('Cardnum')['Date'].shift(1)\n",
    "df3['last_cn'] = (df3['Date'] - df3['Date_lag']).dt.days\n",
    "new_df = new_df.merge(df3[['Cardnum','Date','last_cn']])\n",
    "\n",
    "df3 = df.set_index('Date').groupby(['Merchnum'])['Recnum'].rolling(window = '1D', closed = 'left').count().to_frame().reset_index().drop_duplicates(subset = ['Merchnum','Date'])\n",
    "df3['Date_lag'] = df3.groupby('Merchnum')['Date'].shift(1)\n",
    "df3['last_mn'] = (df3['Date'] - df3['Date_lag']).dt.days\n",
    "new_df = new_df.merge(df3[['Merchnum','Date','last_mn']])\n",
    "\n",
    "df3 = df.set_index('Date').groupby(['Cardnum','Merchnum'])['Recnum'].rolling(window = '1D', closed = 'left').count().to_frame().reset_index().drop_duplicates(subset = ['Cardnum','Merchnum','Date'])\n",
    "df3['Date_lag'] = df3.groupby(['Cardnum','Merchnum'])['Date'].shift(1)\n",
    "df3['last_cn_mn'] = (df3['Date'] - df3['Date_lag']).dt.days\n",
    "new_df = new_df.merge(df3[['Cardnum','Merchnum','Date','last_cn_mn']])\n",
    "\n",
    "df3 = df.set_index('Date').groupby(['Cardnum','Merch zip'])['Recnum'].rolling(window = '1D', closed = 'left').count().to_frame().reset_index().drop_duplicates(subset = ['Cardnum','Merch zip','Date'])\n",
    "df3['Date_lag'] = df3.groupby(['Cardnum','Merch zip'])['Date'].shift(1)\n",
    "df3['last_cn_zip'] = (df3['Date'] - df3['Date_lag']).dt.days\n",
    "new_df = new_df.merge(df3[['Cardnum','Merch zip','Date','last_cn_zip']])\n",
    "\n",
    "df3 = df.set_index('Date').groupby(['Cardnum','Merch state'])['Recnum'].rolling(window = '1D', closed = 'left').count().to_frame().reset_index().drop_duplicates(subset = ['Cardnum','Merch state','Date'])\n",
    "df3['Date_lag'] = df3.groupby(['Cardnum','Merch state'])['Date'].shift(1)\n",
    "df3['last_cn_st'] = (df3['Date'] - df3['Date_lag']).dt.days\n",
    "new_df = new_df.merge(df3[['Cardnum','Merch state','Date','last_cn_st']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Velocity deviation\n",
    "new_df['velo_cn_avg7d'] = new_df['Freq_cn_1d']/(new_df['Freq_cn_7d']/7)\n",
    "new_df['velo_cn_avg14d'] = new_df['Freq_cn_1d']/(new_df['Freq_cn_14d']/14)\n",
    "new_df['velo_cn_avg30d'] = new_df['Freq_cn_1d']/(new_df['Freq_cn_30d']/30)\n",
    "new_df['velo_mn_avg7d'] = new_df['Freq_mn_1d']/(new_df['Freq_mn_7d']/7)\n",
    "new_df['velo_mn_avg14d'] = new_df['Freq_mn_1d']/(new_df['Freq_mn_14d']/14)\n",
    "new_df['velo_mn_avg30d'] = new_df['Freq_mn_1d']/(new_df['Freq_mn_30d']/30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill na with 0\n",
    "new_df = new_df.fillna(0)\n",
    "\n",
    "# export amount expert variables\n",
    "new_df.to_csv('AmountVariables.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.read_csv('AmountVariables.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## add a dummy variable as for sanity checks\n",
    "new_df['random'] = np.random.randint(0, 100, new_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## calculate ks score for all variables\n",
    "from scipy.stats import ks_2samp\n",
    "\n",
    "ks_df = pd.DataFrame()\n",
    "# ks_df['col'] = list(new_df)[10,:]\n",
    "ks_df['col'] = list(new_df[new_df.columns[~new_df.columns.isin(['Amount_cn_actual','Amount_mn_actual','Amount_cn_mn_actual','Amount_cn_zip_actual','Amount_cn_st_actual'])]])[10:]\n",
    "\n",
    "ks_df['p_value'] = ''\n",
    "ks_df['ks_score'] = ''\n",
    "for i in range(len(ks_df)):\n",
    "    ks_df['ks_score'][i] = ks_2samp(new_df[new_df['Fraud'] == 0][ks_df['col'][i]], new_df[new_df['Fraud'] == 1][ks_df['col'][i]])[0]\n",
    "    ks_df['p_value'][i] = ks_2samp(new_df[new_df['Fraud'] == 0][ks_df['col'][i]], new_df[new_df['Fraud'] == 1][ks_df['col'][i]])[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## calculate fraud detection rate for all variables\n",
    "def fdr_cal(row):\n",
    "    col_name = row['col']\n",
    "    df_temp1 = new_df.sort_values(col_name, ascending = False)\n",
    "    df_temp_top1 = df_temp1[:round(len(new_df)*0.03)]\n",
    "    fdr1 = sum(df_temp_top1['Fraud'])/sum(df_temp1['Fraud'])\n",
    "    df_temp2 = new_df.sort_values(col_name, ascending = True)\n",
    "    df_temp_top2 = df_temp2[:round(len(new_df)*0.03)]\n",
    "    fdr2 = sum(df_temp_top2['Fraud'])/sum(df_temp2['Fraud'])\n",
    "    return max(fdr1, fdr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks_df['fdr'] = ks_df.apply(lambda row: fdr_cal(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## sort variables by fdr\n",
    "fdr_sorted_list = ks_df.sort_values('fdr', ascending = False)\n",
    "# fdr_sorted_list.to_pickle('fdr_sorted_list.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## sort variables by ks_score\n",
    "ks_score_sorted_list = ks_df.sort_values('ks_score', ascending = False)\n",
    "# ks_score_sorted_list.to_pickle('ks_score_sorted_list.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ks_df['ks_rank'] = ks_df['ks_score'].rank(ascending = False)\n",
    "# ks_df['fdr_rank'] = ks_df['fdr'].rank(ascending = False)\n",
    "# ks_df['avg_rank'] = ks_df['ks_rank'] * 0.6 + ks_df['fdr_rank'] * 0.4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Divide into OOT and Train/Test\n",
    "\n",
    "## Standardizes in-place\n",
    "def standardize(df, colnames):\n",
    "    for col in colnames:\n",
    "        tmp_sd=df[col].std()\n",
    "        tmp_mean=df[col].mean()\n",
    "        df[col] = (df[col]-tmp_mean) / tmp_sd\n",
    "standardize(new_df,list(new_df)[11:])\n",
    "\n",
    "int_df = new_df[new_df[\"Date\"] < new_df[\"Date\"][84461]] \n",
    "oot_df = new_df[new_df[\"Date\"] > new_df[\"Date\"][84288]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## calculate ks score for all variables\n",
    "def fdr_cal(row, df):\n",
    "    col_name = row['col']\n",
    "    df_temp = df.sort_values(col_name, ascending = False)\n",
    "    df_temp_top = df_temp[:round(len(df)*0.03)]\n",
    "    df_temp_bot = df_temp.tail(round(len(df)*0.03))\n",
    "    top_fdr= sum(df_temp_top['Fraud'])/sum(df_temp['Fraud'])\n",
    "    bot_fdr= sum(df_temp_bot['Fraud'])/sum(df_temp['Fraud'])\n",
    "#     print(str(top_fdr)+ \" \"+str(bot_fdr))\n",
    "    return(max(top_fdr, bot_fdr))\n",
    "\n",
    "def ks_fdr(df):\n",
    "    ks_df = pd.DataFrame()\n",
    "    ks_df['col'] = list(df)[10:]\n",
    "    ks_df['p_value'] = ''\n",
    "    ks_df['ks_score'] = ''\n",
    "    # Calc KS\n",
    "    for i in range(len(ks_df)):\n",
    "        ks_df['ks_score'][i] = ks_2samp(df[df['Fraud'] == 0][ks_df['col'][i]], df[df['Fraud'] == 1][ks_df['col'][i]])[0]\n",
    "        ks_df['p_value'][i] = ks_2samp(df[df['Fraud'] == 0][ks_df['col'][i]], df[df['Fraud'] == 1][ks_df['col'][i]])[1]\n",
    "    # Calc FDR\n",
    "    ks_df['fdr'] = ks_df.apply(lambda row: fdr_cal(row, df), axis=1)\n",
    "    return ks_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ks_fdr_int = ks_fdr(int_df)\n",
    "ks_fdr_oot = ks_fdr(oot_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks_fdr_int['ks_rank'] = ks_fdr_int['ks_score'].rank(ascending = False)\n",
    "ks_fdr_int['fdr_rank'] = ks_fdr_int['fdr'].rank(ascending = False)\n",
    "ks_fdr_int['avg_rank'] = ks_fdr_int['ks_rank'] * 0.6 + ks_fdr_int['fdr_rank'] * 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                          Fraud\n",
       "79          Amount_cn_zip_actual\n",
       "53           Amount_cn_mn_actual\n",
       "105          Amount_cn_st_actual\n",
       "27              Amount_mn_actual\n",
       "1               Amount_cn_actual\n",
       "24         Amount_cn_30d_act-avg\n",
       "50         Amount_mn_30d_act-avg\n",
       "19         Amount_cn_14d_act-avg\n",
       "45         Amount_mn_14d_act-avg\n",
       "40          Amount_mn_7d_act-avg\n",
       "14          Amount_cn_7d_act-avg\n",
       "117          Amount_cn_st_7d_sum\n",
       "35          Amount_mn_4d_act-avg\n",
       "112          Amount_cn_st_4d_sum\n",
       "111          Amount_cn_st_4d_avg\n",
       "86          Amount_cn_zip_4d_sum\n",
       "18             Amount_cn_14d_sum\n",
       "85          Amount_cn_zip_4d_avg\n",
       "13              Amount_cn_7d_sum\n",
       "122         Amount_cn_st_14d_sum\n",
       "59           Amount_cn_mn_4d_avg\n",
       "128     Amount_cn_st_30d_act-avg\n",
       "60           Amount_cn_mn_4d_sum\n",
       "116          Amount_cn_st_7d_avg\n",
       "91          Amount_cn_zip_7d_sum\n",
       "8               Amount_cn_4d_sum\n",
       "7               Amount_cn_4d_avg\n",
       "51         Amount_mn_30d_act/avg\n",
       "127         Amount_cn_st_30d_sum\n",
       "                 ...            \n",
       "100        Amount_cn_zip_30d_avg\n",
       "52         Amount_mn_30d_act/sum\n",
       "101        Amount_cn_zip_30d_sum\n",
       "69          Amount_cn_mn_14d_avg\n",
       "123     Amount_cn_st_14d_act-avg\n",
       "3               Amount_cn_1d_sum\n",
       "2               Amount_cn_1d_avg\n",
       "75          Amount_cn_mn_30d_sum\n",
       "47         Amount_mn_14d_act/sum\n",
       "43             Amount_mn_14d_avg\n",
       "20         Amount_cn_14d_act/avg\n",
       "41          Amount_mn_7d_act/avg\n",
       "74          Amount_cn_mn_30d_avg\n",
       "38              Amount_mn_7d_avg\n",
       "80          Amount_cn_zip_1d_avg\n",
       "81          Amount_cn_zip_1d_sum\n",
       "39              Amount_mn_7d_sum\n",
       "102    Amount_cn_zip_30d_act-avg\n",
       "113      Amount_cn_st_4d_act-avg\n",
       "118      Amount_cn_st_7d_act-avg\n",
       "28              Amount_mn_1d_avg\n",
       "29              Amount_mn_1d_sum\n",
       "48             Amount_mn_30d_avg\n",
       "76      Amount_cn_mn_30d_act-avg\n",
       "55           Amount_cn_mn_1d_sum\n",
       "54           Amount_cn_mn_1d_avg\n",
       "21         Amount_cn_14d_act/sum\n",
       "42          Amount_mn_7d_act/sum\n",
       "152                Freq_cn_st_4d\n",
       "36          Amount_mn_4d_act/avg\n",
       "Name: col, Length: 80, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_features = ks_fdr_int.sort_values(\"avg_rank\")[\"col\"].head(80)\n",
    "top_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "estimator = LogisticRegression(solver=\"liblinear\", max_iter=300)\n",
    "selector = RFE(estimator, 20, step=1)\n",
    "selector = selector.fit(int_df[top_features], int_df[\"Fraud\"])\n",
    "final_features=top_features[selector.support_]\n",
    "selected_df = pd.DataFrame(int_df, columns=list(final_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_df.to_csv(\"selected_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_df=pd.read_csv(\"selected_df.csv\")\n",
    "\n",
    "train, test = train_test_split(selected_df, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "175"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(oot_df[\"Fraud\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 100 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed: 14.4min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed: 80.0min\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed: 83.6min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 1500,\n",
       " 'min_samples_split': 2,\n",
       " 'min_samples_leaf': 2,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_depth': 20,\n",
       " 'criterion': 'entropy',\n",
       " 'bootstrap': True}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### --------- Rogers Models RF and SVM ------------\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "features=['Amount_cn_st_actual', 'Amount_mn_30d_act-avg', 'Amount_cn_14d_act-avg',\n",
    " 'Amount_mn_7d_act-avg', 'Amount_cn_7d_act-avg', 'Amount_cn_st_7d_sum',\n",
    " 'Amount_cn_st_4d_avg', 'Amount_cn_14d_sum', 'Amount_cn_st_30d_act-avg',\n",
    " 'Amount_cn_st_7d_avg', 'Amount_mn_30d_act/avg', 'Amount_cn_30d_act/avg',\n",
    " 'Amount_cn_mn_7d_sum', 'Amount_cn_30d_sum', 'Amount_cn_30d_act/sum',\n",
    " 'Amount_cn_zip_30d_avg', 'Amount_cn_zip_30d_sum', 'Amount_cn_st_7d_act-avg',\n",
    " 'Amount_mn_1d_avg']\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "## RF Hyperparams\n",
    "max_depth = [5,10,20,30]\n",
    "max_depth.append(None)\n",
    "rf_grid = {'n_estimators': [100, 500,1500],\n",
    "           'max_features': ['auto', 'sqrt'],\n",
    "           'criterion':['gini','entropy'],\n",
    "           'max_depth': max_depth,\n",
    "           'min_samples_split': [2, 5, 10],\n",
    "           'min_samples_leaf':[2, 5, 10, 15],\n",
    "           'bootstrap': [True]}\n",
    "rf_best = {'n_estimators': [100],\n",
    "         'min_samples_split': [2],\n",
    "         'min_samples_leaf': [4],\n",
    "         'max_features': ['auto'],\n",
    "         'max_depth': [90],\n",
    "         'bootstrap': [True]}\n",
    "# print(rf_grid)\n",
    "rf_random = RandomizedSearchCV(estimator = rf, \n",
    "                               param_distributions = rf_grid, \n",
    "                               n_iter = 100, \n",
    "                               cv = 2,\n",
    "                               verbose=1, \n",
    "                               random_state=123, \n",
    "                               n_jobs = -1)\n",
    "rf_random.fit(train[list(train)[2:]], train[\"Fraud\"])\n",
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy\n",
      "0.99878201441282940.99672389974343790.9855627578078963\n",
      "auc\n",
      "0.94748447586128440.84770647926973440.5940358891633\n",
      "fdr\n",
      "1.0\n",
      "0.8932806324110671\n",
      "0.6514285714285715\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "def metrics_cal(mod):\n",
    "    train[\"preds\"]=\"\"\n",
    "    test[\"preds\"]=\"\"\n",
    "    oot_df[\"preds\"]=\"\"\n",
    "    \n",
    "    train[\"preds\"]=mod.predict(train[features])\n",
    "    test[\"preds\"]=mod.predict(test[features])\n",
    "    oot_df[\"preds\"]=mod.predict(oot_df[features])\n",
    "    \n",
    "    print(\"accuracy\")\n",
    "    ra_=metrics.accuracy_score(train[\"Fraud\"], train[\"preds\"])\n",
    "    ta_=metrics.accuracy_score(test[\"Fraud\"], test[\"preds\"])\n",
    "    oa_=metrics.accuracy_score(oot_df[\"Fraud\"], oot_df[\"preds\"])\n",
    "    print(str(ra_) + str(ta_) + str(oa_))\n",
    "    \n",
    "    print(\"auc\")\n",
    "    rc_=metrics.roc_auc_score(train[\"Fraud\"], train[\"preds\"])\n",
    "    tc_=metrics.roc_auc_score(test[\"Fraud\"], test[\"preds\"])\n",
    "    oc_=metrics.roc_auc_score(oot_df[\"Fraud\"], oot_df[\"preds\"])\n",
    "    print(str(rc_) + str(tc_) + str(oc_))\n",
    "    \n",
    "    train[\"preds\"]=mod.predict_proba(train[features])[:,1]\n",
    "    test[\"preds\"]=mod.predict_proba(test[features])[:,1]\n",
    "    oot_df[\"preds\"]=mod.predict_proba(oot_df[features])[:,1]\n",
    "    \n",
    "    print(\"fdr\")\n",
    "    \n",
    "    for df in [train,test,oot_df]:\n",
    "        df_temp = df.sort_values(\"preds\", ascending = False)\n",
    "        df_temp_top = df_temp[:round(len(df)*0.03)]\n",
    "        df_temp_bot = df_temp.tail(round(len(df)*0.03))\n",
    "        top_fdr= sum(df_temp_top['Fraud'])/sum(df_temp['Fraud'])\n",
    "        bot_fdr= sum(df_temp_bot['Fraud'])/sum(df_temp['Fraud'])\n",
    "        print(max(top_fdr, bot_fdr))\n",
    "\n",
    "# rf_preds=rf.predict_proba(test[list(train)[2:]])[:,1]\n",
    "\n",
    "metrics_cal(rf_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:  6.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score='raise-deprecating',\n",
       "          estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='rbf', max_iter=-1, probability=True, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False),\n",
       "          fit_params=None, iid='warn', n_iter=50, n_jobs=-1,\n",
       "          param_distributions={'shrinking': [True], 'kernel': ['rbf'], 'gamma': ['auto'], 'degree': [2], 'class_weight': ['balanced']},\n",
       "          pre_dispatch='2*n_jobs', random_state=123, refit=True,\n",
       "          return_train_score='warn', scoring=None, verbose=1)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC  \n",
    "svc = SVC(kernel=\"rbf\",probability=True)    \n",
    "svm_grid = {'kernel': [\"linear\", \"rbf\"],\n",
    "            'degree': [2, 3, 4],\n",
    "            'gamma': [\"auto\"],\n",
    "            'shrinking': [True,False],\n",
    "            'class_weight': [\"balanced\"]}\n",
    "\n",
    "svm_best= {'shrinking': [True],\n",
    "           'kernel': ['rbf'],\n",
    "           'gamma': ['auto'],\n",
    "           'degree': [2],\n",
    "           'class_weight': [\"balanced\"]}\n",
    "\n",
    "svm_random = RandomizedSearchCV(estimator = svc, \n",
    "                                param_distributions = svm_best,\n",
    "                                n_jobs=-1,\n",
    "                                n_iter = 50, \n",
    "                                cv = 3, \n",
    "                                verbose=1, \n",
    "                                random_state=123)\n",
    "\n",
    "svm_random.fit(train[features], train[\"Fraud\"])\n",
    "# svc.fit(train[features], train[\"Fraud\"])\n",
    "\n",
    "# svm_random.best_params_\n",
    "metrics_cal(svm_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainpred = pd.read_csv('train_pred.csv')\n",
    "testpred = pd.read_csv('test_pred.csv')\n",
    "ootpred = pd.read_csv('oot_pred.csv')\n",
    "\n",
    "trainpred[\"Fraud\"] = train[\"Fraud\"].values\n",
    "testpred[\"Fraud\"] = test[\"Fraud\"].values\n",
    "ootpred[\"Fraud\"] = oot_df[\"Fraud\"].values\n",
    "\n",
    "trainpred[\"rf\"] = rf_random.predict_proba(train[features])[:,1]\n",
    "testpred[\"rf\"] = rf_random.predict_proba(test[features])[:,1]\n",
    "ootpred[\"rf\"] = rf_random.predict_proba(oot_df[features])[:,1]\n",
    "\n",
    "trainpred[\"svm\"] = svm_random.predict_proba(train[features])[:,1]\n",
    "testpred[\"svm\"] = svm_random.predict_proba(test[features])[:,1]\n",
    "ootpred[\"svm\"] = svm_random.predict_proba(oot_df[features])[:,1]\n",
    "\n",
    "trainpred.to_csv('train_pred.csv')\n",
    "testpred.to_csv('test_pred.csv')\n",
    "ootpred.to_csv('oot_pred.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>logit</th>\n",
       "      <th>nn</th>\n",
       "      <th>Fraud</th>\n",
       "      <th>rf</th>\n",
       "      <th>svm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.107786</td>\n",
       "      <td>3.595859e-05</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.130642</td>\n",
       "      <td>2.369101e-12</td>\n",
       "      <td>0</td>\n",
       "      <td>8.571429e-04</td>\n",
       "      <td>0.000563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.127210</td>\n",
       "      <td>9.193251e-10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.002066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.110270</td>\n",
       "      <td>2.767875e-10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.001917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.110270</td>\n",
       "      <td>2.767875e-10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.001917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.136699</td>\n",
       "      <td>7.026951e-09</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.002663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.143670</td>\n",
       "      <td>1.910958e-08</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.002186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.103450</td>\n",
       "      <td>9.031143e-09</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.001346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.157458</td>\n",
       "      <td>4.985338e-10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.001848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.088376</td>\n",
       "      <td>3.262635e-06</td>\n",
       "      <td>0</td>\n",
       "      <td>7.222222e-04</td>\n",
       "      <td>0.001018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0.120201</td>\n",
       "      <td>1.093370e-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0.082974</td>\n",
       "      <td>5.262129e-04</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0.003713</td>\n",
       "      <td>4.317163e-24</td>\n",
       "      <td>0</td>\n",
       "      <td>8.400000e-03</td>\n",
       "      <td>0.000576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0.003903</td>\n",
       "      <td>6.785476e-15</td>\n",
       "      <td>0</td>\n",
       "      <td>1.909506e-02</td>\n",
       "      <td>0.019356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0.003973</td>\n",
       "      <td>2.130311e-11</td>\n",
       "      <td>0</td>\n",
       "      <td>2.027778e-02</td>\n",
       "      <td>0.001296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>0.386017</td>\n",
       "      <td>2.053241e-07</td>\n",
       "      <td>0</td>\n",
       "      <td>1.830210e-05</td>\n",
       "      <td>0.011735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>0.403816</td>\n",
       "      <td>4.862706e-10</td>\n",
       "      <td>0</td>\n",
       "      <td>1.845746e-03</td>\n",
       "      <td>0.002719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>0.387188</td>\n",
       "      <td>1.416947e-06</td>\n",
       "      <td>0</td>\n",
       "      <td>4.444444e-04</td>\n",
       "      <td>0.000881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>0.256521</td>\n",
       "      <td>2.296550e-08</td>\n",
       "      <td>0</td>\n",
       "      <td>1.134369e-03</td>\n",
       "      <td>0.002347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>0.248023</td>\n",
       "      <td>2.836561e-06</td>\n",
       "      <td>0</td>\n",
       "      <td>4.471897e-04</td>\n",
       "      <td>0.002791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>0.244198</td>\n",
       "      <td>7.517147e-07</td>\n",
       "      <td>0</td>\n",
       "      <td>1.285609e-03</td>\n",
       "      <td>0.000902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>0.369061</td>\n",
       "      <td>1.588287e-05</td>\n",
       "      <td>0</td>\n",
       "      <td>1.111111e-03</td>\n",
       "      <td>0.031454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>0.022401</td>\n",
       "      <td>3.109761e-05</td>\n",
       "      <td>0</td>\n",
       "      <td>8.849048e-02</td>\n",
       "      <td>0.035282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>0.651074</td>\n",
       "      <td>1.044499e-15</td>\n",
       "      <td>0</td>\n",
       "      <td>2.179692e-01</td>\n",
       "      <td>0.000045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>0.013979</td>\n",
       "      <td>5.638237e-27</td>\n",
       "      <td>0</td>\n",
       "      <td>2.633024e-02</td>\n",
       "      <td>0.000317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>0.165209</td>\n",
       "      <td>1.335783e-03</td>\n",
       "      <td>0</td>\n",
       "      <td>2.114105e-06</td>\n",
       "      <td>0.000880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>0.246752</td>\n",
       "      <td>8.410903e-10</td>\n",
       "      <td>0</td>\n",
       "      <td>2.667143e-02</td>\n",
       "      <td>0.057577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>0.184902</td>\n",
       "      <td>4.210006e-02</td>\n",
       "      <td>0</td>\n",
       "      <td>5.093952e-03</td>\n",
       "      <td>0.000887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>0.142608</td>\n",
       "      <td>2.767180e-03</td>\n",
       "      <td>0</td>\n",
       "      <td>3.351881e-06</td>\n",
       "      <td>0.000702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>0.136602</td>\n",
       "      <td>5.423072e-06</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10152</th>\n",
       "      <td>10152</td>\n",
       "      <td>0.102555</td>\n",
       "      <td>5.351600e-03</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10153</th>\n",
       "      <td>10153</td>\n",
       "      <td>0.266878</td>\n",
       "      <td>7.296583e-05</td>\n",
       "      <td>0</td>\n",
       "      <td>1.148105e-02</td>\n",
       "      <td>0.005073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10154</th>\n",
       "      <td>10154</td>\n",
       "      <td>0.051426</td>\n",
       "      <td>8.353337e-07</td>\n",
       "      <td>0</td>\n",
       "      <td>6.666667e-04</td>\n",
       "      <td>0.000201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10155</th>\n",
       "      <td>10155</td>\n",
       "      <td>0.112007</td>\n",
       "      <td>2.071773e-01</td>\n",
       "      <td>0</td>\n",
       "      <td>9.470805e-07</td>\n",
       "      <td>0.001120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10156</th>\n",
       "      <td>10156</td>\n",
       "      <td>0.221950</td>\n",
       "      <td>2.348427e-10</td>\n",
       "      <td>0</td>\n",
       "      <td>2.607741e-03</td>\n",
       "      <td>0.000122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10157</th>\n",
       "      <td>10157</td>\n",
       "      <td>0.367535</td>\n",
       "      <td>1.055938e-16</td>\n",
       "      <td>0</td>\n",
       "      <td>3.035793e-03</td>\n",
       "      <td>0.000073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10158</th>\n",
       "      <td>10158</td>\n",
       "      <td>0.367535</td>\n",
       "      <td>1.055938e-16</td>\n",
       "      <td>0</td>\n",
       "      <td>3.035793e-03</td>\n",
       "      <td>0.000073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10159</th>\n",
       "      <td>10159</td>\n",
       "      <td>0.367535</td>\n",
       "      <td>1.055938e-16</td>\n",
       "      <td>0</td>\n",
       "      <td>3.035793e-03</td>\n",
       "      <td>0.000073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10160</th>\n",
       "      <td>10160</td>\n",
       "      <td>0.209962</td>\n",
       "      <td>3.386096e-14</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10161</th>\n",
       "      <td>10161</td>\n",
       "      <td>0.260925</td>\n",
       "      <td>7.160875e-10</td>\n",
       "      <td>0</td>\n",
       "      <td>1.543660e-05</td>\n",
       "      <td>0.000042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10162</th>\n",
       "      <td>10162</td>\n",
       "      <td>0.115253</td>\n",
       "      <td>1.546451e-01</td>\n",
       "      <td>0</td>\n",
       "      <td>2.454590e-07</td>\n",
       "      <td>0.001020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10163</th>\n",
       "      <td>10163</td>\n",
       "      <td>0.115253</td>\n",
       "      <td>1.546451e-01</td>\n",
       "      <td>0</td>\n",
       "      <td>2.454590e-07</td>\n",
       "      <td>0.001020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10164</th>\n",
       "      <td>10164</td>\n",
       "      <td>0.105884</td>\n",
       "      <td>9.945665e-04</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10165</th>\n",
       "      <td>10165</td>\n",
       "      <td>0.127496</td>\n",
       "      <td>3.355024e-10</td>\n",
       "      <td>0</td>\n",
       "      <td>3.346316e-04</td>\n",
       "      <td>0.000555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10166</th>\n",
       "      <td>10166</td>\n",
       "      <td>0.127425</td>\n",
       "      <td>3.237280e-08</td>\n",
       "      <td>0</td>\n",
       "      <td>4.045307e-07</td>\n",
       "      <td>0.002392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10167</th>\n",
       "      <td>10167</td>\n",
       "      <td>0.073933</td>\n",
       "      <td>1.884316e-06</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10168</th>\n",
       "      <td>10168</td>\n",
       "      <td>0.100934</td>\n",
       "      <td>2.160274e-03</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10169</th>\n",
       "      <td>10169</td>\n",
       "      <td>0.104483</td>\n",
       "      <td>2.476063e-07</td>\n",
       "      <td>0</td>\n",
       "      <td>1.211111e-03</td>\n",
       "      <td>0.000284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10170</th>\n",
       "      <td>10170</td>\n",
       "      <td>0.062430</td>\n",
       "      <td>5.761844e-05</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10171</th>\n",
       "      <td>10171</td>\n",
       "      <td>0.107572</td>\n",
       "      <td>1.699326e-02</td>\n",
       "      <td>0</td>\n",
       "      <td>3.333333e-04</td>\n",
       "      <td>0.001056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10172</th>\n",
       "      <td>10172</td>\n",
       "      <td>0.084825</td>\n",
       "      <td>1.361781e-05</td>\n",
       "      <td>0</td>\n",
       "      <td>2.454590e-07</td>\n",
       "      <td>0.000485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10173</th>\n",
       "      <td>10173</td>\n",
       "      <td>0.109205</td>\n",
       "      <td>1.817594e-01</td>\n",
       "      <td>0</td>\n",
       "      <td>8.042570e-05</td>\n",
       "      <td>0.001050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10174</th>\n",
       "      <td>10174</td>\n",
       "      <td>0.242956</td>\n",
       "      <td>1.391151e-05</td>\n",
       "      <td>0</td>\n",
       "      <td>1.155556e-03</td>\n",
       "      <td>0.009276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10175</th>\n",
       "      <td>10175</td>\n",
       "      <td>0.109204</td>\n",
       "      <td>1.817042e-01</td>\n",
       "      <td>0</td>\n",
       "      <td>8.042570e-05</td>\n",
       "      <td>0.001050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10176</th>\n",
       "      <td>10176</td>\n",
       "      <td>0.218654</td>\n",
       "      <td>2.220397e-03</td>\n",
       "      <td>0</td>\n",
       "      <td>5.454545e-06</td>\n",
       "      <td>0.011028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10177</th>\n",
       "      <td>10177</td>\n",
       "      <td>0.103028</td>\n",
       "      <td>2.543546e-03</td>\n",
       "      <td>0</td>\n",
       "      <td>2.833865e-07</td>\n",
       "      <td>0.001188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10178</th>\n",
       "      <td>10178</td>\n",
       "      <td>0.109602</td>\n",
       "      <td>2.008317e-13</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10179</th>\n",
       "      <td>10179</td>\n",
       "      <td>0.107797</td>\n",
       "      <td>1.127109e-01</td>\n",
       "      <td>0</td>\n",
       "      <td>7.314235e-05</td>\n",
       "      <td>0.001017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10180</th>\n",
       "      <td>10180</td>\n",
       "      <td>0.347557</td>\n",
       "      <td>1.177924e-06</td>\n",
       "      <td>0</td>\n",
       "      <td>1.334884e-02</td>\n",
       "      <td>0.005348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10181</th>\n",
       "      <td>10181</td>\n",
       "      <td>0.747868</td>\n",
       "      <td>3.276584e-06</td>\n",
       "      <td>0</td>\n",
       "      <td>5.486667e-02</td>\n",
       "      <td>0.000242</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10182 rows  6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0     logit            nn  Fraud            rf       svm\n",
       "0               0  0.107786  3.595859e-05      0  0.000000e+00  0.000647\n",
       "1               1  0.130642  2.369101e-12      0  8.571429e-04  0.000563\n",
       "2               2  0.127210  9.193251e-10      0  0.000000e+00  0.002066\n",
       "3               3  0.110270  2.767875e-10      0  0.000000e+00  0.001917\n",
       "4               4  0.110270  2.767875e-10      0  0.000000e+00  0.001917\n",
       "5               5  0.136699  7.026951e-09      0  0.000000e+00  0.002663\n",
       "6               6  0.143670  1.910958e-08      0  0.000000e+00  0.002186\n",
       "7               7  0.103450  9.031143e-09      0  0.000000e+00  0.001346\n",
       "8               8  0.157458  4.985338e-10      0  0.000000e+00  0.001848\n",
       "9               9  0.088376  3.262635e-06      0  7.222222e-04  0.001018\n",
       "10             10  0.120201  1.093370e-01      0  0.000000e+00  0.000717\n",
       "11             11  0.082974  5.262129e-04      0  0.000000e+00  0.000366\n",
       "12             12  0.003713  4.317163e-24      0  8.400000e-03  0.000576\n",
       "13             13  0.003903  6.785476e-15      0  1.909506e-02  0.019356\n",
       "14             14  0.003973  2.130311e-11      0  2.027778e-02  0.001296\n",
       "15             15  0.386017  2.053241e-07      0  1.830210e-05  0.011735\n",
       "16             16  0.403816  4.862706e-10      0  1.845746e-03  0.002719\n",
       "17             17  0.387188  1.416947e-06      0  4.444444e-04  0.000881\n",
       "18             18  0.256521  2.296550e-08      0  1.134369e-03  0.002347\n",
       "19             19  0.248023  2.836561e-06      0  4.471897e-04  0.002791\n",
       "20             20  0.244198  7.517147e-07      0  1.285609e-03  0.000902\n",
       "21             21  0.369061  1.588287e-05      0  1.111111e-03  0.031454\n",
       "22             22  0.022401  3.109761e-05      0  8.849048e-02  0.035282\n",
       "23             23  0.651074  1.044499e-15      0  2.179692e-01  0.000045\n",
       "24             24  0.013979  5.638237e-27      0  2.633024e-02  0.000317\n",
       "25             25  0.165209  1.335783e-03      0  2.114105e-06  0.000880\n",
       "26             26  0.246752  8.410903e-10      0  2.667143e-02  0.057577\n",
       "27             27  0.184902  4.210006e-02      0  5.093952e-03  0.000887\n",
       "28             28  0.142608  2.767180e-03      0  3.351881e-06  0.000702\n",
       "29             29  0.136602  5.423072e-06      0  0.000000e+00  0.000191\n",
       "...           ...       ...           ...    ...           ...       ...\n",
       "10152       10152  0.102555  5.351600e-03      0  0.000000e+00  0.000853\n",
       "10153       10153  0.266878  7.296583e-05      0  1.148105e-02  0.005073\n",
       "10154       10154  0.051426  8.353337e-07      0  6.666667e-04  0.000201\n",
       "10155       10155  0.112007  2.071773e-01      0  9.470805e-07  0.001120\n",
       "10156       10156  0.221950  2.348427e-10      0  2.607741e-03  0.000122\n",
       "10157       10157  0.367535  1.055938e-16      0  3.035793e-03  0.000073\n",
       "10158       10158  0.367535  1.055938e-16      0  3.035793e-03  0.000073\n",
       "10159       10159  0.367535  1.055938e-16      0  3.035793e-03  0.000073\n",
       "10160       10160  0.209962  3.386096e-14      0  0.000000e+00  0.000043\n",
       "10161       10161  0.260925  7.160875e-10      0  1.543660e-05  0.000042\n",
       "10162       10162  0.115253  1.546451e-01      0  2.454590e-07  0.001020\n",
       "10163       10163  0.115253  1.546451e-01      0  2.454590e-07  0.001020\n",
       "10164       10164  0.105884  9.945665e-04      0  0.000000e+00  0.000590\n",
       "10165       10165  0.127496  3.355024e-10      0  3.346316e-04  0.000555\n",
       "10166       10166  0.127425  3.237280e-08      0  4.045307e-07  0.002392\n",
       "10167       10167  0.073933  1.884316e-06      0  0.000000e+00  0.000135\n",
       "10168       10168  0.100934  2.160274e-03      0  0.000000e+00  0.000934\n",
       "10169       10169  0.104483  2.476063e-07      0  1.211111e-03  0.000284\n",
       "10170       10170  0.062430  5.761844e-05      0  0.000000e+00  0.000160\n",
       "10171       10171  0.107572  1.699326e-02      0  3.333333e-04  0.001056\n",
       "10172       10172  0.084825  1.361781e-05      0  2.454590e-07  0.000485\n",
       "10173       10173  0.109205  1.817594e-01      0  8.042570e-05  0.001050\n",
       "10174       10174  0.242956  1.391151e-05      0  1.155556e-03  0.009276\n",
       "10175       10175  0.109204  1.817042e-01      0  8.042570e-05  0.001050\n",
       "10176       10176  0.218654  2.220397e-03      0  5.454545e-06  0.011028\n",
       "10177       10177  0.103028  2.543546e-03      0  2.833865e-07  0.001188\n",
       "10178       10178  0.109602  2.008317e-13      0  0.000000e+00  0.000477\n",
       "10179       10179  0.107797  1.127109e-01      0  7.314235e-05  0.001017\n",
       "10180       10180  0.347557  1.177924e-06      0  1.334884e-02  0.005348\n",
       "10181       10181  0.747868  3.276584e-06      0  5.486667e-02  0.000242\n",
       "\n",
       "[10182 rows x 6 columns]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ootpred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00064694, 0.00056257, 0.00206625, ..., 0.00101721, 0.00534818,\n",
       "       0.0002423 ])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_random.predict_proba(oot_df[features])[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
